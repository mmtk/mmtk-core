<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>MMTk User Guide</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="The guide describes the usage of MMTk for GC and language runtime developers.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="assets/css/api-migration-details.css">
        <link rel="stylesheet" href="assets/css/mdbook-admonish.css">


        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">MMTk User Guide</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/mmtk/mmtk-core/tree/master/docs/userguide" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="introduction"><a class="header" href="#introduction">Introduction</a></h1>
<p>MMTk is a memory management toolkit providing language implementers with a powerful memory management framework
and researchers with a multi-runtime platform for memory management research. It is a complete re-write of the original MMTk,
which was written in Java as part of Jikes RVM.</p>
<iframe width="800" height="600" src="https://www.youtube.com/embed/0mldpiYW1X4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe><div style="break-before: page; page-break-before: always;"></div><h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<p>This document explains basic concepts of garbage collection.  MMTk uses those terms as described in
this document.  Different VMs may define some terms differently.  Should there be any confusion,
this document will help disambiguating them.  We use the book <a href="https://gchandbook.org/"><em>The Garbage Collection Handbook: The
Art of Automatic Memory Management</em></a> as the primary reference.</p>
<h2 id="object-graph"><a class="header" href="#object-graph">Object graph</a></h2>
<p>Object graph is a graph-theory view of the garbage-collected heap.  An <strong>object graph</strong> is a
directed graph that contains <em>nodes</em> and <em>edges</em>.  An edge always points to a node.  But unlike
conventional graphs, an edge may originate from either another node or a <em>root</em>.</p>
<p>Each <em>node</em> represents an object in the heap.</p>
<p>Each <em>edge</em> represents an object reference from an object or a root.  A <em>root</em> is a reference held
in a slot directly accessible from <a href="glossary.html#mutator">mutators</a>, including local variables, global variables,
thread-local variables, and so on.  A object can have many fields, and some fields may hold
references to objects, while others hold non-reference values.</p>
<p>An object is <em>reachable</em> if there is a path in the object graph from any root to the node of the
object.  Unreachable objects cannot be accessed by <a href="glossary.html#mutator">mutators</a>.  They are considered
garbage, and can be reclaimed by the garbage collector.</p>
<h2 id="mutator"><a class="header" href="#mutator">Mutator</a></h2>
<p>TODO</p>
<h2 id="emergency-collection"><a class="header" href="#emergency-collection">Emergency Collection</a></h2>
<p>Also known as: <em>emergency GC</em></p>
<p>In MMTk, an emergency collection happens when a normal collection cannot reclaim enough memory to
satisfy allocation requests.  Plans may do full-heap GC, defragmentation, etc. during emergency
collections in order to free up more memory.</p>
<p>VM bindings can call <code>MMTK::is_emergency_collection</code> to query if the current GC is an emergency GC.
During emergency GC, the VM binding is recommended to retain fewer objects than normal GCs, to the
extent allowed by the specification of the VM or the language.  For example, the VM binding may
choose not to retain objects used for caching.  Specifically, for Java virtual machines, that means
not retaining referents of <a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/lang/ref/SoftReference.html"><code>SoftReference</code></a> which is primarily designed for
implementing memory-sensitive caches.</p>
<!--
vim: tw=100 ts=4 sw=4 sts=4 et
-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="mmtk-tutorial"><a class="header" href="#mmtk-tutorial">MMTk Tutorial</a></h1>
<p>In this tutorial, you will build multiple garbage collectors from
scratch using MMTk.
You will start with an incredibly simple 'collector' called NoGC,
and through a series of additions and refinements end up with a
generational copying garbage collector.</p>
<p>This tutorial is aimed at GC implementors who would like to implement
new GC algorithms/plans with MMTk. If you are a language implementor
interested in <em>porting</em> your runtime to MMTk, you should refer to the
<a href="tutorial/../portingguide/prefix.html">porting guide</a> instead.</p>
<p>This tutorial is a work in progress. Some sections may be rough, and others may
be missing information (especially about import statements). If something is
missing or inaccurate, refer to the relevant completed garbage collector if
possible. Please also raise an issue, or create a pull request addressing
the problem.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-is-mmtk"><a class="header" href="#what-is-mmtk">What <em>is</em> MMTk?</a></h1>
<p>The Memory Management Toolkit (MMTk) is a framework for designing and
implementing memory managers. It has a runtime-neutral core (mmtk-core)
written in Rust, and bindings that allow it to work with OpenJDK, V8,
and JikesRVM, with more bindings currently in development.
MMTk was originally written in Java as part of the JikesRVM Java runtime.
The current version is similar in its purpose, but was made to be
very flexible with runtime and able to be ported to many different VMs.</p>
<p>The principal idea of MMTk is that it can be used as a
toolkit, allowing new GC algorithms to be rapidly developed using
common components. It also allows different GC algorithms to be
compared on an apples-to-apples basis, since they share common mechanisms.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="what-will-this-tutorial-cover"><a class="header" href="#what-will-this-tutorial-cover">What will this tutorial cover?</a></h1>
<p>This tutorial is intended to get you comfortable constructing new plans in
MMTk.</p>
<p>You will first be guided through building a semispace collector. After that,
you will extend this collector to be a generational collector, to further
familiarise you with different concepts in MMTk. There will also be
questions and exercises at various points in the tutorial, intended to
encourage you to think about what the code is doing, increase your general
understanding of MMTk, and motivate further research.</p>
<p>Where possible, there will be links to finished, functioning code after each
section so that you can check that your code is correct. Note, however, that
these will be full collectors. Therefore, there may be some differences between
these files and your collector due to your position in the tutorial. By the end
of each major section, your code should be functionally identical to the
finished code provided.</p>
<p>Furthermore, please note that this code may not be identical to the main code
of the MMTk. It is deliberately kept separate as a simpler stable
version. Make sure to refer to the
<a href="https://github.com/mmtk/mmtk-core/tree/master/docs/userguide/src/tutorial/code">provided tutorial code</a>
and not the main collector code during the tutorial.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossary-1"><a class="header" href="#glossary-1">Glossary</a></h1>
<p><em>allocator</em>: Code that allocates new objects into memory.</p>
<p><em>collector</em>: Finds and frees memory occupied by 'dead' objects.</p>
<p><em>dead</em>: An object that is not live.</p>
<p><em>GC work (unit), GC packet</em>: A schedulable unit of collection work.</p>
<p><em>GC worker</em>: A worker thread that performs garbage collection operations
(as required by GC work units).</p>
<p><em>live</em>: An object that is reachable, and thus can still be accessed by other
objects, is live/alive.</p>
<p><em>mutator</em>: Something that 'mutates', or changes, the objects stored in memory.
This is the term that is traditionally used in the garbage collection literature
to describe the running program (because it 'mutates' the object graph).</p>
<p><em>plan</em>: A garbage collection algorithm expressed as a configuration of policies.
See also <a href="tutorial/intro/glossary.html#plans-and-policies">Plans and policies</a> below.</p>
<p><em>policy</em>: A specific garbage collection algorithm, such as marksweep, copying,
immix, etc. Plans are made up of an arrangement of one or more policies.
See also <a href="tutorial/intro/glossary.html#plans-and-policies">Plans and policies</a> below.</p>
<p><em>scheduler</em>: Dynamically dispatches units of GC work to workers.</p>
<p><em>zeroing</em>, <em>zero initialization</em>: Initializing and resetting unused memory
bits to have a value of 0. Required by most memory-safe programming languages.</p>
<p>See also: <a href="tutorial/intro/../further_reading.html">Further Reading</a></p>
<h2 id="plans-and-policies"><a class="header" href="#plans-and-policies">Plans and Policies</a></h2>
<p>In MMTk, collectors are instantiated as plans, which can be thought of as
configurations of collector policies. In practice, most production
collectors and almost all collectors in MMTk are comprised of multiple
algorithms/policies. For example the gencopy plan describes a configuration
that combines a copying nursery with a semispace mature space. In MMTk we
think of these as three spaces, each of which happen to use the copyspace
policy, and which have a relationship which is defined by the gencopy plan.
Under the hood, gencopy builds upon a common plan which may also contain other
policies including a space for code, a read-only space, etc.</p>
<p>Thus, someone wishing to construct a new collector based entirely on existing
policies may be able to do so in MMTk by simply writing a new plan, which is
what this tutorial covers.</p>
<p>On the other hand, someone wishing to introduce an entirely new garbage
collection policy (such as Immix, for example), would need to first create
a policy which specifies that algorithm, before creating a plan which defines
how the GC algorithm fits together and utilizes that policy.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="set-up-mmtk-and-openjdk"><a class="header" href="#set-up-mmtk-and-openjdk">Set up MMTk and OpenJDK</a></h1>
<p>This tutorial can be completed with any binding. However, for the sake of
simplicity, only the setup for the OpenJDK binding will be described in detail
here. If you would like to use another binding, you will need to follow the
README files in their respective repositories
(<a href="https://github.com/mmtk/mmtk-jikesrvm">JikesRVM</a>,
<a href="https://github.com/mmtk/mmtk-v8">V8</a>)
to set them up, and find appropriate benchmarks for testing.
Also, while it may be useful to fork the relevant repositories to your own
account, it is not required for this tutorial.</p>
<p>First, set up OpenJDK, MMTk, and the binding:</p>
<ol>
<li>Clone the OpenJDK binding and mmtk-core repository, and install any relevant
dependencies by following the instructions in the
<a href="https://github.com/mmtk/mmtk-openjdk/blob/master/README.md">OpenJDK binding repository</a>.</li>
<li>Ensure you can build OpenJDK according to the instructions in the READMEs of
<a href="https://github.com/mmtk/mmtk-core/blob/master/README.md">the mmtk-core repository</a> and the
<a href="https://github.com/mmtk/mmtk-openjdk/blob/master/README.md">OpenJDK binding repository</a>.
<ul>
<li>Use the <code>slowdebug</code> option when building the OpenJDK binding. This is the
fastest debug variant to build, and allows for easier debugging and better
testing. The rest of the tutorial will assume you are using <code>slowdebug</code>.</li>
<li>You can use the env var <code>MMTK_PLAN=[PlanName]</code> to choose a plan to use at run-time.
The plans that are relevant to this tutorial are <code>NoGC</code> and <code>SemiSpace</code>.</li>
<li>Make sure you <em>only</em> use the env var <code>MMTK_PLAN=[PlanName]</code> when you run the generated <code>java</code> binary
(<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java</code>). Do not set <code>MMTK_PLAN</code>
when you build OpenJDK (if you already have set the env var <code>MMTK_PLAN</code>, you would need to do
<code>export MMTK_PLAN=</code> or <code>unset MMTK_PLAN</code> to clear the env var before building).</li>
</ul>
</li>
</ol>
<p>The MMTk OpenJDK binding ships with a fixed version of mmtk-core, specified in <code>mmtk-openjdk/mmtk/Cargo.toml</code>.
For local development, you would need to build the binding with a local copy of the mmtk-core repo that you
can modify. You would need to point the mmtk dependency to a local path.</p>
<ol>
<li>Find <code>mmtk</code> under <code>[dependencies]</code> in <code>mmtk-openjdk/mmtk/Cargo.toml</code>. It should point
to the mmtk-core git path with a specific revision.</li>
<li>Comment out the line for the git dependency, and uncomment the following line for a local dependency.</li>
<li>The local dependency points to <code>mmtk-openjdk/repos/mmtk-core</code> by default. If your local mmtk-core path is
not <code>mmtk-openjdk/repos/mmtk-core</code>, modify the path to point to your local mmtk-core.</li>
<li>Rebuild the OpenJDK binding.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="test-the-build"><a class="header" href="#test-the-build">Test the build</a></h1>
<p>A few benchmarks of varying size will be used throughout the tutorial. If you
haven't already, set them up now. All of the following commands should be
entered in <code>repos/openjdk</code>.</p>
<ol>
<li>
<p><strong>HelloWorld</strong> (simplest, will never trigger GC):</p>
<ol>
<li>Copy the following code into a new Java file titled "HelloWorld.java"
in <code>mmtk-openjdk/repos/openjdk</code>:
<pre><code class="language-java">class HelloWorld {
   public static void main(String[] args) {
      System.out.println("Hello World!");
   }
}
</code></pre>
</li>
<li>Use the command
<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/javac HelloWorld.java</code>.</li>
<li>Then, run
<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java -XX:+UseThirdPartyHeap HelloWorld</code>
to run HelloWorld.</li>
<li>If your program printed out <code>Hello World!</code> as expected, then
congratulations, you have MMTk working with OpenJDK!</li>
</ol>
</li>
<li>
<p>The Computer Language Benchmarks Game <strong>fannkuchredux</strong> (micro benchmark,
allocates a small amount of memory but - depending on heap size and the GC
plan - may not trigger a collection):</p>
<ol>
<li><a href="https://salsa.debian.org/benchmarksgame-team/benchmarksgame/-/blob/master/bencher/programs/fannkuchredux/fannkuchredux.java">Copy this code</a>
into a new file named "fannkuchredux.java"
in <code>mmtk-openjdk/repos/openjdk</code>.</li>
<li>Use the command
<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/javac fannkuchredux.java</code>.</li>
<li>Then, run
<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java -XX:+UseThirdPartyHeap fannkuchredux</code>
to run fannkuchredux.</li>
</ol>
</li>
<li>
<p><strong>DaCapo</strong> benchmark suite (most complex, will likely trigger multiple
collections):</p>
<ol>
<li>Fetch using
<code>wget https://sourceforge.net/projects/dacapobench/files/9.12-bach-MR1/dacapo-9.12-MR1-bach.jar/download -O ./dacapo-9.12-MR1-bach.jar</code>.</li>
<li>DaCapo contains a variety of benchmarks, but this tutorial will only be
using lusearch. Run the lusearch benchmark using the command
<code>./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java -XX:+UseThirdPartyHeap -Xms512M -Xmx512M -jar ./dacapo-9.12-MR1-bach.jar lusearch</code> in <code>repos/openjdk</code>.</li>
</ol>
</li>
</ol>
<h2 id="rust-logs"><a class="header" href="#rust-logs">Rust Logs</a></h2>
<p>By using one of the debug builds, you gain access to the Rust logs - a useful
tool when testing a plan and observing the general behaviour of MMTk.
There are two levels of trace that are useful when using MMTk - <code>trace</code>
and <code>debug</code>. Generally, <code>debug</code> logs information about the slow paths
(allocation through MMTk, rather than fast path allocation through the binding).
<code>trace</code> includes all the information from <code>debug</code>, plus more information about
both slow and fast paths and garbage collection activities. You can set which
level to view the logs at by setting the environment variable <code>RUST_LOG</code>. For
more information, see the
<a href="https://crates.io/crates/env_logger">env_logger crate documentation</a>.</p>
<h2 id="working-with-different-gc-plans"><a class="header" href="#working-with-different-gc-plans">Working with different GC plans</a></h2>
<p>You will be using multiple GC plans in this tutorial. You should
familiarise yourself with how to do this now.</p>
<ol>
<li>The OpenJDK build will always generate in <code>mmtk-openjdk/repos/openjdk/build</code>.
From the same build, you can run different GC plans by using the environment
variable <code>MMTK_PLAN=[PlanName]</code>. Generally you won't need multiple VM builds.
However, if you do need to keep a build (for instance, to make quick performance
comparisons), you can do the following: rename either the <code>build</code> folder or the
folder generated within it (eg <code>linux-x86_64-normal-server-$DEBUG_LEVEL</code>).
<ol>
<li>Renaming the <code>build</code> folder is the safest method for this.</li>
<li>If you rename the internal folder, there is a possibility that the new
build will generate incorrectly. If a build appears to generate strangely
quickly, it probably generated badly.</li>
<li>A renamed build folder can be tested by changing the file path in
commands as appropriate.</li>
<li>If you plan to completely overwrite a build, deleting the folder you are
writing over will help prevent errors.</li>
</ol>
</li>
<li>Try running your build with <code>NoGC</code>. Both HelloWorld and the fannkuchredux
benchmark should run without issue. If you then run lusearch, it should fail
when a collection is triggered. It is possible to increase the heap size enough
that no collections will be triggered, but it is okay to let it fail for now.
When we build using a proper GC, it will be able to pass. The messages and
errors produced should look identical or nearly identical to the log below.
<pre><code>$ MMTK_PLAN=NoGC ./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java -XX:+UseThirdPartyHeap -Xms512M -Xmx512M -jar ./dacapo-9.12-MR1-bach.jar lusearch
Using scaled threading model. 24 processors detected, 24 threads used to drive the workload, in a possible range of [1,64]
Warning: User attempted a collection request, but it is not supported in NoGC. The request is ignored.
===== DaCapo 9.12-MR1 lusearch starting =====
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
thread '&lt;unnamed&gt;' panicked at 'internal error: entered unreachable code: GC triggered in nogc', /opt/rust/toolchains/nightly-2020-07-08-x86_64-unknown-linux-gnu/lib/rustlib/src/rust/src/libstd/macros.rs:16:9
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
[2020-12-18T00:27:49Z INFO  mmtk::plan::global]   [POLL] nogc_space: Triggering collection
fatal runtime error: failed to initiate panic, error 5
Aborted (core dumped)
</code></pre>
</li>
<li>Try running your build with <code>SemiSpace</code>. lusearch should now
pass, as garbage will be collected, and the smaller benchmarks should run the
same as they did while using NoGC.
<pre><code>MMTK_PLAN=SemiSpace ./build/linux-x86_64-normal-server-$DEBUG_LEVEL/jdk/bin/java -XX:+UseThirdPartyHeap -Xms512M -Xmx512M -jar ./dacapo-9.12-MR1-bach.jar lusearch
</code></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="create-mygc"><a class="header" href="#create-mygc">Create MyGC</a></h1>
<p>NoGC is a GC plan that only allocates memory, and does not have a collector.
We're going to use it as a base for building a new garbage collector.</p>
<p>Recall that this tutorial will take you through the steps of building a
collector from basic principles. To do that, you'll create your own plan
called <code>MyGC</code> which you'll gradually refine and improve upon through the
course of this tutorial. At the beginning MyGC will resemble the very
simple NoGC plan.</p>
<ol>
<li>Each plan is stored in <code>mmtk-openjdk/repos/mmtk-core/src/plan</code>. Navigate
there and create a copy of the folder <code>nogc</code>. Rename it to <code>mygc</code>.</li>
<li>In <em>each file</em> within <code>mygc</code>, rename any reference to <code>nogc</code> to <code>mygc</code>.
You will also have to separately rename any reference to <code>NoGC</code> to <code>MyGC</code>.
<ul>
<li>For example, in Visual Studio Code, you can (making sure case sensitivity
is selected in the search function) select one instance of <code>nogc</code> and either
right click and select "Change all instances" or use the CTRL-F2 shortcut,
and then type <code>mygc</code>, and repeat for <code>NoGC</code>.</li>
</ul>
</li>
<li>In order to use MyGC, you will need to make some changes to the following
files.
<ol>
<li><code>mmtk-core/src/plan/mod.rs</code>, add:
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub mod mygc;
<span class="boring">}</span></code></pre></pre>
This adds <code>mygc</code> as a module.</li>
<li><code>mmtk-core/src/util/options.rs</code>, add <code>MyGC</code> to the enum <code>PlanSelector</code>.
This allows MMTk to accept <code>MyGC</code> as a command line option for <code>plan</code>,
or an environment variable for <code>MMTK_PLAN</code>:
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(Copy, Clone, EnumFromStr, Debug)]
pub enum PlanSelector {
    NoGC,
    SemiSpace,
    GenCopy,
    GenImmix,
    MarkSweep,
    PageProtect,
    Immix,
    // Add this!
    MyGC,
}
<span class="boring">}</span></code></pre></pre>
</li>
<li><code>mmtk-core/src/plan/global.rs</code>, add new expressions to
<code>create_mutator()</code> and <code>create_plan()</code> for <code>MyGC</code>, following the pattern of
the existing plans. These define the location of the mutator and plan's
constructors.
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// NOTE: Sections of this code snippet not relevant to this step of the 
// tutorial (marked by "// ...") have been omitted.
pub fn create_mutator&lt;VM: VMBinding&gt;(
    tls: VMMutatorThread,
    mmtk: &amp;'static MMTK&lt;VM&gt;,
) -&gt; Box&lt;Mutator&lt;VM&gt;&gt; {
    Box::new(match mmtk.options.plan {
        PlanSelector::NoGC =&gt; crate::plan::nogc::mutator::create_nogc_mutator(tls, &amp;*mmtk.plan),
        PlanSelector::SemiSpace =&gt; {
            crate::plan::semispace::mutator::create_ss_mutator(tls, &amp;*mmtk.plan)
        }

        // ...

        // Create MyGC mutator based on selector
        PlanSelector::MyGC =&gt; crate::plan::mygc::mutator::create_mygc_mutator(tls, &amp;*mmtk.plan),    })
}

pub fn create_plan&lt;VM: VMBinding&gt;(
    plan: PlanSelector,
    vm_map: &amp;'static VMMap,
    mmapper: &amp;'static Mmapper,
    options: Arc&lt;UnsafeOptionsWrapper&gt;,
) -&gt; Box&lt;dyn Plan&lt;VM = VM&gt;&gt; {
    match plan {
        PlanSelector::NoGC =&gt; Box::new(crate::plan::nogc::NoGC::new(args)),
        PlanSelector::SemiSpace =&gt; Box::new(crate::plan::semispace::SemiSpace::new(args)),

        // ...

        // Create MyGC plan based on selector
        PlanSelector::MyGC =&gt; Box::new(crate::plan::mygc::MyGC::new(args))
    }
}       
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
</li>
</ol>
<p>Note that all of the above changes almost exactly copy the NoGC entries in
each of these files. However, NoGC has some variants, such as a lock-free
variant. For simplicity, those are not needed for this tutorial. Remove
references to them in the MyGC plan now.</p>
<ol>
<li>Within <code>mygc/global.rs</code>, find any use of <code>#[cfg(feature = "mygc_lock_free")]</code>
and delete both it <em>and the line below it</em>.</li>
<li>Then, delete any use of the above line's negation,
<code>#[cfg(not(feature = "mygc_lock_free"))]</code>, this time without changing the
line below it.</li>
</ol>
<p>After you rebuild OpenJDK (and <code>mmtk-core</code>), you can run MyGC with your new
build (<code>MMTK_PLAN=MyGC</code>). Try testing it with the each of the three benchmarks.
It should work identically to NoGC.</p>
<p>If you've got to this point, then congratulations! You have created your first
working MMTk collector!</p>
<p>At this point, you should familiarise yourself with the MyGC plan if you
haven't already. Try answering the following questions by looking at the code
and <a href="tutorial/mygc/../further_reading.html">Further Reading</a>:</p>
<ul>
<li>Where is the allocator defined?</li>
<li>How many memory spaces are there?</li>
<li>What kind of memory space policy is used?</li>
<li>What happens if garbage has to be collected?</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-a-semispace-collector"><a class="header" href="#building-a-semispace-collector">Building a semispace collector</a></h1>
<p>In a semispace collector, the heap is divided into two equally-sized spaces,
called 'semispaces'. One of these is defined as a 'fromspace', and the other
a 'tospace'. The allocator allocates to the tospace until it is full.</p>
<p>When the tospace is full, a stop-the-world GC is triggered. The mutator is
paused, and the definitions of the spaces are flipped (the 'tospace' becomes
a 'fromspace', and vice versa). Then, the collector scans each object in what
is now the fromspace. If a live object is found, a copy of it is made in the
tospace. That is to say, live objects are copied <em>from</em> the fromspace <em>to</em>
the tospace. After every object is scanned, the fromspace is cleared. The GC
finishes, and the mutator is resumed.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="allocation-add-copyspaces"><a class="header" href="#allocation-add-copyspaces">Allocation: Add copyspaces</a></h1>
<p>We will now change your MyGC plan from one that cannot collect garbage
into one that implements the semispace algorithm. The first step of this
is to add the two copyspaces, and allow collectors to allocate memory
into them. This involves adding two copyspaces, the code to properly initialise
and prepare the new spaces, and a copy context.</p>
<h2 id="change-the-plan-constraints"><a class="header" href="#change-the-plan-constraints">Change the plan constraints</a></h2>
<p>Firstly, change the plan constraints. Some of these constraints are not used
at the moment, but it's good to set them properly regardless.</p>
<p>Look in <code>plan/plan_constraints.rs</code>. <code>PlanConstraints</code> lists all the possible
options for plan-specific constraints. At the moment, <code>MYGC_CONSTRAINTS</code> in
<code>mygc/global.rs</code> should be using the default value for <code>PlanConstraints</code>.
We will make the following changes:</p>
<ol>
<li>Initialize <code>gc_header_bits</code> to 2. We reserve 2 bits in the header for GC use.</li>
<li>Initialize <code>moves_objects</code> to <code>true</code>.</li>
</ol>
<p>Finished code (step 1-3):</p>
<pre><code>pub const MYGC_CONSTRAINTS: PlanConstraints = PlanConstraints {
    moves_objects: true,
    ..PlanConstraints::default()
};
</code></pre>
<h2 id="change-the-plan-implementation"><a class="header" href="#change-the-plan-implementation">Change the plan implementation</a></h2>
<p>Next, in <code>mygc/global.rs</code>, replace the old immortal (nogc) space with two
copyspaces.</p>
<h3 id="imports"><a class="header" href="#imports">Imports</a></h3>
<p>To the import statement block:</p>
<ol>
<li>Replace <code>crate::plan::global::{BasePlan, NoCopy};</code> with
<code>use crate::plan::global::BasePlan;</code>. This collector is going to use
copying, so there's no point to importing NoCopy any more.</li>
<li>Add <code>use crate::plan::global::CommonPlan;</code>. Semispace uses the common
plan, which includes an immortal space and a large object space, rather
than the base plan. Any garbage collected plan should use <code>CommonPlan</code>.</li>
<li>Add <code>use std::sync::atomic::{AtomicBool, Ordering};</code>. These are going
to be used to store an indicator of which copyspace is the tospace.</li>
<li>Delete <code>#[allow(unused_imports)]</code>.</li>
</ol>
<p>Finished code (step 1):</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crate::plan::global::BasePlan; //Modify
use crate::plan::global::CommonPlan; // Add
use crate::plan::global::{CreateGeneralPlanArgs, CreateSpecificPlanArgs};
use crate::plan::mygc::mutator::ALLOCATOR_MAPPING;
use crate::plan::mygc::gc_work::MyGCWorkContext;
use crate::plan::AllocationSemantics;
use crate::plan::Plan;
use crate::plan::PlanConstraints;
use crate::policy::copyspace::CopySpace; // Add
use crate::policy::space::Space;
use crate::scheduler::*; // Modify
use crate::util::alloc::allocators::AllocatorSelector;
use crate::util::copy::*;
use crate::util::heap::VMRequest;
use crate::util::heap::gc_trigger::SpaceStats;
use crate::util::metadata::side_metadata::SideMetadataContext;
use crate::util::opaque_pointer::*;
use crate::vm::VMBinding;
use enum_map::EnumMap;
use std::sync::atomic::{AtomicBool, Ordering}; // Add
<span class="boring">}</span></code></pre></pre>
<h3 id="struct-mygc"><a class="header" href="#struct-mygc">Struct MyGC</a></h3>
<p>Change <code>pub struct MyGC&lt;VM: VMBinding&gt;</code> to add new instance variables.</p>
<ol>
<li>Delete the existing fields in the constructor.</li>
<li>Add <code>pub hi: AtomicBool,</code>. This is a thread-safe bool, indicating which
copyspace is the tospace.</li>
<li>Add <code>pub copyspace0: CopySpace&lt;VM&gt;,</code>
and <code>pub copyspace1: CopySpace&lt;VM&gt;,</code>. These are the two copyspaces.</li>
<li>Add <code>pub common: CommonPlan&lt;VM&gt;,</code>.
This holds an instance of the common plan.</li>
</ol>
<p>Finished code (step 2):</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(HasSpaces, PlanTraceObject)]
pub struct MyGC&lt;VM: VMBinding&gt; {
    pub hi: AtomicBool,
    #[space]
    #[copy_semantics(CopySemantics::DefaultCopy)]
    pub copyspace0: CopySpace&lt;VM&gt;,
    #[space]
    #[copy_semantics(CopySemantics::DefaultCopy)]
    pub copyspace1: CopySpace&lt;VM&gt;,
    #[parent]
    pub common: CommonPlan&lt;VM&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Note that <code>MyGC</code> now also derives <code>PlanTraceObject</code> besides <code>HasSpaces</code>, and we
have attributes on some fields. These attributes tell MMTk's macros how to
generate code to visit each space of this plan as well as trace objects in this
plan.  Although there are other approaches that you can implement object
tracing, in this tutorial we use the macros, as it is the simplest.  Make sure
you import the macros. We will discuss on what those attributes mean in later
sections.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mmtk_macros::{HasSpaces, PlanTraceObject};
<span class="boring">}</span></code></pre></pre>
<h3 id="implement-the-plan-trait-for-mygc"><a class="header" href="#implement-the-plan-trait-for-mygc">Implement the Plan trait for MyGC</a></h3>
<h4 id="constructor"><a class="header" href="#constructor">Constructor</a></h4>
<p>Change <code>fn new()</code>. This section initialises and prepares the objects in MyGC
that you just defined.</p>
<ol>
<li>Delete the definition of <code>mygc_space</code>.
Instead, we will define the two copyspaces here.</li>
<li>Define one of the copyspaces by adding the following code:</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>            copyspace0: CopySpace::new(plan_args.get_space_args("copyspace0", true, false, VMRequest::discontiguous()), false),
<span class="boring">}</span></code></pre></pre>
<ol start="3">
<li>Create another copyspace, called <code>copyspace1</code>, defining it as a fromspace
instead of a tospace. (Hint: the definitions for
copyspaces are in <code>src/policy/copyspace.rs</code>.)</li>
<li>Finally, replace the old MyGC initializer.</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn new(args: CreateGeneralPlanArgs&lt;VM&gt;) -&gt; Self {
        // Modify
        let mut plan_args = CreateSpecificPlanArgs {
            global_args: args,
            constraints: &amp;MYGC_CONSTRAINTS,
            global_side_metadata_specs: SideMetadataContext::new_global_specs(&amp;[]),
        };

        let res = MyGC {
            hi: AtomicBool::new(false),
            copyspace0: CopySpace::new(plan_args.get_space_args("copyspace0", true, false, VMRequest::discontiguous()), false),
            copyspace1: CopySpace::new(plan_args.get_space_args("copyspace1", true, false, VMRequest::discontiguous()), true),
            common: CommonPlan::new(plan_args),
        };

        res.verify_side_metadata_sanity();

        res
    }
<span class="boring">}</span></code></pre></pre>
<h3 id="access-mygc-spaces"><a class="header" href="#access-mygc-spaces">Access MyGC spaces</a></h3>
<p>Add a new section of methods for MyGC:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;VM: VMBinding&gt; MyGC&lt;VM&gt; {
}
<span class="boring">}</span></code></pre></pre>
<p>To this, add two helper methods, <code>tospace(&amp;self)</code>
and <code>fromspace(&amp;self)</code>. They both have return type <code>&amp;CopySpace&lt;VM&gt;</code>,
and return a reference to the tospace and fromspace respectively.
<code>tospace()</code> (see below) returns a reference to the tospace,
and <code>fromspace()</code> returns a reference to the fromspace.</p>
<p>We also add another two helper methods to get <code>tospace_mut(&amp;mut self)</code>
and <code>fromspace_mut(&amp;mut self)</code>. Those will be used later when we implement
collection for our GC plan.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    pub fn tospace(&amp;self) -&gt; &amp;CopySpace&lt;VM&gt; {
        if self.hi.load(Ordering::SeqCst) {
            &amp;self.copyspace1
        } else {
            &amp;self.copyspace0
        }
    }

    pub fn fromspace(&amp;self) -&gt; &amp;CopySpace&lt;VM&gt; {
        if self.hi.load(Ordering::SeqCst) {
            &amp;self.copyspace0
        } else {
            &amp;self.copyspace1
        }
    }

    pub fn tospace_mut(&amp;mut self) -&gt; &amp;mut CopySpace&lt;VM&gt; {
        if self.hi.load(Ordering::SeqCst) {
            &amp;mut self.copyspace1
        } else {
            &amp;mut self.copyspace0
        }
    }

    pub fn fromspace_mut(&amp;mut self) -&gt; &amp;mut CopySpace&lt;VM&gt; {
        if self.hi.load(Ordering::SeqCst) {
            &amp;mut self.copyspace0
        } else {
            &amp;mut self.copyspace1
        }
    }
<span class="boring">}</span></code></pre></pre>
<h4 id="other-methods-in-the-plan-trait"><a class="header" href="#other-methods-in-the-plan-trait">Other methods in the Plan trait</a></h4>
<p>The trait <code>Plan</code> requires a <code>common()</code> method that should return a
reference to the common plan. Implement this method now.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn common(&amp;self) -&gt; &amp;CommonPlan&lt;VM&gt; {
        &amp;self.common
    }
<span class="boring">}</span></code></pre></pre>
<p>Find the helper method <code>base</code> and change it so that it calls the
base plan <em>through</em> the common plan.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn base(&amp;self) -&gt; &amp;BasePlan&lt;VM&gt; {
        &amp;self.common.base
    }

    fn base_mut(&amp;mut self) -&gt; &amp;mut BasePlan&lt;Self::VM&gt; {
        &amp;mut self.common.base
    }
<span class="boring">}</span></code></pre></pre>
<p>The trait <code>Plan</code> requires <code>collection_required()</code> method to know when
we should trigger a collection. We can just use the implementation
in the <code>BasePlan</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn collection_required(&amp;self, space_full: bool, _space: Option&lt;SpaceStats&lt;Self::VM&gt;&gt;) -&gt; bool {
        self.base().collection_required(self, space_full)
    }
<span class="boring">}</span></code></pre></pre>
<p>Find the method <code>get_pages_used</code>. Replace the current body with
<code>self.tospace().reserved_pages() + self.common.get_pages_used()</code>, to
correctly count the pages contained in the tospace and the common plan
spaces (which will be explained later).</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn get_used_pages(&amp;self) -&gt; usize {
        self.tospace().reserved_pages() + self.common.get_used_pages()
    }
<span class="boring">}</span></code></pre></pre>
<p>Add and override the following helper function:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn get_collection_reserved_pages(&amp;self) -&gt; usize {
        self.tospace().reserved_pages()
    }
<span class="boring">}</span></code></pre></pre>
<h2 id="change-the-mutator-definition"><a class="header" href="#change-the-mutator-definition">Change the mutator definition</a></h2>
<p>Next, we need to change the mutator, in <code>mutator.rs</code>, to allocate to the
tospace, and to the two spaces controlled by the common plan.</p>
<h3 id="imports-1"><a class="header" href="#imports-1">Imports</a></h3>
<p>Change the following import statements:</p>
<ol>
<li>Add <code>use super::MyGC;</code>.</li>
<li>Add <code>use crate::util::alloc::BumpAllocator;</code>.</li>
<li>Delete <code>use crate::plan::mygc::MyGC;</code>.</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use super::MyGC; // Add
use crate::MMTK;
use crate::plan::barriers::NoBarrier;
use crate::plan::mutator_context::Mutator;
use crate::plan::mutator_context::MutatorConfig;
use crate::plan::AllocationSemantics;
use crate::util::alloc::allocators::{AllocatorSelector, Allocators};
use crate::util::alloc::BumpAllocator;
use crate::util::opaque_pointer::*;
use crate::vm::VMBinding;
use crate::plan::mutator_context::{
    create_allocator_mapping, create_space_mapping, ReservedAllocators,
};
use enum_map::EnumMap;
// Remove crate::plan::mygc::MyGC
// Remove mygc_mutator_noop
<span class="boring">}</span></code></pre></pre>
<h3 id="allocator-mapping"><a class="header" href="#allocator-mapping">Allocator mapping</a></h3>
<p>In <code>lazy_static!</code>, make the following changes to <code>ALLOCATOR_MAPPING</code>,
which maps the required allocation semantics to the corresponding allocators.
For example, for <code>Default</code>, we allocate using the first bump pointer allocator
(<code>BumpPointer(0)</code>):</p>
<ol>
<li>Define a <code>ReservedAllocators</code> instance to declare that we need one bump allocator.</li>
<li>Map the common plan allocators using <code>create_allocator_mapping</code>.</li>
<li>Map <code>Default</code> to <code>BumpPointer(0)</code>.</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>const RESERVED_ALLOCATORS: ReservedAllocators = ReservedAllocators {
    n_bump_pointer: 1,
    ..ReservedAllocators::DEFAULT
};

lazy_static! {
    pub static ref ALLOCATOR_MAPPING: EnumMap&lt;AllocationSemantics, AllocatorSelector&gt; = {
        let mut map = create_allocator_mapping(RESERVED_ALLOCATORS, true);
        map[AllocationSemantics::Default] = AllocatorSelector::BumpPointer(0);
        map
    };
}
<span class="boring">}</span></code></pre></pre>
<h3 id="space-mapping"><a class="header" href="#space-mapping">Space mapping</a></h3>
<p>Next, in <code>create_mygc_mutator</code>, change which allocator is allocated to what
space in <code>space_mapping</code>. Note that the space allocation is formatted as a list
of tuples. For example, the first bump pointer allocator (<code>BumpPointer(0)</code>) is
bound with <code>tospace</code>.</p>
<p>Downcast the dynamic <code>Plan</code> type to <code>MyGC</code> so we can access specific spaces in
<code>MyGC</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    let mygc = mmtk.get_plan().downcast_ref::&lt;MyGC&lt;VM&gt;&gt;().unwrap();
<span class="boring">}</span></code></pre></pre>
<p>Then, use <code>mygc</code> to access the spaces in <code>MyGC</code>.</p>
<ol>
<li><code>BumpPointer(0)</code> should map to the tospace.</li>
<li>Other common plan allocators should be mapped using <code>create_space_mapping</code>.</li>
<li>None of the above should be dereferenced (ie, they should not have
the <code>&amp;</code> prefix).</li>
</ol>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>        space_mapping: Box::new({
            let mut vec = create_space_mapping(RESERVED_ALLOCATORS, true, mygc);
            vec.push((AllocatorSelector::BumpPointer(0), mygc.tospace()));
            vec
        }),
<span class="boring">}</span></code></pre></pre>
<p>The <code>create_space_mapping</code> and <code>create_allocator_mapping</code> call that have appeared all
of a sudden in these past 2 steps, are parts of the MMTk common plan
itself. They are used to construct allocator-space mappings for the spaces defined
by the common plan:</p>
<ol>
<li>The immortal space is used for objects that the virtual machine or a
library never expects to die.</li>
<li>The large object space is needed because MMTk handles particularly large
objects differently to normal objects, as the space overhead of copying
large objects is very high. Instead, this space is used by a free list
allocator in the common plan to avoid having to copy them.</li>
<li>The read-only space is used to store all the immutable objects.</li>
<li>The code spaces are used for VM generated code objects.</li>
</ol>
<p>With this, you should have the allocation working, but not garbage collection.
Try building again. If you run HelloWorld or Fannkunchredux, they should
work. DaCapo's lusearch should fail, as it requires garbage to be collected.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="collection-implement-garbage-collection"><a class="header" href="#collection-implement-garbage-collection">Collection: Implement garbage collection</a></h1>
<p>We need to add a few more things to get garbage collection working.
Specifically, we need to config the <code>GCWorkerCopyContext</code>, which a GC worker uses for
copying objects, and GC work packets that will be scheduled for a collection.</p>
<h2 id="copyconfig"><a class="header" href="#copyconfig">CopyConfig</a></h2>
<p><code>CopyConfig</code> defines how a GC plan copies objects.
Similar to the <code>MutatorConfig</code> struct, you would need to define <code>CopyConfig</code> for your plan.</p>
<p>In <code>impl&lt;VM: VMBinding&gt; Plan for MyGC&lt;VM&gt;</code>, override the method <code>create_copy_config()</code>.
The default implementation provides a default <code>CopyConfig</code> for non-copying plans. So for non-copying plans,
you do not need to override the method. But
for copying plans, you would have to provide a proper copy configuration.</p>
<p>In a semispace GC, objects will be copied between the two copy spaces. We will use one
<code>CopySpaceCopyContext</code> for the copying, and will rebind the copy context to the proper tospace
in the preparation step of a GC (which will be discussed later when we talk about preparing for collections).</p>
<p>We use <code>CopySemantics::DefaultCopy</code> for our copy
operation, and bind it with the first <code>CopySpaceCopyContext</code> (<code>CopySemantics::DefaultCopy =&gt; CopySelector::CopySpace(0)</code>).
Other copy semantics are unused in this plan. We also provide an initial space
binding for <code>CopySpaceCopyContext</code>. However, we will flip tospace in every GC, and rebind the
copy context to the new tospace in each GC, so it does not matter which space we use as the initial
space here.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn create_copy_config(&amp;'static self) -&gt; CopyConfig&lt;Self::VM&gt; {
        use enum_map::enum_map;
        CopyConfig {
            copy_mapping: enum_map! {
                CopySemantics::DefaultCopy =&gt; CopySelector::CopySpace(0),
                _ =&gt; CopySelector::Unused,
            },
            space_mapping: vec![
                // The tospace argument doesn't matter, we will rebind before a GC anyway.
                (CopySelector::CopySpace(0), &amp;self.copyspace0)
            ],
            constraints: &amp;MYGC_CONSTRAINTS,
        }
    }
<span class="boring">}</span></code></pre></pre>
<p>Because the semispace GC copies objects in every single GC, we modify the method
<code>current_gc_may_move_object()</code> in <code>MyGC</code> so that it always returns <code>true</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn current_gc_may_move_object(&amp;self) -&gt; bool {
        true
    }
<span class="boring">}</span></code></pre></pre>
<h2 id="introduce-collection-to-mygc-plan"><a class="header" href="#introduce-collection-to-mygc-plan">Introduce collection to MyGC plan</a></h2>
<p>Add a new method to <code>Plan for MyGC</code>, <code>schedule_collection()</code>. This function
runs when a collection is triggered. It schedules GC work for the plan, i.e.,
it stops all mutators, runs the
scheduler's prepare stage and resumes the mutators. The <code>StopMutators</code> work
will invoke code from the bindings to scan threads and other roots, and those
scanning work will further push work for a transitive closure.</p>
<p>Though you can add those work packets by yourself, <code>GCWorkScheduler</code> provides a
method <code>schedule_common_work()</code> that will add common work packets for you.</p>
<p>To use <code>schedule_common_work()</code>, first we need to create a type <code>MyGCWorkContext</code>
and implement the trait <code>GCWorkContext</code> for it. We create <code>gc_work.rs</code> and add the
following implementation. Note that we will use the default
<a href="https://docs.mmtk.io/api/mmtk/scheduler/gc_work/struct.SFTProcessEdges.html"><code>SFTProcessEdges</code></a>,
which is a general work packet that a plan can use to trace objects. For plans
like semispace, <code>SFTProcessEdges</code> is sufficient. For more complex GC plans,
one can create and write their own work packet that implements the <code>ProcessEdgesWork</code> trait.
We will discuss about this later, and discuss the alternatives.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MyGCWorkContext&lt;VM: VMBinding&gt;(std::marker::PhantomData&lt;VM&gt;);
impl&lt;VM: VMBinding&gt; crate::scheduler::GCWorkContext for MyGCWorkContext&lt;VM&gt; {
    type VM = VM;
    type PlanType = MyGC&lt;VM&gt;;
    type DefaultProcessEdges = SFTProcessEdges&lt;Self::VM&gt;;
    type PinningProcessEdges = UnsupportedProcessEdges&lt;Self::VM&gt;;
}
<span class="boring">}</span></code></pre></pre>
<p>Then we implement <code>schedule_collection()</code> using <code>MyGCWorkContext</code> and <code>schedule_common_work()</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn schedule_collection(&amp;'static self, scheduler: &amp;GCWorkScheduler&lt;VM&gt;) {
        scheduler.schedule_common_work::&lt;MyGCWorkContext&lt;VM&gt;&gt;(self);
    }
<span class="boring">}</span></code></pre></pre>
<p>Delete <code>handle_user_collection_request()</code>. This function was an override of
a Common plan function to ignore user requested collection for NoGC. Now we
remove it and allow user requested collection.</p>
<h2 id="prepare-for-collection"><a class="header" href="#prepare-for-collection">Prepare for collection</a></h2>
<p>The collector has a number of steps it needs to perform before each collection.
We'll add these now.</p>
<h3 id="prepare-plan"><a class="header" href="#prepare-plan">Prepare plan</a></h3>
<p>In <code>mygc/global.rs</code>, find the method <code>prepare</code>. Delete the <code>unreachable!()</code>
call, and add the following code:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn prepare(&amp;mut self, tls: VMWorkerThread) {
        self.common.prepare(tls, true);

        self.hi
            .store(!self.hi.load(Ordering::SeqCst), Ordering::SeqCst);
        // Flips 'hi' to flip space definitions
        let hi = self.hi.load(Ordering::SeqCst);
        self.copyspace0.prepare(hi);
        self.copyspace1.prepare(!hi);

        self.fromspace_mut()
            .set_copy_for_sft_trace(Some(CopySemantics::DefaultCopy));
        self.tospace_mut().set_copy_for_sft_trace(None);
    }
<span class="boring">}</span></code></pre></pre>
<p>This function is called at the start of a collection. It prepares the two
spaces in the common plan, flips the definitions for which space is 'to'
and which is 'from', then prepares the copyspaces with the new definition.</p>
<p>Note that we call <code>set_copy_for_sft_trace()</code> for both spaces. This step is required
when using <code>SFTProcessEdges</code> to tell the spaces which copy semantic to use for copying.
For fromspace, we use the <code>DefaultCopy</code> semantic, which we have defined earlier in our <code>CopyConfig</code>.
So for objects in fromspace that need to be copied, the policy will use the copy context that binds with
<code>DefaultCopy</code> (which allocates to the tospace) in the GC worker. For tospace, we set its
copy semantics to <code>None</code>, as we do not expect to copy objects from tospace, and if that ever happens,
we will simply panic.</p>
<h3 id="prepare-worker"><a class="header" href="#prepare-worker">Prepare worker</a></h3>
<p>As we flip tospace for the plan, we also need to rebind the copy context
to the new tospace. We will override <code>prepare_worker()</code> in our <code>Plan</code> implementation.
<code>Plan.prepare_worker()</code> is executed by each GC worker in the preparation phase of a GC. The code
is straightforward -- we get the first <code>CopySpaceCopyContext</code>, and call <code>rebind()</code> on it with
the new <code>tospace</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn prepare_worker(&amp;self, worker: &amp;mut GCWorker&lt;VM&gt;) {
        unsafe { worker.get_copy_context_mut().copy[0].assume_init_mut() }.rebind(self.tospace());
    }
<span class="boring">}</span></code></pre></pre>
<h3 id="prepare-mutator"><a class="header" href="#prepare-mutator">Prepare mutator</a></h3>
<p>Going back to <code>mutator.rs</code>, create a new function called
<code>mygc_mutator_prepare&lt;VM: VMBinding&gt;(_mutator: &amp;mut Mutator&lt;VM&gt;, _tls: VMWorkerThread)</code>.
This function will be called at the preparation stage of a collection (at the start of a
collection) for each mutator. Its body can stay empty, as there aren't any preparation steps for
the mutator in this GC.  In <code>create_mygc_mutator()</code>, find the field <code>prepare_func</code> and change it
from <code>&amp;unreachable_prepare_func</code> to <code>&amp;mygc_mutator_prepare</code>.</p>
<blockquote>
<p>💡 Hint: If your plan does nothing when preparing mutators, there is an optimization you can do.
You may set the plan constraints field <code>PlanConstraints::needs_prepare_mutator</code> to <code>false</code> so that
the <code>PrepareMutator</code> work packets which call <code>prepare_func</code> will not be created in the first place.
This optimization is helpful for VMs that run with a large number of mutator threads.  If you do
this optimization, you may also leave the <code>MutatorConfig::prepare_func</code> field as
<code>&amp;unreachable_prepare_func</code> to indicate it should not be called.</p>
</blockquote>
<h2 id="release"><a class="header" href="#release">Release</a></h2>
<p>Finally, we need to fill out the functions that are, roughly speaking,
run after each collection.</p>
<h3 id="release-in-plan"><a class="header" href="#release-in-plan">Release in plan</a></h3>
<p>Find the method <code>release()</code> in <code>mygc/global.rs</code>. Replace the
<code>unreachable!()</code> call with the following code.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn release(&amp;mut self, tls: VMWorkerThread) {
        self.common.release(tls, true);
        self.fromspace().release();
    }
<span class="boring">}</span></code></pre></pre>
<p>This function is called at the end of a collection. It calls the release
routines for the common plan spaces and the fromspace.</p>
<h3 id="release-in-mutator"><a class="header" href="#release-in-mutator">Release in mutator</a></h3>
<p>Go back to <code>mutator.rs</code>.  Create a new function called <code>mygc_mutator_release()</code> that takes the same
inputs as the <code>mygc_mutator_prepare()</code> function above.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn mygc_mutator_release&lt;VM: VMBinding&gt;(
    mutator: &amp;mut Mutator&lt;VM&gt;,
    _tls: VMWorkerThread,
) {
    // rebind the allocation bump pointer to the appropriate semispace
    let bump_allocator = unsafe {
        mutator
            .allocators
            .get_allocator_mut(mutator.config.allocator_mapping[AllocationSemantics::Default])
    }
    .downcast_mut::&lt;BumpAllocator&lt;VM&gt;&gt;()
    .unwrap();
    bump_allocator.rebind(
        mutator
            .plan
            .downcast_ref::&lt;MyGC&lt;VM&gt;&gt;()
            .unwrap()
            .tospace(),
    );
}
<span class="boring">}</span></code></pre></pre>
<p>Then go to <code>create_mygc_mutator()</code>, replace <code>&amp;unreachable_release_func</code> in the <code>release_func</code> field
with <code>&amp;mygc_mutator_release</code>.  This function will be called at the release stage of a collection
(at the end of a collection) for each mutator.  It rebinds the allocator for the <code>Default</code>
allocation semantics to the new tospace. When the mutator threads resume, any new allocations for
<code>Default</code> will then go to the new tospace.</p>
<h2 id="processedgeswork-for-mygc"><a class="header" href="#processedgeswork-for-mygc">ProcessEdgesWork for MyGC</a></h2>
<p><a href="https://docs.mmtk.io/api/mmtk/scheduler/gc_work/trait.ProcessEdgesWork.html"><code>ProcessEdgesWork</code></a>
is the key work packet for tracing objects in a GC. A <code>ProcessEdgesWork</code> implementation
defines how to trace objects, and how to generate more work packets based on the current tracing
to finish the object closure.</p>
<p><code>GCWorkContext</code> specifies a type
that implements <code>ProcessEdgesWork</code>, and we used <code>SFTProcessEdges</code> earlier. In
this section, we discuss what <code>SFTProcessEdges</code> does, and what the alternatives
are.</p>
<h3 id="approach-1-use-sftprocessedges"><a class="header" href="#approach-1-use-sftprocessedges">Approach 1: Use <code>SFTProcessEdges</code></a></h3>
<p><a href="https://docs.mmtk.io/api/mmtk/scheduler/gc_work/struct.SFTProcessEdges.html"><code>SFTProcessEdges</code></a> dispatches
the tracing of objects to their respective spaces through <a href="https://docs.mmtk.io/api/mmtk/policy/sft/trait.SFT.html">Space Function Table (SFT)</a>.
As long as all the policies in a plan provide an implementation of <code>sft_trace_object()</code> in their SFT implementations,
the plan can use <code>SFTProcessEdges</code>. Currently most policies provide an implementation for <code>sft_trace_object()</code>, except
mark compact and immix. Those two policies use multiple GC traces, and due to the limitation of SFT, SFT does not allow
multiple <code>sft_trace_object()</code> for a policy.</p>
<p><code>SFTProcessEdges</code> is the simplest approach when all the policies support it. Fortunately, we can use it for our GC, semispace.</p>
<h3 id="approach-2-derive-plantraceobject-and-use-planprocessedges"><a class="header" href="#approach-2-derive-plantraceobject-and-use-planprocessedges">Approach 2: Derive <code>PlanTraceObject</code> and use <code>PlanProcessEdges</code></a></h3>
<p><code>PlanProcessEdges</code> is another general <code>ProcessEdgesWork</code> implementation that can be used by most plans. When a plan
implements the <a href="https://docs.mmtk.io/api/mmtk/plan/global/trait.PlanTraceObject.html"><code>PlanTraceObject</code></a>,
it can use <code>PlanProcessEdges</code>.</p>
<p>You can manually provide an implementation of <code>PlanTraceObject</code> for <code>MyGC</code>. But you can also use the derive macro MMTK provides,
and the macro will generate an implementation of <code>PlanTraceObject</code>:</p>
<ul>
<li>Make sure <code>MyGC</code> already has the <code>#[derive(HasSpaces)]</code> attribute because all plans need to
implement the <code>HasSpaces</code> trait anyway.  (import the macro properly: <code>use mmtk_macros::HasSpaces</code>)</li>
<li>Add <code>#[derive(PlanTraceObject)]</code> for <code>MyGC</code> (import the macro properly: <code>use mmtk_macros::PlanTraceObject</code>)</li>
<li>Add both <code>#[space]</code> and <code>#[copy_semantics(CopySemantics::Default)]</code> to both copy space fields,
<code>copyspace0</code> and <code>copyspace1</code>. <code>#[space]</code> tells the macro that both <code>copyspace0</code> and <code>copyspace1</code>
are spaces in the <code>MyGC</code> plan, and the generated trace code will check both spaces.
<code>#[copy_semantics(CopySemantics::DefaultCopy)]</code> specifies the copy semantics to use when tracing
objects in the corresponding space.</li>
<li>Add <code>#[parent]</code> to <code>common</code>. This tells the macro that there are more spaces defined in <code>common</code>
and its nested structs.  If an object is not found in any space with <code>#[space]</code> in this plan,
the trace code will try to find the space for the object in the 'parent' plan.  In our case, the
trace code will proceed by checking spaces in the <code>CommonPlan</code>, as the object may be
in large object space or immortal space in the common plan. <code>CommonPlan</code> also implements <code>PlanTraceObject</code>, so it knows how to
find a space for the object and trace it in the same way.</li>
</ul>
<p>With the derive macro, your <code>MyGC</code> struct should look like this:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[derive(HasSpaces, PlanTraceObject)]
pub struct MyGC&lt;VM: VMBinding&gt; {
    pub hi: AtomicBool,
    #[space]
    #[copy_semantics(CopySemantics::DefaultCopy)]
    pub copyspace0: CopySpace&lt;VM&gt;,
    #[space]
    #[copy_semantics(CopySemantics::DefaultCopy)]
    pub copyspace1: CopySpace&lt;VM&gt;,
    #[parent]
    pub common: CommonPlan&lt;VM&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Once this is done, you can specify <code>PlanProcessEdges</code> as the <code>DefaultProcessEdges</code> in your GC work context:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crate::policy::gc_work::DEFAULT_TRACE;
use crate::scheduler::gc_work::PlanProcessEdges;
pub struct MyGCWorkContext2&lt;VM: VMBinding&gt;(std::marker::PhantomData&lt;VM&gt;);
impl&lt;VM: VMBinding&gt; crate::scheduler::GCWorkContext for MyGCWorkContext2&lt;VM&gt; {
    type VM = VM;
    type PlanType = MyGC&lt;VM&gt;;
    type DefaultProcessEdges = PlanProcessEdges&lt;Self::VM, MyGC&lt;VM&gt;, DEFAULT_TRACE&gt;;
    type PinningProcessEdges = UnsupportedProcessEdges&lt;Self::VM&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h3 id="approach-3-implement-your-own-processedgeswork"><a class="header" href="#approach-3-implement-your-own-processedgeswork">Approach 3: Implement your own <code>ProcessEdgesWork</code></a></h3>
<p>Apart from the two approaches above, you can always implement your own <code>ProcessEdgesWork</code>. This is
an overkill for simple plans like semi space, but might be necessary for more complex plans.
We discuss how to implement it for <code>MyGC</code>.</p>
<p>Create a struct <code>MyGCProcessEdges&lt;VM: VMBinding&gt;</code> in the <code>gc_work</code> module. It includes a reference
back to the plan, and a <code>ProcessEdgesBase</code> field:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MyGCProcessEdges&lt;VM: VMBinding&gt; {
    plan: &amp;'static MyGC&lt;VM&gt;,
    base: ProcessEdgesBase&lt;VM&gt;,
}
<span class="boring">}</span></code></pre></pre>
<p>Implement <code>ProcessEdgesWork</code> for <code>MyGCProcessEdges</code>. As most methods in the trait have a default
implemetation, we only need to implement <code>new()</code> and <code>trace_object()</code> for our plan. However, this
may not be true when you implement it for other GC plans. It would be better to check the default
implementation of <code>ProcessEdgesWork</code>.</p>
<p>For <code>trace_object()</code>, what we do is similar to the approach above (except that we need to write the code
ourselves rather than letting the macro to generate it for us). We try to figure out
which space the object is in, and invoke <code>trace_object()</code> for the object on that space. If the
object is not in any of the semi spaces in the plan, we forward the call to <code>CommonPlan</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;VM: VMBinding&gt; ProcessEdgesWork for MyGCProcessEdges&lt;VM&gt; {
    type VM = VM;
    type ScanObjectsWorkType = ScanObjects&lt;Self&gt;;

    fn new(
        slots: Vec&lt;SlotOf&lt;Self&gt;&gt;,
        roots: bool,
        mmtk: &amp;'static MMTK&lt;VM&gt;,
        bucket: WorkBucketStage,
    ) -&gt; Self {
        let base = ProcessEdgesBase::new(slots, roots, mmtk, bucket);
        let plan = base.plan().downcast_ref::&lt;MyGC&lt;VM&gt;&gt;().unwrap();
        Self { base, plan }
    }

    fn trace_object(&amp;mut self, object: ObjectReference) -&gt; ObjectReference {
        let worker = self.worker();
        let queue = &amp;mut self.base.nodes;
        if self.plan.tospace().in_space(object) {
            self.plan.tospace().trace_object(
                queue,
                object,
                Some(CopySemantics::DefaultCopy),
                worker,
            )
        } else if self.plan.fromspace().in_space(object) {
            self.plan.fromspace().trace_object(
                queue,
                object,
                Some(CopySemantics::DefaultCopy),
                worker,
            )
        } else {
            use crate::plan::PlanTraceObject;
            use crate::policy::gc_work::DEFAULT_TRACE;
            self.plan.common.trace_object::&lt;_, DEFAULT_TRACE&gt;(queue, object, worker)
        }
    }

    fn create_scan_work(&amp;self, nodes: Vec&lt;ObjectReference&gt;) -&gt; ScanObjects&lt;Self&gt; {
        ScanObjects::&lt;Self&gt;::new(nodes, false, self.bucket)
    }
}
<span class="boring">}</span></code></pre></pre>
<p>We would also need to implement <code>Deref</code> and <code>DerefMut</code> to our <code>ProcessEdgesWork</code> impl to be
dereferenced as <code>ProcessEdgesBase</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;VM: VMBinding&gt; Deref for MyGCProcessEdges&lt;VM&gt; {
    type Target = ProcessEdgesBase&lt;VM&gt;;
    fn deref(&amp;self) -&gt; &amp;Self::Target {
        &amp;self.base
    }
}

impl&lt;VM: VMBinding&gt; DerefMut for MyGCProcessEdges&lt;VM&gt; {
    fn deref_mut(&amp;mut self) -&gt; &amp;mut Self::Target {
        &amp;mut self.base
    }
}
<span class="boring">}</span></code></pre></pre>
<p>In the end, use <code>MyGCProcessEdges</code> as <code>DefaultProcessEdges</code> in the <code>GCWorkContext</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct MyGCWorkContext3&lt;VM: VMBinding&gt;(std::marker::PhantomData&lt;VM&gt;);
impl&lt;VM: VMBinding&gt; crate::scheduler::GCWorkContext for MyGCWorkContext3&lt;VM&gt; {
    type VM = VM;
    type PlanType = MyGC&lt;VM&gt;;
    type DefaultProcessEdges = MyGCProcessEdges&lt;Self::VM&gt;;
    type PinningProcessEdges = UnsupportedProcessEdges&lt;Self::VM&gt;;
}
<span class="boring">}</span></code></pre></pre>
<h2 id="summary"><a class="header" href="#summary">Summary</a></h2>
<p>You should now have MyGC working and able to collect garbage. All three
benchmarks should be able to pass now.</p>
<p>If the benchmarks pass - good job! You have built a functional copying
collector!</p>
<p>If you get particularly stuck, the code for the completed <code>MyGC</code> plan
is available <a href="https://github.com/mmtk/mmtk-core/tree/master/docs/userguide/src/tutorial/code/mygc_semispace">here</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="exercise-adding-another-copyspace"><a class="header" href="#exercise-adding-another-copyspace">Exercise: Adding another copyspace</a></h1>
<p>Now that you have a working semispace collector, you should be familiar
enough with the code to start writing some yourself. The intention of this
exercise is to reinforce the information from the semispace section, rather
than to create a useful new collector.</p>
<ol>
<li>Create a copy of your semispace collector, called <code>triplespace</code>.</li>
<li>Add a new copyspace to the collector, called the <code>youngspace</code>, with the
following traits:
<ul>
<li>New objects are allocated to the youngspace (rather than the fromspace).</li>
<li>During a collection, live objects in the youngspace are moved to the
tospace.</li>
<li>Garbage is still collected at the same time for all spaces.</li>
</ul>
</li>
</ol>
<p>Triplespace is a sort of generational garbage collector. These collectors
separate out old objects and new objects into separate spaces. Newly
allocated objects should be scanned far more often than old objects, which
minimises the time spent repeatedly re-scanning long-lived objects.</p>
<p>Of course, this means that the Triplespace is incredibly inefficient for a
generational collector, because the older objects are still being scanned
every collection. It wouldn't be very useful in a real-life scenario. The
next thing to do is to make this collector into a more efficient proper
generational collector.</p>
<p>When you are finished, try running the benchmarks and seeing how the
performance of this collector compares to MyGC. Great work!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="triplespace-backup-instructions"><a class="header" href="#triplespace-backup-instructions">Triplespace backup instructions</a></h1>
<p>This is <em>one</em> possible implementation of the Triplespace collector, provided
in case you are stuck on the exercise.</p>
<p><strong>Attempt the exercise yourself before reading this.</strong></p>
<p>First, rename all instances of <code>mygc</code> to <code>triplespace</code>, and add it as a
module by following the instructions in <a href="tutorial/mygc/ss/../create.html">Create MyGC</a>.</p>
<p>In <code>triplespace/global.rs</code>:</p>
<ol>
<li>
<p>Add a <code>youngspace</code> field to <code>pub struct TripleSpace</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct TripleSpace&lt;VM: VMBinding&gt; {
   pub hi: AtomicBool,
   pub copyspace0: CopySpace&lt;VM&gt;,
   pub copyspace1: CopySpace&lt;VM&gt;,
   pub youngspace: CopySpace&lt;VM&gt;, // Add this!
   pub common: CommonPlan&lt;VM&gt;,
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Define the parameters for the youngspace in <code>new()</code> in
<code>Plan for TripleSpace</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn new(
   vm_map: &amp;'static VMMap,
   mmapper: &amp;'static Mmapper,
   options: Arc&lt;UnsafeOptionsWrapper&gt;,
   _scheduler: &amp;'static MMTkScheduler&lt;Self::VM&gt;,
) -&gt; Self {
   //change - again, completely changed.
   let mut heap = HeapMeta::new(HEAP_START, HEAP_END);

   TripleSpace {
       hi: AtomicBool::new(false),
       copyspace0: CopySpace::new(
           "copyspace0",
           false,
           true,
           VMRequest::discontiguous(),
           vm_map,
           mmapper,
           &amp;mut heap,
       ),
       copyspace1: CopySpace::new(
           "copyspace1",
           true,
           true,
           VMRequest::discontiguous(),
           vm_map,
           mmapper,
           &amp;mut heap,
       ),

       // Add this!
       youngspace: CopySpace::new(
           "youngspace",
           true,
           true,
           VMRequest::discontiguous(),
           vm_map,
           mmapper,
           &amp;mut heap,
       ),
       common: CommonPlan::new(vm_map, mmapper, options, heap, &amp;TRIPLESPACE_CONSTRAINTS, &amp;[]),
   }
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Initialise the youngspace in <code>gc_init()</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span> fn gc_init(
    &amp;mut self,
    heap_size: usize,
    vm_map: &amp;'static VMMap,
    scheduler: &amp;Arc&lt;MMTkScheduler&lt;VM&gt;&gt;,
) {
    self.common.gc_init(heap_size, vm_map, scheduler);
    self.copyspace0.init(&amp;vm_map);
    self.copyspace1.init(&amp;vm_map);
    self.youngspace.init(&amp;vm_map); // Add this!
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Prepare the youngspace (as a fromspace) in <code>prepare()</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn prepare(&amp;self, tls: OpaquePointer) {
   self.common.prepare(tls, true);
   self.hi
       .store(!self.hi.load(Ordering::SeqCst), Ordering::SeqCst);
   let hi = self.hi.load(Ordering::SeqCst);
   self.copyspace0.prepare(hi);
   self.copyspace1.prepare(!hi);
   self.youngspace.prepare(true); // Add this!
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Release the youngspace in <code>release()</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn release(&amp;self, tls: OpaquePointer) {
   self.common.release(tls, true);
   self.fromspace().release();
   self.youngspace().release(); // Add this!
}
<span class="boring">}</span></code></pre></pre>
</li>
<li>
<p>Under the reference functions <code>tospace()</code> and <code>fromspace()</code>, add a similar
reference function <code>youngspace()</code>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn youngspace(&amp;self) -&gt; &amp;CopySpace&lt;VM&gt; {
   &amp;self.youngspace
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<p>In <code>mutator.rs</code>:</p>
<ol>
<li>Map a bump pointer to the youngspace (replacing the one mapped to the
tospace) in <code>space_mapping</code> in <code>create_triplespace_mutator()</code>:
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>space_mapping: box vec![
    (AllocatorSelector::BumpPointer(0), plan.youngspace()), // Change this!
    (
        AllocatorSelector::BumpPointer(1),
        plan.common.get_immortal(),
    ),
    (AllocatorSelector::LargeObject(0), plan.common.get_los()),
],
<span class="boring">}</span></code></pre></pre>
</li>
<li>Rebind the bump pointer to youngspace (rather than the tospace) in
<code>triplespace_mutator_release()</code>:
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub fn triplespace_mutator_release&lt;VM: VMBinding&gt; (
    mutator: &amp;mut Mutator&lt;VM&gt;,
    _tls: OpaquePointer
) {
    let bump_allocator = unsafe {
        mutator
            .allocators
            . get_allocator_mut(
                mutator.config.allocator_mapping[AllocationType::Default]
            )
        }
        .downcast_mut::&lt;BumpAllocator&lt;VM&gt;&gt;()
        .unwrap();
        bump_allocator.rebind(Some(mutator.plan.youngspace())); // Change this!
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<p>In <code>gc_work.rs</code>:</p>
<ol>
<li>Add the youngspace to trace_object, following the same format as
the tospace and fromspace:
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>    fn trace_object(&amp;mut self, object: ObjectReference) -&gt; ObjectReference {
        // Add this!
        else if self.plan().youngspace().in_space(object) {
            self.plan().youngspace.trace_object::&lt;Self, TripleSpaceCopyContext&lt;VM&gt;&gt;(
                self,
                object,
                super::global::ALLOC_TripleSpace,
                unsafe { self.worker().local::&lt;TripleSpaceCopyContext&lt;VM&gt;&gt;() },
            )
        }

        else if self.plan().tospace().in_space(object) {
            self.plan().tospace().trace_object::&lt;Self, TripleSpaceCopyContext&lt;VM&gt;&gt;(
                self,
                object,
                super::global::ALLOC_TripleSpace,
                unsafe { self.worker().local::&lt;MyGCCopyContext&lt;VM&gt;&gt;() },
            )
        } else if self.plan().fromspace().in_space(object) {
            self.plan().fromspace().trace_object::&lt;Self, MyGCCopyContext&lt;VM&gt;&gt;(
                self,
                object,
                super::global::ALLOC_TripleSpace,
                unsafe { self.worker().local::&lt;TripleSpaceCopyContext&lt;VM&gt;&gt;() },
            )
        } else {
            self.plan().common.trace_object::&lt;Self, TripleSpaceCopyContext&lt;VM&gt;&gt;(self, object)
        }
    }
}
<span class="boring">}</span></code></pre></pre>
</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-a-generational-copying-collector"><a class="header" href="#building-a-generational-copying-collector">Building a generational copying collector</a></h1>
<blockquote>
<p>Note: This part is work in progress.</p>
</blockquote>
<h2 id="what-is-a-generational-collector"><a class="header" href="#what-is-a-generational-collector">What is a generational collector?</a></h2>
<p>The <em>weak generational hypothesis</em> states that most of the objects allocated
to a heap after one collection will die before the next collection.
Therefore, it is worth separating out 'young' and 'old' objects and only
scanning each as needed, to minimise the number of times old live objects are
scanned. New objects are allocated to a 'nursery', and after one collection
they move to the 'mature' space. In <code>triplespace</code>, <code>youngspace</code> is a
proto-nursery, and the <code>tospace</code> and <code>fromspace</code> are the mature spaces.</p>
<p>This collector fixes one of the major problems with semispace - namely, that
any long-lived objects are repeatedly copied back and forth. By separating
these objects into a separate 'mature' space, the number of full heap
collections needed is greatly reduced.</p>
<p>This section is currently incomplete. Instructions for building a
generational copying (gencopy) collector will be added in future.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h1>
<ul>
<li><a href="https://docs.rs/crate/mmtk/latest">MMTk Crate Documentation</a></li>
<li>Original MMTk papers:
<ul>
<li><a href="https://www.mmtk.io/assets/pubs/mmtk-icse-2004.pdf"><em>Oil and Water? High Performance Garbage Collection in Java with MMTk</em></a> (Blackburn, Cheng, McKinley, 2004)</li>
<li><a href="https://www.mmtk.io/assets/pubs/mmtk-sigmetrics-2004.pdf"><em>Myths and realities: The performance impact of garbage collection</em></a> (Blackburn, Cheng, McKinley, 2004)</li>
</ul>
</li>
<li><a href="https://learning.oreilly.com/library/view/the-garbage-collection/9781315388007"><em>The Garbage Collection Handbook</em></a> (Jones, Hosking, Moss, 2016)</li>
<li>Videos: <a href="https://www.youtube.com/watch?v=3L6XEVaYAmU">MPLR 2020 Keynote</a>, <a href="https://www.youtube.com/watch?v=MAk6RdApGLs">Deconstructing the Garbage-First Collector</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="porting-guide"><a class="header" href="#porting-guide">Porting Guide</a></h1>
<blockquote>
<p>Note: This guide is work in progress.</p>
</blockquote>
<p>This guide is designed to get you started on porting MMTk to a new runtime.
We start with an overview of the MMTk approach to porting and then step through recommended strategies for implementing a port.</p>
<p>There’s no fixed way to implement a new port.
What we outline here is a distillation of best practices that have emerged from community as it has worked through many ports (each at various levels of maturity).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="overview-of-mmtks-approach-to-portability"><a class="header" href="#overview-of-mmtks-approach-to-portability">Overview of MMTk’s Approach to Portability</a></h1>
<p>MMTk is designed from the outset to be both high performance and portable.
The core of MMTk is entirely runtime-neutral, and is written in Rust.
Runtimes that wish to use MMTk may be written in any language so long as they have a means to call into MMTk’s API, which presents itself as a shared library.</p>
<p>MMTk uses the concept of <em>bindings</em> to create high performance impedance matching between runtimes and MMTk.</p>
<p>MMTk’s approach to portability follows these principles:</p>
<ol>
<li>The MMTk core must remain entirely runtime-agnostic and free of any runtime-specific code.</li>
<li>The runtime’s code base should be entirely garbage-collector agnostic and free of any MMTk-specific code.</li>
<li>The semantics of all MMTk functionality is strictly defined within the MMTk core.</li>
</ol>
<p>Those principles have the following important implications:</p>
<ul>
<li>Each port of a runtime is supported by a binding that has two components: one which is a logical extension of the runtime, written in the same language as the runtime, but which is MMTk-specific, and one which is a logical extension of MMTk, written in Rust, but which is runtime-specific (see diagram below).</li>
<li>A fully-correct but non-performant port will simply implement calls from the runtime to MMTk (to allocate an object, for example), and from MMTk to the runtime (to enumerate pointers, for example).</li>
<li>A performant port will likely replicate and lift MMTk functionality into the runtime portion of the port, and conversely replicate runtime functionality in Rust for performant access by MMTk.</li>
</ul>
<p><img src="portingguide/bindings.png" alt="A diagram with four boxes, left to right: OpenJDK, MMTk-specific mutator code, OpenJDK-specific MMTk code, MMTk" /></p>
<p>The diagram above illustrates a port of MMTk to OpenJDK with the binding in the center.
The code coloured brown is logically part of MMTk and is written in Rust.
The code coloured white is logically part of OpenJDK and is written in C++.
The rightmost box is entirely free of any OpenJDK-specific code.
The leftmost box should be entirely free of any MMTk-specific code.</p>
<blockquote>
<p>Note: we do currently maintain a fork of OpenJDK which includes some necessary changes to their code base, but this is not MMTk-specific and ideally this will be upstreamed.  Our port to V8 is a cleaner example, where we’ve managed to work closely with the V8 team to upstream all of the refactoring of the V8 code base that was necessary for it to support a third party heap.</p>
</blockquote>
<p>We structure the code into three repos. Taking the example of the OpenJDK port, the three repos are: the <a href="https://github.com/mmtk/mmtk-core">MMTk core</a>, the <a href="https://github.com/mmtk/mmtk-openjdk">binding repo</a> containing both parts of the binding, and the OpenJDK repo, which is currently <a href="https://github.com/mmtk/openjdk">a fork</a> we maintain.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="things-to-consider-before-starting-a-port"><a class="header" href="#things-to-consider-before-starting-a-port">Things to Consider Before Starting a Port</a></h1>
<p>In principle, a port to MMTk is not particularly difficult.
MMTk can present itself as a standard library and the core of the API is relatively simple.</p>
<p>However, porting a runtime to a different GC (any GC) can be difficult and time consuming.
Key questions include:</p>
<ul>
<li>How well encapsulated is the runtime's existing collector?</li>
<li>Does the runtime make tacit assumptions about the underlying collector's implementation?</li>
<li>How many places in the runtime codebase reference some part of the GC?</li>
<li>If the runtime has a JIT, how good is the interface between the JIT and the GC (for write barriers and allocations, for example)?</li>
<li>Does the runtime support precise stack scanning?</li>
<li>etc.</li>
</ul>
<p>Thinking through these questions should give you a sense for how big a task a GC port will be.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="how-to-undertake-a-port"><a class="header" href="#how-to-undertake-a-port">How to Undertake a Port</a></h1>
<p>We recommend a highly incremental approach to implementing a port.   The broad idea is:</p>
<ul>
<li>Start with the NoGC plan and gradually move to more advanced collectors</li>
<li>Focus on simplicity and correctness.</li>
<li>Optimize the port later.</li>
</ul>
<p>In MMTk’s language, a plan is essentially a configuration which specifies a GC algorithm.
Plans can be selected at run time.
Not all plans will be suitable for all runtimes.
For example, a runtime that for some reason cannot support object movement won’t be able to use plans that use copying garbage collection.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="starting-a-port-nogc"><a class="header" href="#starting-a-port-nogc">Starting a Port: NoGC</a></h1>
<p>We always start a port with NoGC. It is the simplest possible plan: it simply allocates memory and never collects.
Although this appears trivial, depending on the complexity of the runtime and how well factored (or not) its internal GC interfaces are, just getting this working may be a major undertaking.
In the case of V8, the refactoring within V8 required to get a simple NoGC plan working was substantial, touching over 100 files. So it’s a good idea not to underestimate the difficulty of a NoGC port!</p>
<p>At a high level, in order to implement NoGC, we need to handle MMTk initialization, mutator initialization, and memory allocation.</p>
<p>If you're ever stuck at any point, feel free to send a message in the <code>#Porting</code> channel of our <a href="https://mmtk.zulipchat.com/">Zulip</a>!</p>
<h2 id="set-up"><a class="header" href="#set-up">Set up</a></h2>
<p>You want to set up the binding repository/directory structure before starting the port. For the sake of the tutorial guide we assume you have a directory structure similar to the one below. Note that such a directory structure is not a requirement<sup class="footnote-reference"><a href="#1">1</a></sup> but a recommendation. We assume you are using some form of version control system (such as <code>git</code> or <code>mercurial</code>) in this guide.</p>
<div class="footnote-definition" id="1"><sup class="footnote-definition-label">1</sup>
<p>In fact some bindings may not be able to have such a directory structure due to the build tools used by the runtime.</p>
</div>
<ul>
<li><code>mmtk-X/mmtk</code>: The MMTk side of the binding. This includes the implementation of <a href="https://docs.mmtk.io/api/mmtk/vm/trait.VMBinding.html">the <code>VMBinding</code> trait</a>,
and any necessary Rust code to integrate MMTk with the VM code (e.g. exposing MMTk functions to native, allowing up-calls from the MMTk binding to the runtime, etc).
To start with, you can copy <a href="https://github.com/mmtk/mmtk-core/tree/master/docs/dummyvm">the <code>DummyVM</code></a> code and start from there.
<code>DummyVM</code> provides all the Rust boilerplates that you need to implement in the binding side.
You can also take a look at one of our officially maintained language bindings as an example: <a href="https://github.com/mmtk/mmtk-openjdk/tree/master/mmtk">OpenJDK</a>,
<a href="https://github.com/mmtk/mmtk-jikesrvm/tree/master/mmtk">JikesRVM</a>, <a href="https://github.com/mmtk/mmtk-v8/tree/master/mmtk">V8</a>, <a href="https://github.com/mmtk/mmtk-julia/tree/master/mmtk">Julia</a>,
<a href="https://github.com/mmtk/mmtk-v8/tree/master/mmtk">V8</a>.</li>
<li><code>mmtk-X/X</code>: Runtime-specific code for integrating with MMTk. This should act as a bridge between the generic GC interface offered by the runtime and the MMTk side of the binding. This is implemented in the runtime's implementation language. Often this will be one of C or C++.</li>
<li>You can place your runtime repository at any path. For the sake of this guide, we assume you will place the runtime repo as a sibling of the binding repo. You can also clone <code>mmtk-core</code> to a local path. Using a local repo of <code>mmtk-core</code> can be beneficial to your development in case you need to make certain changes to the core (though this is unlikely).</li>
</ul>
<p>Your working directory may look like this (assuming your runtime is named as <code>X</code>):</p>
<pre><code>Your working directory/
├─ mmtk-X/
│  ├─ X/
│  └─ mmtk/
├─ X/
└─ mmtk-core/ (optional)
</code></pre>
<p>You may also find it helpful to take inspiration from the <a href="https://github.com/mmtk/mmtk-openjdk">OpenJDK binding</a>, particularly for a more complete example of the relevant <code>Cargo.toml</code> files.</p>
<p>For this guide, we will assume your runtime is implemented in C or C++ as they are the most common implementation languages. However note that your runtime does not <em>need</em> to be implemented in C/C++ to work with MMTk.</p>
<h2 id="adding-a-rust-library-to-the-runtime"><a class="header" href="#adding-a-rust-library-to-the-runtime">Adding a Rust library to the runtime</a></h2>
<p>We recommend learning the ins and outs of your runtime's build system. You should try and add a simple Rust "hello world" library to your runtime's code and build system to investigate how easy it will be to add MMTk. Unfortunately this step is highly dependent on the runtime build system. We recommend taking a look at what other bindings do, but keep in mind that no two runtime build systems are the same even if they are using the same build tools.</p>
<p>In case the build system is too complex and you want get to hacking, a quick and dirty way to add MMTk could be to build a static and/or dynamic binary for MMTk and link it to the runtime directly, manually building new binaries as necessary, like so:</p>
<ol>
<li><code>cd mmtk-X/mmtk</code></li>
<li><code>cargo build</code> to build in debug mode or add <code>--release</code> for release mode</li>
<li>Copy the shared or static<sup class="footnote-reference"><a href="#2">2</a></sup> library from <code>target/debug</code> or <code>target/release</code> to your desired location</li>
</ol>
<div class="footnote-definition" id="2"><sup class="footnote-definition-label">2</sup>
<p>You would have to change the <code>crate-type</code> in <code>mmtk-X/mmtk/Cargo.toml</code> from <code>cdylib</code> to <code>staticlib</code> to build a static library.</p>
</div>
<p>Later, you can edit the runtime build process to build MMTk at the same time automatically.</p>
<p><strong>Note:</strong> If the runtime you are targeting already links some Rust FFI libraries, then you may notice "multiple definition" linker errors for Rust stdlib functions. Unfortunately this is a current limitation of Rust FFI wherein all symbols are bundled together in the final C lib which will cause multiple definitions errors when two or more Rust FFI libraries are linked together. There is ongoing work to stabilize the Rust package format that would hopefully make it easier in the future. A current workaround would be to use the <code>-Wl,--allow-multiple-definition</code> linker flag, but this unfortunately isn't ideal as it increases code sizes. See <a href="https://internals.rust-lang.org/t/pre-rfc-stabilize-a-version-of-the-rlib-format/17558">here</a> and <a href="https://github.com/rust-lang/rust/issues/73632">here</a> for more details.</p>
<p><strong>Note:</strong> It is <em>highly</em> recommended to also check-in the generated <code>Cargo.lock</code> file into your version control. This improves the reproducibility of the build and ensures the same package versions are used when building in the future in order to prevent random breakages.</p>
<p>We recommend using the <code>debug</code> build when doing development work as it has helpful logging statements and assertions that will make catching bugs in your implementation easier.</p>
<h2 id="the-vmbinding-trait"><a class="header" href="#the-vmbinding-trait">The <code>VMBinding</code> trait</a></h2>
<p>Now let's actually start implementing the binding. Here we take a look at the Rust side of the binding first (i.e. <code>mmtk-X/mmtk</code>). What we want to do is implement the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.VMBinding.html"><code>VMBinding</code></a> trait.</p>
<p>The <code>VMBinding</code> trait is a "meta-trait" (i.e. a trait that encapsulates other traits) that we expect every binding to implement. In essence, it is the contract established between MMTk and the runtime. We discuss each of its seven key traits briefly:</p>
<ol>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/trait.ActivePlan.html"><code>ActivePlan</code></a>: This trait implements functions related to mutators such as how many mutators exist, getting an iterator for all mutators, etc.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/trait.Collection.html"><code>Collection</code></a>: This trait implements functions related to garbage collection such as starting and stopping mutators, blocking current mutator thread for GC, etc.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/trait.ObjectModel.html"><code>ObjectModel</code></a>: This trait implements the runtime's object model. The object model includes object metadata such as mark-bits, forwarding-bits, etc.; constants regarding assumptions about object addresses; and functions to implement copying objects, querying object sizes, etc. You should <em><strong>carefully</strong></em> implement and understand this as it is a key trait on which many things depend. We will go into more detail about this trait in the <a href="portingguide/howto/nogc.html#object-model">object model section</a>.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/trait.ReferenceGlue.html"><code>ReferenceGlue</code></a>: This trait implements runtime-specific finalization and weak reference processing methods. Note that each runtime has its own way of dealing with finalization and reference processing, so this is often one of the trickiest traits to implement.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/trait.Scanning.html"><code>Scanning</code></a>: This trait implements object scanning functions such as scanning mutator threads for root pointers, scanning a particular object for reference fields, etc.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/slot/trait.Slot.html"><code>Slot</code></a>: This trait implements a slot in an object, on the stack or other places (such as global variables). If a slot in your runtime simply holds the address of an object (or 0 for NULL references), you may use the <a href="https://docs.mmtk.io/api/mmtk/vm/slot/struct.SimpleSlot.html"><code>SimpleSlot</code></a> type. But if your VM uses tagged pointers or compressed pointers, you will need to implement it manually.</li>
<li><a href="https://docs.mmtk.io/api/mmtk/vm/slot/trait.MemorySlice.html"><code>MemorySlice</code></a>: This trait implements functions related to memory slices such as arrays. This is mainly used by generational collectors.</li>
</ol>
<p>For the time-being we can implement all the above traits via <code>unimplemented!()</code> stubs. If you are using the Dummy VM binding as a starting point, you will have to edit some of the concrete implementations to <code>unimplemented!()</code>. Note that you should change the type that implements <code>VMBinding</code> from <code>DummyVM</code> to an appropriately named type for your runtime. For example, the OpenJDK binding defines the zero-struct <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/lib.rs#L139-L162"><code>OpenJDK</code></a> which implements the <code>VMBinding</code> trait.</p>
<h3 id="object-model"><a class="header" href="#object-model">Object model</a></h3>
<p>The <code>ObjectModel</code> trait is a fundamental trait describing the layout of an object to MMTk. This is important as MMTk's core doesn't know of how objects look like internally as each runtime will be different. There are certain key aspects you need to be aware of while implementing the <code>ObjectModel</code> trait. We discuss them in this section.</p>
<h4 id="header-vs-side-metadata"><a class="header" href="#header-vs-side-metadata">Header vs Side metadata</a></h4>
<p>Per-object metadata can live in one of two places: in the object header or in a separate space used just for metadata. Each one has its pros and cons.</p>
<p>Header metadata sits in close proximity to the actual object address but it is not easy to perform bulk operations. On the other hand, side metadata sits in a dedicated metadata space where each possible object address is assigned some metadata. This makes performing bulk operations easy and does not require stealing bits from the object header (there may in fact be no bits to steal for certain runtimes), but can result in large heap sizes given the metadata space is counted as part of the heap.</p>
<p>The choice of metadata location depends on the runtime and its object model and header layout. For example the JikesRVM runtime reserved extra space at the start of each object for GC-related metadata. Such space may not be available in your runtime. In such cases you can use side metadata to reserve per-object metadata.</p>
<h4 id="local-vs-global-metadata"><a class="header" href="#local-vs-global-metadata">Local vs Global metadata</a></h4>
<p>MMTk uses multiple GC policies and each policy may use a different set of object metadata from each other. A moving policy, for example, may require extra metadata (in comparison to a non-moving policy) to store the forwarding bits and forwarding pointer. Such a metadata, which is local to a policy, is referred to as "local" metadata.</p>
<p>However, in certain cases, we may need to have metadata globally for the entire heap space. The classic example is the valid-object bit metadata which tells us if an arbitrary address is allocated/managed by MMTk. Such a metadata, which spans multiple policies, is referred to as "global" metadata.</p>
<p>For example, the <em>Forwarding bits and pointer</em> metadata is a local metadata used by copying policies to store forwarding bits (2-bits) and forwarding pointers (word size). Often runtimes require word-aligned addresses which means we can use the last two bits in the object header (due to alignment) and the entire object header to store the forwarding bits and pointer respectively. This metadata is almost always in the header.</p>
<p>We recommend going through the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.ObjectModel.html#required-associated-consts">list of metadata specifications</a> that are defined by MMTk. You should set them to locations that are appropriate for your runtime.</p>
<h4 id="objectreference-vs-address"><a class="header" href="#objectreference-vs-address"><code>ObjectReference</code> vs <code>Address</code></a></h4>
<p>A key principle in MMTk is the distinction between <a href="https://docs.mmtk.io/api/mmtk/util/address/struct.ObjectReference.html"><code>ObjectReference</code></a> and <a href="https://docs.mmtk.io/api/mmtk/util/address/struct.Address.html"><code>Address</code></a>. The idea is that very few operations are allowed on an <code>ObjectReference</code>. For example, MMTk does not allow address arithmetic on <code>ObjectReference</code>s. This allows us to preserve memory-safety, only performing unsafe operations when required, and gives us a cleaner and more flexible abstraction to work with as it can allow object handles or offsets etc. <code>Address</code>, on the other hand, represents an arbitrary machine address. You might be interested in reading the <a href="https://users.cecs.anu.edu.au/~steveb/pubs/papers/vmmagic-vee-2009.pdf"><em>Demystifying Magic: High-level Low-level Programming</em></a> paper which describes the above in more detail.</p>
<p>In MMTk, <code>ObjectReference</code> is a special address that represents an object.  It is required to be
within the address range of the object it refers to, and must be word-aligned.  This address is used
by MMTk to access side metadata, and find the space or regions (chunk, block, line, etc.) that
contains the object.  It must also be efficient to locate the object header (where in-header MMTk
metadata are held) and the object's VM-specific metadata, such as type information, from a given
<code>ObjectReference</code>.  MMTk will need to access those information, either directly or indirectly via
traits implemented by the binding, during tracing, which is performance-critical.</p>
<p>The address used as <code>ObjectReference</code> is nominated by the VM binding when an object is allocated (or
moved by a moving GC, which we can ignore for now when supporting NoGC).  VMs usually have their own
concepts of "object reference" which refer to objects.  Some of them, including OpenJDK and CRuby,
uses addresses to the object (the starting address or at an offset within the object) to refer to an
object.  Such VMs can directly use their "object reference" for the address of MMTk's
<code>ObjectReference</code>.</p>
<p>Some VMs, such as JikesRVM, refers to an object by an address at a constant offset after the header,
and can be outside the object.  This does not satisfy the requirement of MMTk's <code>ObjectReference</code>,
and the VM binding needs to make a clear distinction between the VM-level object reference and
MMTk's <code>ObjectReference</code> type.  A detailed example for supporting such a VM can be found
<a href="https://github.com/mmtk/mmtk-jikesrvm/issues/178">here</a>.</p>
<p>Other VMs may use tagged references, compressed pointers, etc.  They need to convert them to plain
addresses to be used as MMTk's <code>ObjectReference</code>.  Specifically, if the VM use such representations
in object fields, the VM binding can deal with the encoding and the decoding in its
<a href="https://docs.mmtk.io/api/mmtk/vm/slot/trait.Slot.html"><code>Slot</code></a> implementation, and always present plain <code>ObjectReference</code>s to MMTk. See [this
test] for some <code>Slot</code> implementation examples.</p>
<h4 id="miscellaneous-configuration-options"><a class="header" href="#miscellaneous-configuration-options">Miscellaneous configuration options</a></h4>
<p>There are many constants in the <code>ObjectModel</code> trait that can be overridden in your binding in order to meet your runtime's requirements. For example, the <code>OBJECT_REF_OFFSET_LOWER_BOUND</code> constant which defines the minimum offset from allocation result start (i.e. the address that MMTk will return to the runtime) and the actual start of the object, i.e. the <code>ObjectReference</code>. In other words, the constant represents the minimum offset from the allocation result start such that the following invariant always holds:</p>
<pre><code>OBJECT_REFERENCE &gt;= ALLOCATION_RESULT_START + OFFSET
</code></pre>
<p>We recommend going through the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.ObjectModel.html">list of constants in the documentation</a> and seeing if the default values suit your runtime's semantics, changing them if required.</p>
<h2 id="mmtk-initialization"><a class="header" href="#mmtk-initialization">MMTk initialization</a></h2>
<p>Now that we have most of the boilerplate set up, the next step is to initialize MMTk so that we can start allocating objects.</p>
<p>In short, MMTk uses the builder pattern. The binding needs to create an <a href="https://docs.mmtk.io/api/mmtk/struct.MMTKBuilder.html"><code>MMTKBuilder</code></a>,
create an <a href="https://docs.mmtk.io/api/mmtk/mmtk/struct.MMTK.html"><code>MMTK</code></a> instance from the builder, and then initialize MMTk's collection
when the runtime system is ready for GCs.
The following steps describes details. In an actual binding implementation, the binding may choose to combine several
steps into one function call to make things simpler.</p>
<ol>
<li>Create an <code>MMTKBuilder</code> using <a href="https://docs.mmtk.io/api/mmtk/struct.MMTKBuilder.html#method.new"><code>MMTKBuilder::new()</code></a>. You can set
runtime options via <a href="https://docs.mmtk.io/api/mmtk/struct.MMTKBuilder.html#method.set_option"><code>set_option()</code></a> for things like
the GC plan to use, heap sizes, etc. This is <a href="https://docs.mmtk.io/api/mmtk/util/options/struct.Options.html">a full list of runtime options</a>.
You can also set options by directly accessing the <code>options</code> in the builder, such as <code>builder.options.threads.set(4)</code>.
It is a common practice that the VM parses its command line arguments, then sets some GC-related options
to MMTk here. You can also set virtual memory layout for MMTk. Some runtimes may require special layouts, such as using compressed pointers
with a fixed heap range. However, both setting options and VM layouts are optional -- MMTk will use the default values if none is set.</li>
<li>Create an <code>MMTK</code> instance via <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.mmtk_init.html"><code>memory_manager::mmtk_init()</code></a>. This
enables the binding to use most of the MMTk APIs in <a href="https://docs.mmtk.io/api/mmtk/memory_manager/index.html"><code>memory_manager</code></a>, as most
APIs require a reference to <code>MMTK</code>.</li>
<li>When the runtime is ready for GCs (including getting its thread system ready to spawn GC threads), it is expected to call <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.initialize_collection.html"><code>memory_manager::initialize_collection</code></a>. Once the function returns, MMTk may trigger a GC at any appropriate time.
In terms of getting NoGC to work, this step is optional, as NoGC will not trigger GCs.</li>
</ol>
<p>In practice, it greatly depends on the runtime about how to expose the MMTk's Rust API above to native, and when to call the native API in the runtime.
In the following example, we assume a <code>MMTKBuilder</code> is created statically (Step 1), and expects a call from the runtime to set heap sizes to the builder
via <code>mmtk_set_heap_size()</code>. We will create an <code>MMTK</code> instance from the builder in <code>mmtk_init()</code> (Step 2). Step 3 is omitted, as we do not need it for NoGC.</p>
<h3 id="runtime-side-changes"><a class="header" href="#runtime-side-changes">Runtime-side changes</a></h3>
<p>Create a <code>mmtk.h</code> header file in the runtime folder of the binding (i.e. <code>mmtk-X/X</code>) which exposes the functions required to implement NoGC and <code>#include</code> it in the relevant runtime code. You can use the <a href="https://github.com/mmtk/mmtk-core/blob/master/docs/dummyvm/include/mmtk.h">example <code>mmtk.h</code> header file</a> as an example.</p>
<p><strong>Note:</strong> It is convention to prefix all MMTk API functions exposed with <code>mmtk_</code> in order to avoid name clashes. It is <em>highly</em> recommended that you follow this convention.</p>
<p>Having a clean heap API for MMTk to implement makes life easier. Some runtimes may already have a sufficiently clean abstraction such as OpenJDK after the merging of <a href="https://openjdk.org/jeps/304">JEP 304</a>. In (most) other cases, the runtime doesn't provide a clean enough heap API for MMTk to implement. In such cases, it is recommended to create a class (or equivalent) that abstracts allocation and other heap functions like what the <a href="https://chromium.googlesource.com/v8/v8/+/a9976e160f4755990ec065d4b077c9401340c8fb/src/heap/third-party/heap-api.h">V8</a> and ART bindings do. This allows making minimal changes to the actual runtime and having a concrete implementation of the exposed heap API in the binding, reducing MMTk-specific code in the runtime. Ideally these changes are upstreamed like in the case of V8.</p>
<p>It is also recommended that any change you do in the runtime be guarded by build-time flags as it helps in maintaining a clean port.</p>
<p>At this step, your <code>mmtk.h</code> file may look something like this:</p>
<pre><code class="language-C">#ifndef MMTK_H
#define MMTK_H

#include &lt;stddef.h&gt;
#include &lt;sys/types.h&gt;

// The extern "C" is only required if the runtime
// implementation language is C++
extern "C" {

// An arbitrary address
typedef void* Address;
// MmtkMutator should be an opaque pointer for the VM
typedef void* MmtkMutator;
// An opaque pointer to a VMThread
typedef void* VMThread;

/**
 * Initialize MMTk instance
 */
void mmtk_init();

/**
 * Set the heap size
 *
 * @param min minimum heap size
 * @param max maximum heap size
 */
void mmtk_set_heap_size(size_t min, size_t max);

} // extern "C"

#endif // MMTK_H
</code></pre>
<p>Now we can initialize MMTk in the runtime. Note that MMTk should ideally be initialized around when the default heap of the runtime is initialized. You will have to figure out where is the best location to initialize MMTk in your runtime.</p>
<p>Initializing MMTk requires two steps. First, we set the heap size by calling <code>mmtk_set_heap_size</code> with the initial heap size and the maximum heap size. Then, we initialize MMTk by calling <code>mmtk_init</code>. In the future, you may wish to make the heap size configurable via a command line argument or environment variable (See <a href="portingguide/howto/nogc.html#setting-options-for-mmtk">setting options for MMTk</a>).</p>
<!-- You may have noticed the `mmtk_initialize_collection` function defined above in the `mmtk.h` file. This function is called after the runtime has completely set up including (but not limited to) its thread system. This function will spawn GC threads and allow MMTk to collect objects. For the time-being we can ignore calling this function as NoGC does not collect objects so does not require calling `mmtk_initialize_collection`. -->
<h3 id="mmtk-side-changes"><a class="header" href="#mmtk-side-changes">MMTk-side changes</a></h3>
<p>On the Rust side of the binding, we want to implement the two functions exposed by the <code>mmtk.h</code> file above. We use an <a href="https://docs.mmtk.io/api/mmtk/struct.MMTKBuilder.html"><code>MMTKBuilder</code></a> instance to actually create our concrete <a href="https://docs.mmtk.io/api/mmtk/struct.MMTK.html"><code>MMTK</code></a> instance. We recommend following the paradigm used by all our bindings wherein we have a <code>static</code> single <code>MMTK</code> instance and an <code>MMTKBuilder</code> instance that we can use to set relevant options. See the <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/lib.rs#L169-L178">OpenJDK binding</a> for an example.</p>
<p><strong>Note:</strong> MMTk currently assumes that there is only one <code>MMTK</code> instance in your runtime process. Multiple <code>MMTK</code> instances are currently not supported.</p>
<p>The <code>mmtk_set_heap_size</code> function is fairly straightforward. We recommend using the implementation in the <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L94-L104">OpenJDK binding</a>. The <code>mmtk_init</code> function is straightforward as well. It should simply manually initialize the <code>MMTK</code> <code>static</code> variable using <code>lazy_static</code>, like <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L83-L86">here</a> in the OpenJDK binding.</p>
<p>By this point, you should have MMTk initialized. If you are using a debug build (which is recommended) and have logging turned on a message similar to below would be printed out:</p>
<pre><code>[...]
[INFO  mmtk::memory_manager] Initialized MMTk with NoGC (FixedHeapSize(10485760))
[...]
</code></pre>
<h2 id="binding-mutator-threads-to-mmtk"><a class="header" href="#binding-mutator-threads-to-mmtk">Binding mutator threads to MMTk</a></h2>
<p>For MMTk to allocate objects, it needs to be aware of mutator threads. MMTk only allows mutator threads to allocate objects. We do this by "binding" a mutator thread to MMTk when it is initialized in the runtime.</p>
<h3 id="runtime-side-changes-1"><a class="header" href="#runtime-side-changes-1">Runtime-side changes</a></h3>
<p>Add the following function to the <code>mmtk.h</code> file:</p>
<pre><code class="language-C">[...]

/**
 * Bind a mutator thread in MMTk
 *
 * @param tls pointer to mutator thread
 * @return an instance of an MMTk mutator
 */
MmtkMutator mmtk_bind_mutator(VMThread tls);

[...]
</code></pre>
<p>The <code>mmtk_bind_mutator</code> function takes in an opaque pointer representing an instance of the runtime's mutator thread and returns an opaque pointer to a <a href="https://docs.mmtk.io/api/mmtk/plan/struct.Mutator.html"><code>Mutator</code></a> instance back to the runtime. The runtime <em><strong>must</strong></em> store this pointer somewhere, preferably in its runtime thread local storage implementation, as MMTk requires a <code>Mutator</code> instance to allocate and perform other actions.</p>
<p>The placement of the <code>mmtk_bind_mutator</code> call in the runtime depends on the runtime's implementation of its thread system. It is recommended to call <code>mmtk_bind_mutator</code> when the runtime initializes the thread local storage of a newly created thread. This ensures that the thread can allocate from MMTk immediately after initialization.</p>
<h3 id="mmtk-side-changes-1"><a class="header" href="#mmtk-side-changes-1">MMTk-side changes</a></h3>
<p>The Rust side of the binding should simply defer the actual implementation to <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.bind_mutator.html"><code>mmtk::memory_manager::bind_mutator</code></a>. See the <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L106-L109">OpenJDK binding</a> for an example.</p>
<h2 id="allocation"><a class="header" href="#allocation">Allocation</a></h2>
<p>Now we can finally implement the allocation functions.</p>
<h3 id="runtime-side-changes-2"><a class="header" href="#runtime-side-changes-2">Runtime-side changes</a></h3>
<p>Add the following two functions to the <code>mmtk.h</code> file:</p>
<pre><code class="language-C">[...]

/**
 * Allocate an object
 *
 * @param mutator the mutator instance that is requesting the allocation
 * @param size the size of the requested object
 * @param align the alignment requirement for the object
 * @param offset the allocation offset for the object
 * @param allocator the allocation semantics to use for the allocation
 * @return the address of the newly allocated object
 */
void *mmtk_alloc(MmtkMutator mutator, size_t size, size_t align,
        ssize_t offset, int allocator);

/**
 * Set relevant object metadata
 *
 * @param mutator the mutator instance that is requesting the allocation
 * @param object the ObjectReference address chosen by the VM binding
 * @param size the size of the allocated object
 * @param allocator the allocation semantics to use for the allocation
 */
void mmtk_post_alloc(MmtkMutator mutator, void* object, size_t size, int allocator);

[...]
</code></pre>
<p>In order to perform allocations, you will need to know what object alignment the runtime expects. Runtimes often align allocations at word boundaries (i.e. 4- or 8-bytes) as it allows the CPU to access the data faster at execution time. Additionally, the runtime may use the unused lowest order bits to store flags (e.g. type information), so it is important that MMTk respects these expectations. Once you have figured out the alignment requirements for your runtime, you should update the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.VMBinding.html#associatedconstant.MIN_ALIGNMENT"><code>MIN_ALIGNMENT</code></a> constant in <code>VMBinding</code> to the correct value.</p>
<p>Now that MMTk is aware of each mutator thread, you have to change the runtime's allocation functions to call into MMTk to allocate using <code>mmtk_alloc</code> and set object metadata using <code>mmtk_post_alloc</code>. Note that there may be multiple allocation functions in the runtime so make sure that you edit them all!</p>
<p>When calling <code>mmtk_alloc</code>, you should use the saved <code>Mutator</code> pointer as the first parameter, the requested object size as the next parameter, and any alignment requirements the runtimes has as the third parameter.</p>
<p>If your runtime requires a non-zero allocation offset (i.e. the alignment requirements are for the offset address, not the returned address) then you have to provide the required value as the fourth parameter. Note that you <em><strong>must</strong></em> also update the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.VMBinding.html#associatedconstant.USE_ALLOCATION_OFFSET"><code>USE_ALLOCATION_OFFSET</code></a> constant in the <code>VMBinding</code> implementation if your runtime requires a non-zero allocation offset.</p>
<p>For the time-being, you can ignore the <code>allocator</code> parameter in both these functions and always pass a value of <code>0</code> which means MMTk will pick the default allocator for your collector (a bump pointer allocator in the case of NoGC).</p>
<p>The return value of <code>mmtk_alloc</code> is the starting address of the allocated object.</p>
<p>Then you should nominate a word-aligned address within the allocated bytes to be the
<code>ObjectReference</code> used to refer to that object from now on.  It doesn't have to be the starting
address.</p>
<p>Finally, you need to call <code>mmtk_post_alloc</code> with your chosen <code>ObjectReference</code> in order to
initialize MMTk-level object metadata, such as logging bits, valid-object (VO) bits, etc.  As a VM
binding developer, you can ignore the details for now.</p>
<p><strong>Note:</strong> Currently MMTk assumes object sizes are multiples of the <code>MIN_ALIGNMENT</code>. If you encounter errors with alignment, a simple workaround would be to align the requested object size up to the <code>MIN_ALIGNMENT</code>. See <a href="https://github.com/mmtk/mmtk-core/issues/730">here</a> for the tracking issue to fix this bug.</p>
<h3 id="mmtk-side-changes-2"><a class="header" href="#mmtk-side-changes-2">MMTk-side changes</a></h3>
<p>The Rust side of the binding should simply defer the actual implementation to <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.alloc.html"><code>mmtk::memory_manager::alloc</code></a> and <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.post_alloc.html"><code>mmtk::memory_manager::post_alloc</code></a> respectively. See the <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L125-L136">OpenJDK</a> <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L151-L161">binding</a> for an example.</p>
<p>Congratulations! At this point, you hopefully have object allocation working and can run simple programs with your runtime using MMTk!</p>
<h2 id="miscellaneous-implementation-steps"><a class="header" href="#miscellaneous-implementation-steps">Miscellaneous implementation steps</a></h2>
<h3 id="setting-options-for-mmtk"><a class="header" href="#setting-options-for-mmtk">Setting options for MMTk</a></h3>
<p>The preferred method of setting <a href="https://docs.mmtk.io/api/mmtk/util/options/index.html">options for MMTk</a> is by setting them via the <code>MMTKBuilder</code> instance. See <a href="https://github.com/mmtk/mmtk-openjdk/blob/54a249e877e1cbea147a71aafaafb8583f33843d/mmtk/src/api.rs#L79">here</a> for an example in the OpenJDK binding.</p>
<p>The <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.process.html"><code>process</code></a> function can also be used to pass options. You may want to set multiple options at the same time. In such a case you can use the <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.process_bulk.html"><code>process_bulk</code></a> function.</p>
<p>MMTk also supports setting options via environment variables. This is generally only recommended at early stages of the porting process in order for quick development. For example, to use the NoGC plan, you can set the environment variable <code>MMTK_PLAN=NoGC</code>.</p>
<p>A full list of available options that you can set can be found <a href="https://docs.mmtk.io/api/mmtk/util/options/struct.Options.html">here</a>.</p>
<h3 id="runtime-specific-steps"><a class="header" href="#runtime-specific-steps">Runtime-specific steps</a></h3>
<p>Often it is the case that the above changes are not enough to allow a runtime to work with MMTk. For example, for the ART binding, the runtime required that all inflated locks be deflated prior to writing the boot image. In order to fix this, we had to implement a heap visitor that visited each allocated object and checked if it had inflated locks, deflating them if they were.</p>
<p>Unfortunately there is no real magic bullet here. If you come across a runtime-specific idiosyncrasy (and you almost certainly will), you will have to understand what the underlying bug is and either fix or work around it.</p>
<p>If you have any confusions or questions, please free to reach us on our <a href="https://mmtk.zulipchat.com/">Zulip</a>! We would be glad to help.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h1>
<p>Your choice of the next GC plan to implement depends on your situation.
If you’re developing a new VM from scratch, or if you are intimately familiar with the internals of your target VM, then implementing a SemiSpace collector is probably the best course of action.
Although the GC itself is rather simplistic, it stresses many of the key components of the MMTk &lt;-&gt; VM binding that will be required for later (and more powerful) GCs.
In particular, since it always moves objects, it is an excellent stress test.</p>
<p>An alternative route is to implement MarkSweep.
This may be necessary in scenarios where the target VM doesn’t support object movement, or would require significant refactoring to do so.
This can then serve as a stepping stone for future, moving GCs such as SemiSpace.</p>
<p>We hope to have an Immix implementation available soon, which provides a nice middle ground between moving and non-moving (since it copies opportunistically, and can cope with a strictly non-moving requirement if needs be).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging-tips"><a class="header" href="#debugging-tips">Debugging Tips</a></h1>
<p>In this section, we discuss debugging tips that will be useful to debug MMTk
in a binding implementation. We will focus on discussing strategies and tools
in the specific context of debugging MMTk.</p>
<p>We aim to enhance the debugging capabilities for MMTk. However, as of October 2023, our debugging
tools remain limited. We welcome your feedback and suggestions. If there's a specific debugging tool
you'd like to see or have recommendations, please reach out to us on <a href="https://mmtk.zulipchat.com/">Zulip</a>
or submit your thoughts via <a href="https://github.com/mmtk/mmtk-core/issues">issues</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enabling-debug-assertions"><a class="header" href="#enabling-debug-assertions">Enabling debug assertions</a></h1>
<p>MMTk is implemented with an extensive amount of assertions to ensure the correctness.
We strongly recommend using a debug build of MMTk that includes all the debugging assertions
when one is developing on a MMTk binding. The assertions are normal Rust <code>debug_assert!</code>,
and they can be turned on in a release build with Rust flags (https://doc.rust-lang.org/cargo/reference/profiles.html#debug-assertions).</p>
<h2 id="extreme-debugging-assertions"><a class="header" href="#extreme-debugging-assertions">Extreme debugging assertions</a></h2>
<p>In addition to the normal debugging assertions, MMTk also has a set of
optional runtime checks that can be turned on by enabling the feature <code>extreme_assertions</code>.
These usually include checks that are too expensive (even in a debug build) that we do not
want to enable by default.</p>
<p>You should make sure your MMTk binding can pass all the assertions (including <code>extreme_assertions</code>).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="performance-tuning-for-bindings"><a class="header" href="#performance-tuning-for-bindings">Performance Tuning for Bindings</a></h1>
<p>In this section, we discuss how to achieve the best performance with MMTk in a binding implementation.
MMTk is a high performance GC library. But there are some key points that need to be done correctly
to achieve the optimal performance.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="enabling-link-time-optimization-lto-with-mmtk"><a class="header" href="#enabling-link-time-optimization-lto-with-mmtk">Enabling Link Time Optimization (LTO) with MMTk</a></h1>
<p>MMTk's API is designed with an assumption that LTO will be enabled for a performant build.
It is essential to allow the Rust compiler to optimize across the crate boundary between the binding crate and mmtk-core.
LTO allows inlining for both directions (from mmtk-core to the binding, and from the binding to mmtk-core),
and allows further optimization such as specializing and constant folding for the <code>VMBinding</code> trait.</p>
<p>We suggest enabling LTO for the release build in the binding's manifest (<code>Cargo.toml</code>) by adding a profile for the release build,
so LTO is always enabled for a release build.</p>
<pre><code class="language-toml">[profile.release]
lto = true
</code></pre>
<p>If your binding project is a Rust binary (e.g. the VM is written in Rust), this should be enough. However, if your binding project
is a library, there are some limitations with cargo that you should be aware of.</p>
<h2 id="binding-as-a-library"><a class="header" href="#binding-as-a-library">Binding as a library</a></h2>
<p>Cargo only allows LTO for certain crate types. You will need to specify the crate type properly, otherwise cargo may skip LTO without
any warning or error.</p>
<pre><code class="language-toml">[lib]
...
# be careful - LTO is only allowed for certain crate types
crate-type = ["cdylib"]
</code></pre>
<p>At the time of writing, cargo has some limitations about LTO with different crate types:</p>
<ol>
<li>LTO is only allowed with <code>cdylib</code> and <code>staticlib</code> (other than <code>bin</code>).
Check the code of <a href="https://github.com/rust-lang/cargo/blob/5f40a97e5c85affecfbc4fde67fc06bf188c07db/src/cargo/core/compiler/crate_type.rs#L33"><code>can_lto</code></a>
for your Rust version to clarify.</li>
<li>If the <code>crate-type</code> field includes any type that LTO is not allowed, LTO will be skipped for all the libraries generated (https://github.com/rust-lang/rust/issues/51009).
For example, if you have <code>crate-type = ["cdylib", "rlib"]</code> and cargo cannot do LTO for <code>rlib</code>, LTO will be skipped for <code>cdylib</code> as well.
So only keep the crate type that you actually need in the <code>crate-type</code> field.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="optimizing-allocation"><a class="header" href="#optimizing-allocation">Optimizing Allocation</a></h1>
<p>MMTk provides <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.alloc.html"><code>alloc()</code></a>
and <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.post_alloc.html"><code>post_alloc()</code></a>, to allocate a piece of memory, and
finalize the memory as an object. Calling them is sufficient for a functional implementation, and we recommend doing
so in the early development of an MMTk integration. However, as allocation is performance critical, runtimes generally would want to
optimize allocation to make it as fast as possible, in which invoking <code>alloc()</code> and <code>post_alloc()</code> becomes inadequate.</p>
<p>The following discusses a few design decisions and optimizations related to allocation. The discussion mainly focuses on <code>alloc()</code>.
<code>post_alloc()</code> works in a similar way, and the discussion can also be applied to <code>post_alloc()</code>.
For concrete examples, you can refer to any of our supported bindings, and check the implementation in the bindings.</p>
<blockquote>
<p><strong>Note:</strong> Some of the optimizations need to make assumptions about MMTk's internal implementation and may make the code less maintainable.
We recommend adding assertions in the binding code to make sure the assumptions are not broken across versions.</p>
</blockquote>
<h2 id="efficient-access-to-mmtk-mutators"><a class="header" href="#efficient-access-to-mmtk-mutators">Efficient access to MMTk mutators</a></h2>
<p>An MMTk mutator context (created by <a href="https://docs.mmtk.io/api/mmtk/memory_manager/fn.bind_mutator.html"><code>bind_mutator()</code></a>) is a thread-local data structure
of type <a href="https://docs.mmtk.io/api/mmtk/plan/struct.Mutator.html"><code>Mutator</code></a>.
MMTk expects the binding to provide efficient access to the mutator structure in their thread-local storage (TLS).
Usually one of the following approaches is used to store MMTk mutators.</p>
<h3 id="option-1-storing-the-pointer"><a class="header" href="#option-1-storing-the-pointer">Option 1: Storing the pointer</a></h3>
<p>The <code>Box&lt;Mutator&lt;VM&gt;&gt;</code> returned from <code>mmtk::memory_manager::bind_mutator</code> is actually a pointer to
a <code>Mutator&lt;VM&gt;</code> instance allocated in the Rust heap. It is simple to store it in the TLS.
This approach does not make any assumption about the internals of an MMTk <code>Mutator</code>. However, it requires an extra pointer dereference
when accessing a value in the mutator. This may sound not too bad, however, this degrades the performance of
a carefully implemented inlined fast-path allocation sequence which is normally just a few (assembly) instructions.
This approach could be a simple start in early development, but we do not recommend it for an efficient implementation.</p>
<p>If the VM is not implemented in Rust,
the binding needs to turn the boxed pointer into a raw pointer before storing it.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>                struct MutatorInTLS {
                    // Store the mutator as a boxed pointer.
                    // Accessing any value in the mutator will need a dereferencing of the boxed pointer.
                    ptr: Box&lt;Mutator&lt;MockVM&gt;&gt;,
                }

                // Bind an MMTk mutator
                let mutator = memory_manager::bind_mutator(fixture.get_mmtk(), tls_opaque_pointer);
                // Store the pointer in TLS
                let mut storage = MutatorInTLS { ptr: mutator };

                // Allocate
                let addr =
                    memory_manager::alloc(&amp;mut storage.ptr, 8, 8, 0, AllocationSemantics::Default);
<span class="boring">}</span></code></pre></pre>
<h3 id="option-2-embed-the-mutator-struct"><a class="header" href="#option-2-embed-the-mutator-struct">Option 2: Embed the <code>Mutator</code> struct</a></h3>
<p>To remove the extra pointer dereference, the binding can embed the <code>Mutator</code> type into their TLS type. This saves the extra dereference.</p>
<p>If the implementation language is not Rust, the developer needs to create a type that has the same layout as <code>Mutator</code>. It is recommended to
have an assertion to ensure that the native type has the exact same layout as the Rust type <code>Mutator</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>                struct MutatorInTLS {
                    embed: Mutator&lt;MockVM&gt;,
                }

                // Bind an MMTk mutator
                let mutator = memory_manager::bind_mutator(fixture.get_mmtk(), tls_opaque_pointer);
                // Store the struct (or use memcpy for non-Rust code)
                let mut storage = MutatorInTLS { embed: *mutator };
                // Allocate
                let addr = memory_manager::alloc(
                    &amp;mut storage.embed,
                    8,
                    8,
                    0,
                    AllocationSemantics::Default,
                );
<span class="boring">}</span></code></pre></pre>
<h3 id="option-3-embed-the-fast-path-struct"><a class="header" href="#option-3-embed-the-fast-path-struct">Option 3: Embed the fast-path struct</a></h3>
<p>The size of <code>Mutator</code> is a few hundreds of bytes, which could be considered too large to store in the TLS in some language implementations.
Embedding <code>Mutator</code> also requires to duplicate a native type for the <code>Mutator</code> struct if the implementation language is not Rust.
Sometimes it is undesirable to embed the <code>Mutator</code> type. One can choose to only embed the fast-path struct that is in use.</p>
<p>Unlike the <code>Mutator</code> type, the fast-path struct has a C-compatible layout, and it is simple and primitive enough
so it is unlikely to change. For example, MMTk provides <a href="https://docs.mmtk.io/api/mmtk/util/alloc/struct.BumpPointer.html"><code>BumpPointer</code></a>,
which simply includes a <code>cursor</code> and a <code>limit</code>.</p>
<p>In the following example, we embed one <code>BumpPointer</code> struct in the TLS.
The <code>BumpPointer</code> is used in the fast-path, and carefully synchronized with the allocator in the <code>Mutator</code> struct in the slow-path. We also need to revoke (i.e. reset) all the cached <code>BumpPointer</code> values for <em>all</em> mutators if a GC occurs. Currently, we recommend implementing this in the <a href="https://docs.mmtk.io/api/mmtk/vm/trait.Collection.html#tymethod.resume_mutators"><code>resume_mutators</code></a> API call, however there is work in progress that would make it <a href="https://github.com/mmtk/mmtk-core/issues/1017">an explicit API call instead</a>.</p>
<p>Note that the <code>allocate_default</code> closure in the example below assumes the allocation semantics is <code>AllocationSemantics::Default</code>
and its selected allocator uses bump-pointer allocation.
Real-world fast-path implementations for high-performance VMs are usually JIT-compiled, inlined, and specialized for the current plan
and allocation site. Hence, the allocation semantics of the concrete allocation site (and therefore the selected allocator) is known to the JIT compiler.</p>
<p>For the sake of simplicity, we only store <em>one</em> <code>BumpPointer</code> in the TLS in the example.
In MMTk, each plan has multiple allocators, and the allocation semantics are mapped
to those allocator by the GC plan you choose. So a plan uses multiple allocators, and
depending on how many allocation semantics are used by a binding, the binding may use multiple allocators as well.
In practice, a binding may embed multiple fast-path structs for all the allocators they use if they would like
more efficient allocation.</p>
<p>Also for simplicity, the example assumes the default allocator for the plan in use is a bump pointer allocator.
Many plans in MMTk use bump pointer allocator for their default allocation semantics (<code>AllocationSemantics::Default</code>),
which includes (but not limited to) <code>NoGC</code>, <code>SemiSpace</code>, <code>Immix</code>, generational plans, etc.
If a plan does not do bump-pointer allocation, we may still implement fast-paths, but we need to embed different data structures instead of <code>BumpPointer</code>.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>                use crate::util::alloc::BumpPointer;
                struct MutatorInTLS {
                    default_bump_pointer: BumpPointer,
                    mutator: Box&lt;Mutator&lt;MockVM&gt;&gt;,
                }

                // Bind an MMTk mutator
                let mutator = memory_manager::bind_mutator(fixture.get_mmtk(), tls_opaque_pointer);
                // Create a fastpath BumpPointer with default(). The BumpPointer from default() will guarantee to fail on the first allocation
                // so the allocation goes to the slowpath and we will get an allocation buffer from MMTk.
                let default_bump_pointer = BumpPointer::default();
                // Store the fastpath BumpPointer along with the mutator
                let mut storage = MutatorInTLS {
                    default_bump_pointer,
                    mutator,
                };

                // Allocate
                let mut allocate_default = |size: usize| -&gt; Address {
                    // Alignment code is omitted here to make the code simpler to read.
                    // In an actual implementation, alignment and offset need to be considered by the bindings.
                    let new_cursor = storage.default_bump_pointer.cursor + size;
                    if new_cursor &lt; storage.default_bump_pointer.limit {
                        let addr = storage.default_bump_pointer.cursor;
                        storage.default_bump_pointer.cursor = new_cursor;
                        addr
                    } else {
                        use crate::util::alloc::Allocator;
                        let selector = memory_manager::get_allocator_mapping(
                            fixture.get_mmtk(),
                            AllocationSemantics::Default,
                        );
                        let default_allocator = unsafe {
                            storage
                                .mutator
                                .allocator_impl_mut::&lt;crate::util::alloc::BumpAllocator&lt;MockVM&gt;&gt;(
                                    selector,
                                )
                        };
                        // Copy bump pointer values to the allocator in the mutator
                        default_allocator.bump_pointer = storage.default_bump_pointer;
                        // Do slow path allocation with MMTk
                        let addr = default_allocator.alloc_slow(size, 8, 0);
                        // Copy bump pointer values to the fastpath BumpPointer so we will have an allocation buffer.
                        storage.default_bump_pointer = default_allocator.bump_pointer;
                        addr
                    }
                };

                // Allocate: this will fail in the fastpath, and will get an allocation buffer from the slowpath
                let addr1 = allocate_default(8);
                // Allocate: this will allocate from the fastpath
                let addr2 = allocate_default(8);
<span class="boring">}</span></code></pre></pre>
<p>And pseudo-code for how you would reset the <code>BumpPointer</code>s for all mutators in <code>resume_mutators</code>. Note that these mutators are the runtime's actual mutator threads (i.e. where the cached bump pointers are stored) and are different from MMTk's <code>Mutator</code> struct.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Collection&lt;RtName&gt; for RtNameCollection {
  ...
  fn resume_mutators(tls: VMWorkerThread) {
    // Reset the cached bump pointers of each mutator (setting both cursor and limit to 0) after a GC to
    // ensure that the VM sees a cohesive state
    for mutator in mutators {
      mutator.storage.default_bump_pointer = BumpPointer::default();
    }
    // Actually resume all the mutators now
    ...
  }
  ...
}
<span class="boring">}</span></code></pre></pre>
<h2 id="avoid-resolving-the-allocator-at-run-time"><a class="header" href="#avoid-resolving-the-allocator-at-run-time">Avoid resolving the allocator at run time</a></h2>
<p>For a simple and general API of <code>alloc()</code>, MMTk requires <code>AllocationSemantics</code> as an argument in an allocation request, and resolves it at run-time.
The following is roughly what <code>alloc()</code> does internally.</p>
<ol>
<li>Resolving the allocator
<ol>
<li>Find the <code>Allocator</code> for the required <code>AllocationSemantics</code>. It is defined by the plan in use.</li>
<li>Dynamically dispatch the call to <a href="https://docs.mmtk.io/api/mmtk/util/alloc/trait.Allocator.html#tymethod.alloc"><code>Allocator::alloc()</code></a>.</li>
</ol>
</li>
<li><code>Allocator::alloc()</code> executes the allocation fast-path.</li>
<li>If the fast-path fails, it executes the allocation slow-path <a href="https://docs.mmtk.io/api/mmtk/util/alloc/trait.Allocator.html#method.alloc_slow"><code>Allocator::alloc_slow()</code></a>.</li>
<li>The slow-path will further attempt to allocate memory, and may trigger a GC.</li>
</ol>
<p>Resolving to a specific allocator and doing dynamic dispatch is expensive for an allocation.
With the build-time or JIT-time knowledge about the object that will be allocated, an MMTk binding can possibly skip the first step in the run time.</p>
<p>If you implement an efficient fast-path allocation in the binding side (like the Option 3 above, and <a href="portingguide/perf_tuning/alloc.html#emitting-allocation-sequence-in-a-jit-compiler">generating allocation code in a JIT</a>),
that naturally avoids this problem. If you do not want to implement the fast-path allocation, the following is another example of how to avoid resolving the allocator.</p>
<p>Once MMTk is initialized, a binding can get the memory offset for the default allocator, and save it somewhere. When we know an object should be allocated
with the default allocation semantics, we can use the offset to get a reference to the actual allocator (with unsafe code), and allocate with the allocator.</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>            // At boot time
            let selector = memory_manager::get_allocator_mapping(
                fixture.get_mmtk(),
                AllocationSemantics::Default,
            );
            let default_allocator_offset =
                crate::plan::Mutator::&lt;MockVM&gt;::get_allocator_base_offset(selector);
            let mutator = memory_manager::bind_mutator(fixture.get_mmtk(), tls_opaque_pointer);

            // At run time: allocate with the default semantics without resolving allocator
            let default_allocator: &amp;mut BumpAllocator&lt;MockVM&gt; = {
                let mutator_addr = Address::from_ref(&amp;*mutator);
                unsafe {
                    (mutator_addr + default_allocator_offset).as_mut_ref::&lt;BumpAllocator&lt;MockVM&gt;&gt;()
                }
            };
            let addr = default_allocator.alloc(8, 8, 0);
<span class="boring">}</span></code></pre></pre>
<h2 id="emitting-allocation-sequence-in-a-jit-compiler"><a class="header" href="#emitting-allocation-sequence-in-a-jit-compiler">Emitting Allocation Sequence in a JIT Compiler</a></h2>
<p>If the language has a JIT compiler, it is generally desirable to generate the code sequence for the allocation fast-path, rather
than simply emitting a call instruction to the allocation function. The optimizations we talked above are relevant as well: (i)
the compiler needs to be able to access the mutator, and (ii) the compiler needs to be able to resolve to a specific allocator at
JIT time. The actual implementation highly depends on the compiler implementation.</p>
<p>The following are some examples from our bindings (at the time of writing):</p>
<ul>
<li>OpenJDK:
<ul>
<li><a href="https://github.com/mmtk/mmtk-openjdk/blob/9ab13ae3ac9c68c5f694cdd527a63ca909e27b15/openjdk/mmtkBarrierSetAssembler_x86.cpp#L38">Example 1 (C1 compiler)</a></li>
<li><a href="https://github.com/mmtk/mmtk-openjdk/blob/9ab13ae3ac9c68c5f694cdd527a63ca909e27b15/openjdk/mmtkBarrierSetC2.cpp#L45">Example 2 (C2 compiler)</a></li>
</ul>
</li>
<li><a href="https://github.com/mmtk/mmtk-jikesrvm/blob/fbfb91adafd9e9b3f45bd6a4b32c845a5d48d20b/jikesrvm/rvm/src/org/jikesrvm/mm/mminterface/MMTkMutatorContext.java#L377">JikesRVM</a></li>
<li><a href="https://github.com/mmtk/julia/blob/5c406d9bb20d76e2298a6101f171cfac491f651c/src/llvm-final-gc-lowering.cpp#L267">Julia</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="vm-specific-concerns"><a class="header" href="#vm-specific-concerns">VM-specific Concerns</a></h1>
<p>Every VM is special in some way.  Because of this, some VM bindings may use MMTk features not
usually used by most VMs, and may even deviate from the usual steps of integrating MMTk into the VM.
Here we provide special guides to cover such cases.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="finalizers-and-weak-references"><a class="header" href="#finalizers-and-weak-references">Finalizers and Weak References</a></h1>
<p>Some VMs support <em>finalizers</em>, <em>weak references</em>, and other complex data structures that have weak
reference semantics, such as weak tables (hash tables where the key, the value or both can be weak
references), ephemerons, etc.  The concrete semantics of finalizer and weak reference varies from VM
to VM, but MMTk provides a low-level API that allows the VM bindings to implement their flavors of
finalizer and weak references on top of it.</p>
<h2 id="definitions"><a class="header" href="#definitions">Definitions</a></h2>
<p>In this chapter, we use the following definitions.  They may be different from the definitions in
concrete VMs.</p>
<p><strong>Finalizers</strong> are clean-up operations associated with an object, and are executed when the garbage
collector determines the object is no longer reachable.  Depending on the VM, finalizers may have
different properties.</p>
<ul>
<li>Finalizers may be executed immediately during GC, or postponed to mutator time.</li>
<li>They may have access to the object body, or executed independently from the object.</li>
<li>They may "resurrect" the unreachable object, or guarantee unreachable objects remain unreachable
after finalization.</li>
</ul>
<p><strong>Weak references</strong> are special <a href="portingguide/concerns/../../glossary.html#object-graph">object graph</a> edges distinct from ordinary "strong" references.</p>
<ul>
<li>An object is <em>strongly reachable</em> if there is a path from roots to the object that contains only
strong references.</li>
<li>An object is <em>weakly reachable</em> if any path from the roots to the object must contain at least
one weak reference.</li>
</ul>
<p>The garbage collector may reclaim weakly reachable objects, clear weak references to weakly
reachable objects, and/or performing associated clean-up operations.</p>
<p><strong>A note for Java programmers</strong>: In Java, the term "weak reference" often refers to instances of
<code>java.lang.ref.Reference</code> (including the concrete classes <code>SoftReference</code>, <code>WeakReference</code>,
<code>PhantomReference</code> and the hidden <code>FinalizerReference</code> class used by some JVM implementations to
implement finalizers).  Instances of <code>Reference</code> are proper Java heap objects, but each instance has
a field that contains a pointer to the referent, and the field can be cleared when the referent
dies.  In this article, we use the term "weak reference" to refer to the pointer inside that field.
In other words, a Java <code>Reference</code> instance has a field that holds a weak reference to the referent.</p>
<h2 id="overview-of-mmtks-finalizer-and-weak-reference-processing-api"><a class="header" href="#overview-of-mmtks-finalizer-and-weak-reference-processing-api">Overview of MMTk's finalizer and weak reference processing API</a></h2>
<p>During each GC, MMTk core starts tracing from roots.  It will follow strong references discovered by
<code>Scanning::scan_object</code> and <code>Scanning::scan_object_and_trace_edges</code>.  After all strongly reachable
objects have been reached (i.e. the transitive closure including strongly reachable objects is
computed), MMTk will call <code>Scanning::process_weak_refs</code> which is implemented by the VM binding.
Inside this function, the VM binding can do several things.</p>
<ul>
<li><strong>Query reachability</strong>: The VM binding can query whether any given object has been reached.
<ul>
<li>Do this with <code>ObjectReference::is_reachable()</code>.</li>
</ul>
</li>
<li><strong>Query forwarded address</strong>: If an object has already been reached, the VM binding can further
query the new address of an object.  This is needed to support copying GC.
<ul>
<li>Do this with <code>ObjectReference::get_forwarded_object()</code>.</li>
</ul>
</li>
<li><strong>Retain objects</strong>: If an object has not been reached at this time, the VM binding can
optionally demand the object to be retained.  That object <em>and all descendants</em> will be kept
alive during this GC.
<ul>
<li>Do this with the <code>tracer_context</code> argument of <code>process_weak_refs</code>.</li>
</ul>
</li>
<li><strong>Request another invocation</strong>: The VM binding can request <code>Scanning::process_weak_refs</code> to be
called again after computing the transitive closure that includes <em>retained objects and their
descendants</em>.  This helps handling multiple levels of weak reference strength.
<ul>
<li>Do this by returning <code>true</code> from <code>process_weak_refs</code>.</li>
</ul>
</li>
</ul>
<p>The <code>Scanning::process_weak_refs</code> function also gives the VM binding a chance to perform other
operations, including (but not limited to)</p>
<ul>
<li><strong>Do clean-up operations</strong>: The VM binding can perform clean-up operations, or queue them to be
executed after GC.</li>
<li><strong>Update fields</strong> that contain weak references.
<ul>
<li><strong>Forward the field</strong>: It can write the forwarded address of the referent if moved by a
copying GC.</li>
<li><strong>Clear the field</strong>: It can clear the field if the referent has not been reached and the
binding decides it is unreachable.</li>
</ul>
</li>
</ul>
<p>Using those primitive operations, the VM binding can support different flavors of finalizers and/or
weak references.  We will discuss common use cases in the following sections.</p>
<h2 id="supporting-finalizers"><a class="header" href="#supporting-finalizers">Supporting finalizers</a></h2>
<p>Different languages and VMs define "finalizer" differently, but they all involve performing
operations when an object is dead.  The general way to handle finalizer is visiting all
<strong>finalizable objects</strong> (i.e.  objects that have associated finalization operations), check if they
are unreachable and, if unreachable, do something about them.</p>
<h3 id="identifying-finalizable-objects"><a class="header" href="#identifying-finalizable-objects">Identifying finalizable objects</a></h3>
<p>Some VMs determine whether an object is finalizable by its type.  In Java, for example, an object is
finalizable if its <code>finalize()</code> method is overridden.  The VM binding can maintain a list of
finalizable objects, and register instances of such types into that list when they are constructed.</p>
<p>Some VMs can dynamically attach finalizing operations to individual objects after objects are
created.  The VM binding can maintain a list of objects with attached finalizers, or maintain a
(weak) hash map that maps finalizable objects to its associated finalizers.</p>
<h3 id="when-to-run-finalizers"><a class="header" href="#when-to-run-finalizers">When to run finalizers?</a></h3>
<p>Depending on the finalizer semantics in different VMs, finalizers can be executed during GC or
during mutator time after GC.</p>
<p>The VM binding can run finalizers immediately in <code>Scanning::process_weak_refs</code> when finding a
finalizable object unreachable.  Beware that executing finalizers can be time-consuming.  The VM
binding can creating work packets and let each work packet process a part of all finalizable
objects.  In this way, multiple GC workers can process finalizable objects in parallel.  The
<code>Scanning::process_weak_refs</code> function is executed in the <code>VMRefClosure</code> stage, so the created work
packets shall be added to the same bucket.</p>
<p>If the finalizers should be executed after GC, the VM binding should enqueue such jobs to
VM-specific queues so that they can be picked up by mutator threads after GC.</p>
<h3 id="reading-the-body-of-dead-object"><a class="header" href="#reading-the-body-of-dead-object">Reading the body of dead object</a></h3>
<p>In some VMs, finalizers can read the fields in dead objects.  Such fields usually include
information needed for cleaning up resources held by the object, such as file descriptors and
pointers to memory not managed by GC.</p>
<p><code>Scanning::process_weak_refs</code> is executed in the <code>VMRefClosure</code> stage, which happens after computing
transitive closure, but before any object has been released (which happens in the <code>Release</code> stage).
This means the body of all objects, live or dead, can still be accessed during this stage.</p>
<p>Therefore, there is no problem reading the object body if the VM binding executes finalizers
immediately in <code>process_weak_refs</code>, or in created work packets in the <code>VMRefClosure</code> stage.</p>
<p>However, if the VM needs to execute finalizers after GC, it will be a problem because the object
will have been reclaimed, and memory of the object will have been overwritten by other objects.  In
this case, the VM will need to retain the dead object to make it accessible after the current GC.</p>
<h3 id="retaining-unreachable-objects"><a class="header" href="#retaining-unreachable-objects">Retaining unreachable objects</a></h3>
<p>Some VMs, particularly the Java VM, executes finalizers during mutator time.  Any finalizable
objects unreachable before a GC must be retained so that they can still be accessed by their
finalizers after the GC.</p>
<p>The <code>Scanning::process_weak_refs</code> has an parameter <code>tracer_context: impl ObjectTracerContext&lt;VM&gt;</code>.
This parameter provides the necessary mechanism to retain objects and make them (and their
descendants) live through the current GC.  The typical use pattern is:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Scanning&lt;MyVM&gt; for VMScanning {
    fn process_weak_refs(
        worker: &amp;mut GCWorker&lt;MyVM&gt;,
        tracer_context: impl ObjectTracerContext&lt;MyVM&gt;,
    ) -&gt; bool {
        let finalizable_objects: Vec&lt;ObjectReference&gt; = my_vm::get_finalizable_object();
        let mut new_finalizable_objects = vec![];

        tracer_context.with_tracer(worker, |tracer| {
            for object in finalizable_objects {
                if object.is_reachable() {
                    // `object` is still reachable.
                    // It may have been moved if it is a copying GC.
                    let new_object = object.get_forwarded_object().unwrap_or(object);
                    new_finalizable_objects.push(new_object);
                } else {
                    // `object` is unreachable.
                    // Retain it, and enqueue it for postponed finalization.
                    let new_object = tracer.trace_object(object);
                    my_vm::enqueue_finalizable_object_to_be_executed_later(new_object);
                }
            }
        });

        my_vm::set_new_finalizable_objects(new_finalizable_objects);

        false
    }

    // ...
<span class="boring">}</span></code></pre></pre>
<p>Within the closure <code>|tracer| { ... }</code>, the VM binding can call <code>tracer.trace_object(object)</code> to
retain <code>object</code>.  It returns the new address of <code>object</code> because in a copying GC the <code>trace_object</code>
function can also move the object.</p>
<p>Under the hood, <code>tracer_context.with_tracer</code> creates a queue and calls the closure.  The <code>tracer</code>
implements the <code>ObjectTracer</code>  trait, and is just an interface that provides the <code>trace_object</code>
method.  Objects retained by <code>tracer.trace_object</code> will be enqueued.  After the closure returns,
<code>with_tracer</code> will split the queue into reasonably-sized work packets and add them to the
<code>VMRefClosure</code> work bucket.  Those work packets will trace the retained objects and their
descendants, effectively expanding the transitive closure to include all objects reachable from the
retained objects.  Because of the overhead of creating queues and work packets, the VM binding
should <strong>retain as many objects as needed in one invocation of <code>with_tracer</code>, and avoid calling
<code>with_tracer</code> again and again for each object</strong>.</p>
<p><strong>Don't do this</strong>:</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>for object in objects {
    tracer_context.with_tracer(worker, |tracer| { // This is expensive! DON'T DO THIS!
        tracer.trace_object(object);
    });
}
<span class="boring">}</span></code></pre></pre>
<p>Keep in mind that <strong>tracer_context implements the <code>Clone</code> trait</strong>.  As introduced in the <a href="portingguide/concerns/weakref.html#when-to-run-finalizers"><em>When to
run finalizers</em></a> section, the VM binding can use work packets to
parallelize finalizer processing.  If finalizable objects need to be retained, the VM binding can
clone the <code>trace_context</code> and give each work packet a clone of <code>tracer_context</code>.</p>
<h3 id="warning-object-resurrection"><a class="header" href="#warning-object-resurrection">WARNING: object resurrection</a></h3>
<p>If the VM binding retains an unreachable object for finalization, and the finalizer writes a
reference of that object into a place readable by application threads, including global or static
variable, then the previously unreachable object will become reachable by the application again.
This phenomenon is known as <strong>"resurrection"</strong>, and can be surprising to the programmers.</p>
<p>Developers of VM bindings of existing VMs may have no choice but to implement the finalizer
semantics strictly according to the specification of the VM, even if that would result in
"resurrection".  JVM is a well-known example of the "resurrection" behavior, although the
<code>Object.finalize()</code> method has been deprecated for removal, in favor for alternative clean-up
mechanisms such as <code>PhantomReference</code> and <code>Cleaner</code> which never "resurrect" objects.</p>
<p>Designers of new programming languages or VMs should be aware of the "resurrection" problem.  It is
recommended not to let finalizers have access to the object body.  For finalizers that need to
release certain resources (such as files), the VM may store relevant data (such as file descriptors)
in a separate object and use that as the context of the finalizer.</p>
<p>To avoid unintentionally "resurrecting" objects, if the VM binding intends to get the new address of
a moved object, it should use <code>object.get_forwarded_object()</code> instead of
<code>tracer.trace_object(object)</code>, although the latter also returns the new address if <code>object</code> is
already moved.</p>
<h2 id="supporting-weak-references"><a class="header" href="#supporting-weak-references">Supporting weak references</a></h2>
<p>The general way to handle weak references is, after computing the transitive closure, iterate
through all fields that contain weak references to objects.  For each field,</p>
<ul>
<li>if the referent has already been reached, write the new address of the object to the field (or
do nothing if the object is not moved);</li>
<li>otherwise, clear the field, writing <code>null</code>, <code>nil</code>, or whatever represents a cleared weak
reference to the field.</li>
</ul>
<h3 id="identifying-weak-references"><a class="header" href="#identifying-weak-references">Identifying weak references</a></h3>
<p>Weak references in fields of <em>global</em> (per-VM) data structures are relatively straightforward.  We
just need to enumerate them in <code>Scanning::process_weak_refs</code>.</p>
<p>There are also fields in <em>heap objects</em> that hold weak references to other heap objects.  There are
two basic ways to identify them.</p>
<ul>
<li><strong>Register on creation</strong>: We may record objects that contain weak reference fields in a global
list when such objects are created.  In <code>Scanning::process_weak_refs</code>, we just need to iterate
through this list, process the fields, and remove dead objects from the list.</li>
<li><strong>Discover objects during tracing</strong>: While computing the transitive closure, we scan objects and
discover objects that contain weak reference fields.  We enqueue such objects into a list, and
iterate through the list in <code>Scanning::process_weak_refs</code> after transitive closure.  The list
needs to be reconstructed in each GC.</li>
</ul>
<p>Both methods work, but each has its advantages and disadvantages.  Registering on creation does not
need to reconstruct the list in every GC, while discovering during tracing can avoid visiting dead
objects.  Depending on the nature of your VM, one method may be easier to implement than the other,
especially if your VM's existing GC has already implemented weak reference processing in some way.</p>
<h3 id="associated-clean-up-operations"><a class="header" href="#associated-clean-up-operations">Associated clean-up operations</a></h3>
<p>Some languages and VMs allow certain clean-up operations to be associated with weak references, and
will be executed after the weak reference is cleared.</p>
<p>Such clean-up operations can be supported similar to finalizers.  While we enumerate weak references
in <code>Scanning::process_weak_refs</code>, we clear weak references to unreachable objects.  Depending on the
semantics, we may choose to execute the clean-up operations immediately, or enqueue them to be
executed after GC.  We may retain the unreachable referent if we need to.</p>
<h3 id="soft-references"><a class="header" href="#soft-references">Soft references</a></h3>
<p>Java has a special kind of weak reference: <code>SoftReference</code>.  The API allows the GC to choose between
(1) retaining softly reachable referents, and (2) clearing references to softly reachable objects.
When using MMTk, there are two ways to implement this semantics.</p>
<p>The easiest way is <strong>treating <code>SoftReference</code> as strong references in non-emergency GCs, and
treating them like <code>WeakReference</code> in <a href="portingguide/concerns/../../glossary.html#emergency-collection">emergency GCs</a></strong>.</p>
<ul>
<li>During non-emergency GC, we let <code>Scanning::scan_object</code> and
<code>Scanning::scan_object_and_trace_edges</code> scan the weak reference field inside a <code>SoftReference</code>
instance as if it were an ordinary strong reference field.  In this way, softly reachable
objects will be included in the (strong) transitive closure from roots.  By the first time
<code>Scanning::process_weak_refs</code> is called, strongly reachable objects will have already been
reached (i.e. <code>object.is_reachable()</code> will be true).  They will be kept alive just like strongly
reachable objects.</li>
<li>During emergency GC, however, skip this field in <code>Scanning::scan_object</code> or
<code>Scanning::scan_object_and_trace_edges</code>, and clear <code>SoftReference</code> just like <code>WeakReference</code> in
<code>Scanning::process_weak_refs</code>.  In this way, softly reachable objects will become unreachable
unless they are subject to finalization.</li>
</ul>
<p>The other way is <strong>retaining referents of <code>SoftReference</code> after the strong closure</strong>.  This involves
supporting multiple levels of reference strength, which will be introduced in the <a href="portingguide/concerns/weakref.html#multiple-levels-of-reference-strength">next
section</a>.</p>
<h3 id="multiple-levels-of-reference-strength"><a class="header" href="#multiple-levels-of-reference-strength">Multiple levels of reference strength</a></h3>
<p>Some VMs support multiple levels of weak reference strengths.  Java, for example, has
<code>SoftReference</code>, <code>WeakReference</code>, <code>FinalizerReference</code> (internal) and <code>PhantomReference</code>, in the
order of decreasing strength.</p>
<p>This can be supported by running <code>Scanning::process_weak_refs</code> multiple times.  If
<code>process_weak_refs</code> returns <code>true</code>, it will be called again after all pending work packets in the
<code>VMRefClosure</code> stage has been executed.  Those pending work packets include all work packets that
compute the transitive closure from objects retained during <code>process_weak_refs</code>.  This allows the VM
binding to expand the transitive closure multiple times, each handling weak references at different
levels of strength.</p>
<p>Take Java as an example,  we may run <code>process_weak_refs</code> four times.</p>
<ol>
<li>Visit all <code>SoftReference</code>.
<ul>
<li>If the referent has been reached, then
<ul>
<li>forward the referent field.</li>
</ul>
</li>
<li>If the referent has not been reached, yet, then
<ul>
<li>if it is not an emergency GC, then
<ul>
<li>retain the referent and update the referent field.</li>
</ul>
</li>
<li>it it is an emergency GC, then
<ul>
<li>clear the referent field,</li>
<li>remove the <code>SoftReference</code> from the list of soft references, and</li>
<li>optionally enqueue it to the associated <code>ReferenceQueue</code> if it has one.</li>
</ul>
</li>
</ul>
</li>
<li>(This step may expand the transitive closure in emergency GCs if any referents are
retained.)</li>
</ul>
</li>
<li>Visit all <code>WeakReference</code>.
<ul>
<li>If the referent has been reached, then
<ul>
<li>forward the referent field.</li>
</ul>
</li>
<li>If the referent has not been reached, yet, then
<ul>
<li>clear the referent field,</li>
<li>remove the <code>WeakReference</code> from the list of weak references, and</li>
<li>optionally enqueue it to the associated <code>ReferenceQueue</code> if it has one.</li>
</ul>
</li>
<li>(This step cannot expand the transitive closure.)</li>
</ul>
</li>
<li>Visit the list of finalizable objects.
<ul>
<li>If the finalizable object has been reached, then
<ul>
<li>forward the reference in the list.</li>
</ul>
</li>
<li>If the finalizable object has not been reached, yet, then
<ul>
<li>retain the finalizable object, and</li>
<li>remove it from the list of finalizable objects, and</li>
<li>enqueue it for finalization.</li>
</ul>
</li>
<li>(This step may expand the transitive closure if any finalizable objects are retained.)</li>
</ul>
</li>
<li>Visit all <code>PhantomReference</code>.
<ul>
<li>If the referent has been reached, then
<ul>
<li>forward the referent field.</li>
<li>(Note: <code>PhantomReference#get()</code> always returns <code>null</code>, but the actual referent field
shall hold a valid reference to the referent before it is cleared.)</li>
</ul>
</li>
<li>If the referent has not been reached, yet, then
<ul>
<li>clear the referent field,</li>
<li>remove the <code>PhantomReference</code> from the list of phantom references, and</li>
<li>optionally enqueue it to the associated <code>ReferenceQueue</code> if it has one.</li>
</ul>
</li>
<li>(This step cannot expand the transitive closure.)</li>
</ul>
</li>
</ol>
<p>As an optimization,</p>
<ul>
<li>Step 1 can be, as we described in the <a href="portingguide/concerns/weakref.html#soft-references">previous section</a>, eliminated by
merging it with the strong closure in non-emergency GC, or with <code>WeakReference</code> processing in
emergency GCs.</li>
<li>Step 2 can be merged with Step 3 since Step 2 never expands the transitive closure.</li>
</ul>
<p>Therefore, we only need to run <code>process_weak_refs</code> twice:</p>
<ol>
<li>Handle <code>WeakReference</code> (and also <code>SoftReference</code> in emergency GCs), and then handle finalizable
objects.</li>
<li>Handle <code>PhandomReference</code>.</li>
</ol>
<p>To implement this, the VM binding may need to implement some kind of <em>state machine</em> so that the
<code>Scanning::process_weak_refs</code> function behaves differently each time it is called.  For example,</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn process_weak_refs(...) -&gt; bool {
    let mut state = /* Get VM-specific states here. */;

    match *state {
        State::ProcessSoftReference =&gt; {
            process_soft_references(...);
            *state = State::ProcessWeakReference;
            return true; // Run this function again.
        }
        State::ProcessWeakReference =&gt; {
            process_weak_references(...);
            *state = State::ProcessFinalizableObjects;
            return true; // Run this function again.
        }
        State::ProcessFinalizableObjects =&gt; {
            process_finalizable_objects(...);
            *state = State::ProcessPhantomReferences;
            return true; // Run this function again.
        }
        State::ProcessPhantomReferences =&gt; {
            process_phantom_references(...);
            *state = State::ProcessSoftReference
            return false; // Proceed to the Release stage.
        }
    }
}
<span class="boring">}</span></code></pre></pre>
<h3 id="ephemerons"><a class="header" href="#ephemerons">Ephemerons</a></h3>
<p>An <a href="https://dl.acm.org/doi/10.1145/263700.263733">Ephemeron</a> has a <em>key</em> and a <em>value</em>, both of which are object references.  The key is a weak
reference, while the value keeps the referent alive only if both the ephemeron itself and the key
are reachable.</p>
<p>To support ephemerons, the VM binding needs to identify ephemerons.  This includes ephemerons as
individual objects, objects that contain ephemerons, and, equivalently, objects that contain
key/value fields that have semantics similar to ephemerons.</p>
<p>The following is the algorithm for processing ephemerons.  It gradually discovers ephemerons as we
do the tracing.  We maintain a queue of ephemerons which is empty before the <code>Closure</code> stage.</p>
<ol>
<li>In <code>Scanning::scan_object</code> and <code>Scanning::scan_object_and_trace_edges</code>, we enqueue ephemerons
(into the queue of ephemerons we created before) as we scan them, but do not trace either the
key or the value fields.</li>
<li>In <code>Scanning::process_weak_refs</code>, we iterate through all ephemerons in the queue.  If the key of
an ephemeron has been reached, but its value has not yet been reached, then retain its value,
and remove the ephemeron from the queue.  Otherwise, keep the object in the queue.</li>
<li>If any value is retained, return <code>true</code> from <code>Scanning::process_weak_refs</code> so that it will be
called again after the transitive closure from retained values are computed.  Then go back to
Step 2.</li>
<li>If no value is retained, the algorithm completes.  The queue contains reachable ephemerons that
have unreachable keys.</li>
</ol>
<p>This algorithm can be modified if we have a list of all ephemerons before GC starts.  We no longer
need to maintain the queue.</p>
<ul>
<li>In Step 1, we don't need to enqueue ephemerons.</li>
<li>In Step 2, we iterate through all ephemerons.  We retain the value if both the ephemeron itself
and the key have been reached, and the value has not been reached, yet.  We don't need to remove
any ephemeron from the list.</li>
<li>When the algorithm completes, we can identify both reachable and unreachable ephemerons that
have unreachable keys.  But we need to remove unreachable (dead) ephemerons from the list
because they will be recycled in the <code>Release</code> stage.</li>
</ul>
<p>And we can go through ephemerons with unreachable keys and do necessary clean-up operations, either
immediately or postponed to mutator time.</p>
<h2 id="optimizations"><a class="header" href="#optimizations">Optimizations</a></h2>
<h3 id="generational-gc"><a class="header" href="#generational-gc">Generational GC</a></h3>
<p>MMTk provides generational GC plans.  Currently, there are <code>GenCopy</code>, <code>GenImmix</code> and <code>StickyImmix</code>.
In a minor GC, a generational plan only consider <em>young objects</em> (i.e. objects allocated since the
last GC) as candidates of garbage, and will assume all <em>old objects</em> (i.e. objects survived the last
GC) are live.</p>
<p>The VM binding can query if the current GC is a nursery GC by calling</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let is_nursery_gc = mmtk.get_plan().generational().is_some_and(|gen|
    gen.is_current_gc_nursery());
<span class="boring">}</span></code></pre></pre>
<p>The VM binding can make use of this information when processing finalizers and weak references.  In
a minor GC,</p>
<ul>
<li>The VM binding only needs to visit <strong>finalizable objects allocated since the last GC</strong>.  Other
finalizable objects must be old and will not be considered dead.</li>
<li>The VM binding only needs to visit <strong>weak reference slots written since the last GC</strong>.  Other
slots must be pointing to old objects (if not <code>null</code>).  For weak hash tables, if existing
entries are immutable, it is sufficient to only visit newly added entries.</li>
</ul>
<p>Implementation-wise, the VM binding can split the lists or hash tables into two parts: one for old
entries and another for young entries.</p>
<h3 id="copying-versus-non-copying-gc"><a class="header" href="#copying-versus-non-copying-gc">Copying versus non-copying GC</a></h3>
<p>MMTk provides both copying and non-copying GC plans.  <code>MarkSweep</code> never moves any objects.
<code>MarkCompact</code>, <code>SemiSpace</code> always moves all objects (except objects in the large object space,
immortal space, VM space, etc.).  Immix-based plans sometimes do non-copying GC, and sometimes do
copying GC.  Regardless of the plan, the VM binding can query if the current GC is a copying GC by
calling</p>
<pre><pre class="playground"><code class="language-rust edition2021"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let may_move_object = mmtk.get_plan().current_gc_may_move_object();
<span class="boring">}</span></code></pre></pre>
<p>If it returns <code>false</code>, the current GC will not move any object.</p>
<p>The VM binding can make use of this information.  For example, if a weak hash table uses object
addresses as keys, and the hash code is computed directly from the address, then the VM will need to
rehash the table during copying GC because changing the address may move the entry to a different
hash bin.  But if the current GC is non-moving, the VM binding will not need to rehash the table,
but only needs to remove entries for dead objects.  Despite of this optimization opportunity, we
still recommend VMs to implement <em>address-based hashing</em> if possible.  In that case, we never need
to rehash any hash tables due to object movement.</p>
<div id="admonition-info" class="admonition admonish-info" role="note" aria-labelledby="admonition-info-title">
<div class="admonition-title">
<div id="admonition-info-title">
<p>Info</p>
</div>
<a class="admonition-anchor-link" href="portingguide/concerns/weakref.html#admonition-info"></a>
</div>
<div>
<p>When using <strong>address-based hashing</strong>, the hash code of an object depends on whether its hash code
has been observed before, and whether it has been moved after its hash code has been observed.</p>
<ul>
<li>If never observed, the hash code of an object will be its current address.</li>
<li>When the object is moved the first time after its hash code is observed, the GC thread copies
its old address to a field of the new copy.  From then on, its hash code will be read from that
field.</li>
<li>When such an object is copied again, its hash code will be copied to the new copy of the object.
The hash code of the object remains unchanged.</li>
</ul>
<p>The VM binding needs to implement this in <code>ObjectModel::copy</code>.</p>
</div>
</div>
<h2 id="deprecated-reference-and-finalizable-processors"><a class="header" href="#deprecated-reference-and-finalizable-processors">Deprecated reference and finalizable processors</a></h2>
<p>When porting MMTk from JikesRVM to a dedicated Rust library, we also ported the <code>ReferenceProcessor</code>
and the <code>FinalizableProcessor</code> from JikesRVM.  They are implemented in mmtk-core, and provide the
mechanisms for handling Java-style soft/weak/phantom references and finalizable objects.  The VM
binding can use those utilities by implementing the <code>mmtk::vm::ReferenceGlue</code> and the
<code>mmtk::vm::Finalizable</code> traits, and calling the
<code>mmtk::memory_manager::add_{soft,weak,phantom}_candidate</code> and the
<code>mmtk::memory_manager::add_finalizer</code> functions.</p>
<p>However, those mechanisms are too specific to Java, and are not applicable to most other VMs.  <strong>New
VM bindings should use the <code>Scanning::process_weak_refs</code> API</strong>, and we are porting existing VM
bindings away from the built-in reference/finalizable processors.</p>
<!--
vim: tw=100 ts=4 sw=4 sts=4 et
-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="api-migration-guide"><a class="header" href="#api-migration-guide">API Migration Guide</a></h1>
<p>This document lists changes to the MMTk-VM API that require changes to be made by the VM bindings.
VM binding developers can use this document as a guide to update their code to maintain
compatibility with the latest release of MMTk.</p>
<h2 id="view-control"><a class="header" href="#view-control">View control</a></h2>
<p>Choose how many details you want to read.</p>
<p><button class="api-migration-details-show-tldr" type="button">Show TL;DR only</button>
<button class="api-migration-details-show-outline" type="button">Show outline</button>
<button class="api-migration-details-show-all" type="button">Show all details</button></p>
<!--

Notes for the mmtk-core developers:

-   Make sure you add to the **upcoming release**.  Check the current version in `Cargo.toml`.
-   You may add new items or edit existing items before a release, whichever makes sense.
-   No need to mention API changes that are source compatible and do not require VM binding code
    to be updated.
-   Use the [template](template.md).
-   100 characters per line.  Those who read this doc in text editors and IDEs will thank you.
    -   vim: "gq" formats the selected lines, and "gqap" formats one paragraph.
    -   vscode: The "Rewrap" plugin can re-wrap a paragraph with one hot key.

-->
<div id="api-migration-detail-body"><!-- We use JavaScript to process things within this div. -->
<!-- Insert new versions here -->
<h2 id="0300"><a class="header" href="#0300">0.30.0</a></h2>
<h3 id="live_bytes_in_last_gc-becomes-a-runtime-option-and-returns-a-map-for-live-bytes-in-each-space"><a class="header" href="#live_bytes_in_last_gc-becomes-a-runtime-option-and-returns-a-map-for-live-bytes-in-each-space"><code>live_bytes_in_last_gc</code> becomes a runtime option, and returns a map for live bytes in each space</a></h3>
<div id="admonition-tldr" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-title">
<div class="admonition-title">
<div id="admonition-tldr-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr"></a>
</div>
<div>
<p><code>count_live_bytes_in_gc</code> is now a runtime option instead of a features (build-time), and we collect
live bytes statistics per space. Correspondingly, <code>memory_manager::live_bytes_in_last_gc</code> now returns a map for
live bytes in each space.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>module <code>util::options</code>
<ul>
<li><code>Options</code> includes <code>count_live_bytes_in_gc</code>, which defaults to <code>false</code>. This can be turned on at run-time.</li>
<li>The old <code>count_live_bytes_in_gc</code> feature is removed.</li>
</ul>
</li>
<li>module <code>memory_manager</code>
<ul>
<li><code>live_bytes_in_last_gc</code> now returns a <code>HashMap&lt;&amp;'static str, LiveBytesStats&gt;</code>. The keys are
strings for space names, and the values are statistics for live bytes in the space.</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1238">https://github.com/mmtk/mmtk-core/pull/1238</a></li>
</ul>
<h3 id="mmap-related-functions-require-annotation"><a class="header" href="#mmap-related-functions-require-annotation">mmap-related functions require annotation</a></h3>
<div id="admonition-tldr-1" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-1-title">
<div class="admonition-title">
<div id="admonition-tldr-1-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-1"></a>
</div>
<div>
<p>Memory-mapping functions in <code>mmtk::util::memory</code> now take an additional <code>MmapAnnotation</code> argument.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>module <code>util::memory</code>
<ul>
<li>The following functions take an additional <code>MmapAnnotation</code> argument.
<ul>
<li><code>dzmmap</code></li>
<li><code>dzmmap_noreplace</code></li>
<li><code>mmap_noreserve</code></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="0280"><a class="header" href="#0280">0.28.0</a></h2>
<h3 id="handle_user_collection_request-returns-bool"><a class="header" href="#handle_user_collection_request-returns-bool"><code>handle_user_collection_request</code> returns <code>bool</code></a></h3>
<div id="admonition-tldr-2" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-2-title">
<div class="admonition-title">
<div id="admonition-tldr-2-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-2"></a>
</div>
<div>
<p><code>memory_manager::handle_user_collection_request</code> now returns a boolean value to indicate whether a GC
is triggered by the method or not. Bindings may use the return value to do some post-gc cleanup, or
simply ignore the return value.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>module <code>memory_manager</code>
<ul>
<li><code>handle_user_collection_request</code> now returns <code>bool</code> to indicate if a GC is triggered by the method.
Bindings may use the value, or simply ignore it.</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/issues/1205">https://github.com/mmtk/mmtk-core/issues/1205</a></li>
<li>Examples:
<ul>
<li>https://github.com/mmtk/mmtk-julia/pull/177: Ignore return value.</li>
</ul>
</li>
</ul>
<h3 id="objectreference-must-point-inside-an-object"><a class="header" href="#objectreference-must-point-inside-an-object"><code>ObjectReference</code> must point inside an object</a></h3>
<div id="admonition-tldr-3" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-3-title">
<div class="admonition-title">
<div id="admonition-tldr-3-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-3"></a>
</div>
<div>
<p><code>ObjectReference</code> is now required to be an address within an object.  The concept of "in-object
address" and related methods are removed.  Some methods which used to depend on the "in-object
address" no longer need the <code>&lt;VM&gt;</code> type argument.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>struct <code>ObjectReference</code>
<ul>
<li>Its "raw address" must be within an object now.</li>
<li>The following methods which were used to access the in-object address are removed.
<ul>
<li><code>from_address</code></li>
<li><code>to_address</code></li>
<li>When accessing side metadata, the "raw address" should be used, instead.</li>
</ul>
</li>
<li>The following methods no longer have the <code>&lt;VM&gt;</code> type argument.
<ul>
<li><code>get_forwarded_object</code></li>
<li><code>is_in_any_space</code></li>
<li><code>is_live</code></li>
<li><code>is_movable</code></li>
<li><code>is_reachable</code></li>
</ul>
</li>
</ul>
</li>
<li>module <code>memory_manager</code>
<ul>
<li><code>is_mmtk_object</code>: It now requires the address parameter to be non-zero and word-aligned.
<ul>
<li>Otherwise it will not be a legal <code>ObjectReference</code> in the first place.  The user should
filter out such illegal values.</li>
</ul>
</li>
<li>The following functions no longer have the <code>&lt;VM&gt;</code> type argument.
<ul>
<li><code>find_object_from_internal_pointer</code></li>
<li><code>is_in_mmtk_space</code></li>
<li><code>is_live_object</code></li>
<li><code>is_pinned</code></li>
<li><code>pin_object</code></li>
<li><code>unpin_object</code></li>
</ul>
</li>
</ul>
</li>
<li>struct <code>Region</code>
<ul>
<li>The following methods no longer have the <code>&lt;VM&gt;</code> type argument.
<ul>
<li><code>containing</code></li>
</ul>
</li>
</ul>
</li>
<li>trait <code>ObjectModel</code>
<ul>
<li><code>IN_OBJECT_ADDRESS_OFFSET</code>: removed because it is no longer needed.</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/issues/1170">https://github.com/mmtk/mmtk-core/issues/1170</a></li>
<li>Examples:
<ul>
<li>https://github.com/mmtk/mmtk-openjdk/pull/286: a simple case</li>
<li>https://github.com/mmtk/mmtk-jikesrvm/issues/178: a VM that needs much change for this</li>
</ul>
</li>
</ul>
<h2 id="0270"><a class="header" href="#0270">0.27.0</a></h2>
<h3 id="is_mmtk_object-returns-optionobjectreference"><a class="header" href="#is_mmtk_object-returns-optionobjectreference"><code>is_mmtk_object</code> returns <code>Option&lt;ObjectReference&gt;</code></a></h3>
<div id="admonition-tldr-4" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-4-title">
<div class="admonition-title">
<div id="admonition-tldr-4-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-4"></a>
</div>
<div>
<p><code>memory_manager::is_mmtk_object</code> now returns <code>Option&lt;ObjectReference&gt;</code> instead of <code>bool</code>.
Bindings can use the returned object reference instead of computing the object reference at the binding side.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>module <code>memory_manager</code>
<ul>
<li><code>is_mmtk_object</code> now returns <code>Option&lt;ObjectReference&gt;</code>.</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1165">https://github.com/mmtk/mmtk-core/pull/1165</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-ruby/pull/86">https://github.com/mmtk/mmtk-ruby/pull/86</a></li>
</ul>
<h3 id="introduce-objectmodelin_object_address_offset"><a class="header" href="#introduce-objectmodelin_object_address_offset">Introduce <code>ObjectModel::IN_OBJECT_ADDRESS_OFFSET</code></a></h3>
<div id="admonition-tldr-5" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-5-title">
<div class="admonition-title">
<div id="admonition-tldr-5-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-5"></a>
</div>
<div>
<p>We used to have <code>ObjectModel::ref_to_address</code> and <code>ObjectModel::address_to_ref</code>, and require
the object reference and the in-object address to have a constant offset. Now, the two methods
are removed, and replaced with a constant <code>ObjectModel::IN_OBJECT_ADDRESS_OFFSET</code>.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>trait <code>ObjectModel</code>
<ul>
<li>The methods <code>ref_to_address</code> and <code>address_to_ref</code> are removed.</li>
<li>Users are required to specify <code>IN_OBJECT_ADDRESS_OFFSET</code> instead, which is the offset from the object
reference to the in-object address (the in-object address was the return value for the old <code>ref_to_address()</code>).</li>
</ul>
</li>
<li>type <code>ObjectReference</code>
<ul>
<li>Add a constant <code>ALIGNMENT</code> which equals to the word size. All object references should be at least aligned
to the word size. This is checked in debug builds when an <code>ObjectReference</code> is constructed.</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1159">https://github.com/mmtk/mmtk-core/pull/1159</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/283">https://github.com/mmtk/mmtk-openjdk/pull/283</a></li>
</ul>
<h2 id="0260"><a class="header" href="#0260">0.26.0</a></h2>
<h3 id="rename-edge-to-slot"><a class="header" href="#rename-edge-to-slot">Rename "edge" to "slot"</a></h3>
<div id="admonition-tldr-6" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-6-title">
<div class="admonition-title">
<div id="admonition-tldr-6-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-6"></a>
</div>
<div>
<p>The word "edge" <strong>in many identifiers</strong> have been changed to "slot" if it actaully means slot.
Notable items include the traits <code>Edge</code>, <code>EdgeVisitor</code>, the module <code>edge_shape</code>, and member types
and functions in the <code>Scanning</code> and <code>VMBinding</code> traits.  The VM bindings should not only make
changes in response to the changes in MMTk-core, but also make changes to their own identifiers if
they also use "edge" where it should have been "slot".  The find/replace tools in text editors and
the refactoring/renaming tools in IDEs should be helpful.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>module <code>edge_shape</code> -&gt; <code>slot</code></li>
<li>type <code>RootsWorkFactory</code>
<ul>
<li><code>&lt;ES: Edge&gt;</code> -&gt; <code>&lt;SL: Slot&gt;</code></li>
<li><code>create_process_edge_roots_work</code> -&gt; <code>create_process_roots_work</code></li>
</ul>
</li>
<li>type <code>SimpleEdge</code> -&gt; <code>SimpleSlot</code></li>
<li>type <code>UnimplementedMemorySliceEdgeIterator</code> -&gt; <code>UnimplementedMemorySliceSlotIterator</code></li>
<li>trait <code>Edge</code> -&gt; <code>Slot</code></li>
<li>trait <code>EdgeVisitor</code> -&gt; <code>SlotVisitor</code>
<ul>
<li><code>&lt;ES: Edge&gt;</code> -&gt; <code>&lt;SL: Slot&gt;</code></li>
<li><code>visit_edge</code> -&gt; <code>visit_slot</code></li>
</ul>
</li>
<li>trait <code>MemorySlice</code>
<ul>
<li><code>Edge</code> -&gt; <code>SlotType</code></li>
<li><code>EdgeIterator</code> -&gt; <code>SlotIterator</code></li>
<li><code>iter_edges</code> -&gt; <code>iter_slots</code></li>
</ul>
</li>
<li>trait <code>Scanning</code>
<ul>
<li><code>support_edge_enqueuing</code> -&gt; <code>support_slot_enqueuing</code></li>
<li><code>scan_object</code>
<ul>
<li><code>&lt;EV: EdgeVisitor&gt;</code> -&gt; <code>&lt;SV: SlotVisitor&gt;</code></li>
</ul>
</li>
<li><code>scan_roots_in_mutator_thread</code>
<ul>
<li>Type parameter of <code>factory</code> changed. See type <code>RootsWorkFactory</code>.</li>
</ul>
</li>
<li><code>scan_vm_specific_roots</code>
<ul>
<li>Same as above.</li>
</ul>
</li>
</ul>
</li>
<li>trait <code>VMBinding</code>
<ul>
<li><code>VMEdge</code> -&gt; <code>VMSlot</code></li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1134">https://github.com/mmtk/mmtk-core/pull/1134</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/274">https://github.com/mmtk/mmtk-openjdk/pull/274</a></li>
</ul>
<h2 id="0250"><a class="header" href="#0250">0.25.0</a></h2>
<h3 id="objectreference-is-no-longer-nullable"><a class="header" href="#objectreference-is-no-longer-nullable"><code>ObjectReference</code> is no longer nullable</a></h3>
<div id="admonition-tldr-7" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-7-title">
<div class="admonition-title">
<div id="admonition-tldr-7-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-7"></a>
</div>
<div>
<p><code>ObjectReference</code> can no longer represent a NULL reference.  Some methods of <code>ObjectReference</code> and
the write barrier functions in <code>memory_manager</code> are changed.  VM bindings need to re-implement
methods of the <code>Edge</code>, <code>ObjectModel</code> and <code>ReferenceGlue</code> traits.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>type <code>ObjectReference</code>
<ul>
<li>It can no longer represent NULL reference.
<ul>
<li>It is now backed by <code>NonZeroUsize</code>, and MMTk uses <code>Option&lt;ObjectReference&gt;</code> universally
when an <code>ObjectReference</code> may or may not exist.  It is more idiomatic in Rust.</li>
</ul>
</li>
<li>The constant <code>ObjectReference::NULL</code> is removed.</li>
<li><code>is_null()</code> is removed.</li>
<li><code>from_raw_address(addr)</code>
<ul>
<li>The return type is changed to <code>Option&lt;ObjectReference&gt;</code>.</li>
<li>It returns <code>None</code> if <code>addr</code> is not zero.</li>
<li>If you know <code>addr</code> cannot be zero, you can use the new method
<code>from_raw_address_unchecked(addr)</code>, instead.</li>
</ul>
</li>
</ul>
</li>
<li>module <code>mmtk::memory_manager</code>
<ul>
<li><strong>Only affects users of write barriers</strong></li>
<li><code>object_reference_write_pre(mutator, obj, slot, target)</code>
<ul>
<li>The <code>target</code> parameter is now <code>Option&lt;ObjectReference&gt;</code>.</li>
<li>Pass <code>None</code> if the slot was holding a NULL reference or any non-reference value.</li>
</ul>
</li>
<li><code>object_reference_write_post(mutator, obj, slot, target)</code>
<ul>
<li>Same as above.</li>
</ul>
</li>
<li><code>object_reference_write(mutator, obj, slot, target)</code>
<ul>
<li>It is labelled as <code>#[deprecated]</code> and needs to be redesigned.  It cannot handle the case
of storing a non-reference value (such as tagged small integer) into the slot.</li>
<li>Before a replacement is available, use <code>object_reference_write_pre</code> and
<code>object_reference_write_post</code>, instead.</li>
</ul>
</li>
</ul>
</li>
<li>trait <code>Edge</code>
<ul>
<li><code>load()</code>
<ul>
<li>The return type is changed to <code>Option&lt;ObjectReference&gt;</code>.</li>
<li>It returns <code>None</code> if the slot is holding a NULL reference or other non-reference
values.  MMTk will skip those slots.</li>
</ul>
</li>
</ul>
</li>
<li>trait <code>ObjectModel</code>
<ul>
<li><code>copy(from, semantics, copy_context)</code>
<ul>
<li>Previously VM bindings convert the result of <code>copy_context.alloc_copy()</code> to
<code>ObjectReference</code> using <code>ObjectReference::from_raw_address()</code>.</li>
<li>Because <code>CopyContext::alloc_copy()</code> never returns zero, you can use
<code>ObjectReference::from_raw_address_unchecked()</code> to skip the zero check.</li>
</ul>
</li>
<li><code>get_reference_when_copied_to(from, to)</code>
<ul>
<li><code>to</code> is never zero because MMTk only calls this after the destination is determined.</li>
<li>You may skip the zero check, too.</li>
</ul>
</li>
<li><code>address_to_ref(addr)</code>
<ul>
<li><code>addr</code> is never zero because this method is an inverse operation of
<code>ref_to_address(objref)</code> where <code>objref</code> is never NULL.</li>
<li>You may skip the zero check, too.</li>
</ul>
</li>
</ul>
</li>
<li>trait <code>ReferenceGlue</code>
<ul>
<li><em>Note: If your VM binding is still using <code>ReferenceGlue</code> and the reference processor and
finalization processor in mmtk-core, it is strongly recommended to switch to the
<code>Scanning::process_weak_refs</code> method and implement weak reference and finalization
processing on the VM side.</em></li>
<li><code>get_referent()</code>
<ul>
<li>The return type is changed to <code>Option&lt;ObjectReference&gt;</code>.</li>
<li>It now returns <code>None</code> if the referent is cleared.</li>
</ul>
</li>
<li><code>clear_referent()</code>
<ul>
<li>It now needs to be explicitly implemented because <code>ObjectReference::NULL</code> no longer
exists.</li>
<li>Note: The <code>Edge</code> trait does not have a method for storing NULL to a slot.  The VM
binding needs to implement its own method to store NULL to a slot.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Not API change, but worth noting:</p>
<ul>
<li>Functions that return <code>Option&lt;ObjectReference&gt;</code>
<ul>
<li><code>memory_manager::get_finalized_object</code></li>
<li><code>ObjectReference::get_forwarded_object</code>
<ul>
<li>The functions listed above did not change, as they still return
<code>Option&lt;ObjectReference&gt;</code>.  But some VM bindings used to expose them to native programs
by wrapping them into <code>extern "C"</code> functions that return <code>ObjectReference</code>, and return
<code>ObjectReference::NULL</code> for <code>None</code>.  This is no longer possible since we removed
<code>ObjectReference::NULL</code>.  The VM bindings should use
<code>mmtk::util::api_util::NullableObjectReference</code> for the return type instead.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1064">https://github.com/mmtk/mmtk-core/pull/1064</a></li>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1130">https://github.com/mmtk/mmtk-core/pull/1130</a> (for write barriers)</li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/265">https://github.com/mmtk/mmtk-openjdk/pull/265</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/273">https://github.com/mmtk/mmtk-openjdk/pull/273</a> (for write barriers)</li>
</ul>
<h3 id="instance-methods-of-objectreference-changed"><a class="header" href="#instance-methods-of-objectreference-changed">Instance methods of <code>ObjectReference</code> changed</a></h3>
<div id="admonition-tldr-8" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-8-title">
<div class="admonition-title">
<div id="admonition-tldr-8-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-8"></a>
</div>
<div>
<p>Some methods of <code>ObjectReference</code> now have a type parameter <code>&lt;VM&gt;</code>.  <code>ObjectReference::value()</code> is
removed.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>type <code>ObjectReference</code>
<ul>
<li>The following methods now require a generic argument <code>&lt;VM: VMBinding&gt;</code>:
<ul>
<li><code>ObjectReference::is_reachable</code></li>
<li><code>ObjectReference::is_live</code></li>
<li><code>ObjectReference::is_movable</code></li>
<li><code>ObjectReference::get_forwarded_object</code></li>
<li><code>ObjectReference::is_in_any_space</code></li>
<li><code>ObjectReference::is_sane</code></li>
</ul>
</li>
<li><code>ObjectReference::value()</code> is removed.
<ul>
<li>Use <code>ObjectReference::to_raw_address()</code> instead.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1122">https://github.com/mmtk/mmtk-core/pull/1122</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/272">https://github.com/mmtk/mmtk-openjdk/pull/272</a></li>
</ul>
<h3 id="the-gc-controller-aka-coordinator-is-removed"><a class="header" href="#the-gc-controller-aka-coordinator-is-removed">The GC controller (a.k.a. coordinator) is removed</a></h3>
<div id="admonition-tldr-9" class="admonition admonish-abstract" role="note" aria-labelledby="admonition-tldr-9-title">
<div class="admonition-title">
<div id="admonition-tldr-9-title">
<p>TL;DR</p>
</div>
<a class="admonition-anchor-link" href="migration/prefix.html#admonition-tldr-9"></a>
</div>
<div>
<p>The GC controller thread is removed from MMTk core.  The VM binding needs to re-implement
<code>Collection::spawn_gc_thread</code> and call <code>GCWorker::run</code> differently.</p>
</div>
</div>
<p>API changes:</p>
<ul>
<li>type <code>GCWorker</code>
<ul>
<li><code>GCWorker::run</code>
<ul>
<li>It now takes ownership of the <code>Box&lt;GCWorker&gt;</code> instance instead of borrowing it.</li>
<li>The VM binding can simply call the method <code>worker.run()</code> on the worker instance from
<code>GCThreadContext::Worker(worker)</code>.</li>
</ul>
</li>
</ul>
</li>
<li>module <code>mmtk::memory_manager</code>
<ul>
<li><code>start_worker</code>
<ul>
<li>It is now a simple wrapper of <code>GCWorker::run</code> for legacy code.  It takes ownership of
the <code>Box&lt;GCWorker&gt;</code> instance, too.</li>
</ul>
</li>
</ul>
</li>
<li>trait <code>Collection</code>
<ul>
<li><code>Collection::spawn_gc_thread</code>
<ul>
<li>It no longer asks the binding to spawn the controller thread.</li>
<li>The VM binding can simply remove the code path related to creating the controller
thread.</li>
<li>Note the API change when calling <code>GCWorker::run</code> or <code>start_worker</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>See also:</p>
<ul>
<li>PR: <a href="https://github.com/mmtk/mmtk-core/pull/1067">https://github.com/mmtk/mmtk-core/pull/1067</a></li>
<li>Example: <a href="https://github.com/mmtk/mmtk-openjdk/pull/268">https://github.com/mmtk/mmtk-openjdk/pull/268</a></li>
</ul>
</div>
<script type="text/javascript">
const isApiMigrationGuide = true;
</script>
<!--
vim: tw=100
-->
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributors"><a class="header" href="#contributors">Contributors</a></h1>
<p>This is a list of the contributors who helped writing and improving this document.
We deeply appreciate your commitment to making this work the best it can be. Thank you for your contribution.</p>
<ul>
<li>Rouane Bannister (<a href="https://github.com/rouanebannister">rouanebannister</a>)</li>
<li>Angus Atkinson (<a href="https://github.com/angussidney">angussidney</a>)</li>
<li>Brenda Wang</li>
<li>Steve Blackburn (<a href="https://github.com/steveblackburn">steveblackburn</a>)</li>
<li>Kunal Sareen (<a href="https://github.com/k-sareen">k-sareen</a>)</li>
<li>Yi Lin (<a href="https://github.com/qinsoon">qinsoon</a>)</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="assets/js/api-migration-details.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
