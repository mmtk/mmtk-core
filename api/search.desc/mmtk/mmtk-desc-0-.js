searchState.loadedDescShard("mmtk", 0, "Memory Management ToolKit (MMTk) is a portable and high …\nStatistics for the live bytes in the last GC. The …\nAn MMTk instance. MMTk allows multiple instances to run …\nMMTk builder. This is used to set options and other …\nAnalysis counters. The feature analysis allows us to …\nSome information for the current MMTk build.\nTotal accumulated bytes of live objects in the space.\nVM-to-MMTk interface: safe Rust APIs.\nConstruct an <code>MmapAnnotation::Test</code> with the current file …\nMMTk instance.\nThe options for this instance.\nGC algorithms from the MMTk suite.\nMemory policies that can be used for spaces.\nA general scheduler implementation. MMTk uses it to …\nTotal bytes used by the space, computed from <code>used_pages</code>. …\nTotal pages used by the space.\nUtilities used by other modules, including allocators, …\nMMTk-to-VM interface: the VMBinding trait.\nComma separated features enabled for this build The …\nFull build info, including MMTk’s name, version, git, …\nGit version as short commit hash, such as a96e8f9, or …\nMMTk crate version such as 0.14.0 The full version.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe endianness, given by <code>CARGO_CFG_TARGET_ENDIAN</code>.\nThe toolchain-environment, given by <code>CARGO_CFG_TARGET_ENV</code>.\nThe OS-family, given by <code>CARGO_CFG_TARGET_FAMILY</code>.\nThe operating system, given by <code>CARGO_CFG_TARGET_OS</code>.\nThe pointer width, given by <code>CARGO_CFG_TARGET_POINTER_WIDTH</code>.\nThe target architecture, given by <code>CARGO_CFG_TARGET_ARCH</code>.\nThe Continuous Integration platform detected during …\nValue of DEBUG for the profile used during compilation.\nThe features that were enabled during compilation.\nThe features as above, as lowercase strings.\nThe feature-string as above, from lowercase strings.\nThe features as a comma-separated string.\nIf the crate was compiled from within a git-repository, …\nIf the crate was compiled from within a git-repository, …\nIf the repository had dirty/staged files.\nIf the crate was compiled from within a git-repository, …\nIf the crate was compiled from within a git-repository, …\nThe host triple of the rust compiler.\nThe parallelism that was specified during compilation.\nValue of OPT_LEVEL for the profile used during compilation.\nA colon-separated list of authors.\nThe description.\nThe homepage.\nThe license.\nThe name of the package.\nThe source repository as advertised in Cargo.toml.\nThe full version.\nThe major version.\nThe minor version.\nThe patch version.\nThe pre-release version.\n<code>release</code> for release builds, <code>debug</code> for other builds.\nThe compiler that cargo resolved to use.\nThe output of …\nThe documentation generator that cargo resolved to use.\nThe output of …\nThe target triple that was being compiled for.\nThis stores some global states for an MMTK instance. Some …\nStatistics for the live bytes in the last GC. The …\nA counter that keeps tracks of the number of bytes …\nIs the current GC an emergency collection? Emergency means …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nWhen did the last GC start? Only accessed by the last …\nThe current GC status.\nIncrease the allocation bytes and return the current …\nInform that 1 stack has been scanned. The argument …\nWhether MMTk is now ready for collection. This is set to …\nIs the current GC triggered internally by MMTK? This is …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs MMTk initialized?\nReturn true if this collection was triggered by …\nIs the last GC internally triggered?\nTotal accumulated bytes of live objects in the space.\nThis stores the live bytes and the used bytes (by pages) …\nA counteer that keeps tracks of the number of bytes …\nPrepare for stack scanning. This is usually used with …\nReset collection state information.\nA counter for per-mutator stack scanning\nSet the collection kind for the current GC. This is called …\nAre the stacks scanned?\nHave we scanned all the stacks?\nTotal bytes used by the space, computed from <code>used_pages</code>. …\nTotal pages used by the space.\nIs the current GC triggered by the user?\nRegister a finalizable object. MMTk will retain the …\nAdd a reference to the list of phantom references. A …\nAdd a reference to the list of soft references. A binding …\nAdd a reference to the list of weak references. A binding …\nAdd a work packet to the given work bucket. Note that this …\nBulk add a number of work packets to the given work …\nAllocate memory for an object. For performance reasons, a …\nInvoke the allocation slow path. This is only intended for …\nRequest MMTk to create a mutator for the given thread. The …\nThe standard calloc.\nThe standard calloc except that with the feature …\nThe standard malloc except that with the feature …\nReport to MMTk that a mutator is no longer needed. All …\nFind if there is an object with VO bit set for the given …\nFlush the mutator’s local states.\nThe standard free. The <code>addr</code> in the arguments must be an …\nReturn free memory in bytes. MMTk accounts for memory in …\nThe standard free except that with the feature …\nPoll for GC. MMTk will decide if a GC is needed. If so, …\nPop all the finalizers that were registered for …\nReturn an AllocatorSelector for the given allocation …\nGet an object that is ready for finalization. After each …\nPop finalizers that were registered and associated with a …\nGet the current active malloc’d bytes. Here MMTk only …\nThe application code has requested a collection. This is …\nGeneric hook to allow benchmarks to be harnessed. We do a …\nGeneric hook to allow benchmarks to be harnessed. We stop …\nWrapper for <code>crate::mmtk::MMTK::initialize_collection</code>.\nReturn true if the <code>object</code> lies in a region of memory where\nIs the object alive?\nIs the address in the mapped memory? The runtime can use …\nCheck if <code>addr</code> is the raw address of an object reference to …\nCheck whether an object is currently pinned\nReturn the ending address of the heap. <em>Note that currently </em>…\nReturn a hash map for live bytes statistics in the last GC …\nThe standard malloc. MMTk either uses its own allocator, …\nThe <em>subsuming</em> memory region copy barrier by MMTk. This is …\nThe <em>generic</em> memory region copy <em>post</em> barrier by MMTk, which …\nThe <em>generic</em> memory region copy <em>pre</em> barrier by MMTk, which …\nInitialize an MMTk instance. A VM should call this method …\nGet the number of workers. MMTk spawns worker threads for …\nThe <em>subsuming</em> write barrier by MMTk. For performance …\nThe write barrier by MMTk. This is a <em>post</em> write barrier, …\nThe write barrier by MMTk. This is a <em>pre</em> write barrier, …\nPin an object. MMTk will make sure that the object does …\nPerform post-allocation actions, usually initializing …\nProcess MMTk run-time options. Returns true if the option …\nProcess multiple MMTk run-time options. Returns true if …\nThe standard realloc.\nThe standard realloc except that with the feature …\nAdd an externally mmapped region to the VM space. A VM …\nWrapper for <code>crate::scheduler::GCWorker::run</code>.\nReturn the starting address of the heap. <em>Note that </em>…\nReturn the total memory in bytes.\nUnpin an object. Returns true if the unpinning operation …\nReturn used memory in bytes. MMTk accounts for memory in …\nA global Mmapper for mmaping and protection of virtual …\nAn MMTk instance. MMTk allows multiple instances to run …\nMMTk builder. This is used to set options and other …\nA global VMMap that manages the mapping of spaces to …\nCall this function after the VM called the <code>fork()</code> system …\nAggregate a hash map of live bytes per space with the …\nAnalysis counters. The feature analysis allows us to …\nBuild an MMTk instance from the builder.\nPrint VM maps.  It will print the memory ranges used by …\nEnumerate objects in all spaces in this MMTK instance.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn true if a collection is in progress.\nReturn true if a collection is in progress and past the …\nGet the run time options.\nGet a reference to the plan.\nGet the plan as mutable reference.\nThe application code has requested a collection. This is …\nGeneric hook to allow benchmarks to be harnessed. MMTk …\nGeneric hook to allow benchmarks to be harnessed. MMTk …\nInitialize the GC worker threads that are required for …\nInitialize object metadata for a VM space object. Objects …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn true if the current GC is an emergency GC.\nReturn true if the current GC is trigger manually by the …\nCreate an MMTK builder with options read from environment …\nCreate an MMTK instance. This is not public. Bindings …\nCreate an MMTK builder with build-in default options, but …\nThe options for this instance.\nPrepare an MMTk instance for calling the <code>fork()</code> system …\nSet an option.\nSet multiple options by a string. The string should be …\nCustom VM layout constants. VM bindings may use this …\nMMTK has requested stop-the-world activity (e.g., stw …\nAllocation semantics that MMTk provides. Each allocation …\nBarrierSelector describes which barrier to use.\nCode objects have execution permission. Note that this is …\nThe default semantic. This means there is no specific …\nThe plan constraints for the generational copying plan.\nThe plan constraints for the generational immix plan.\nThe plan constraints for the immix plan.\nImmortal objects will not be reclaimed. MMTk still traces …\nLos + Code.\nLarge objects. It is usually desirable to allocate large …\nThe plan constraints for the mark compact plan.\nThe plan constraints for the mark sweep plan.\nA mutator is a per-thread data structure that manages …\nEach GC plan should provide their implementation of a …\nThe plan constraints for the no gc plan.\nNo barrier is used.\nNon moving objects will not be moved by GC.\nObject remembering barrier is used.\nThis trait represents an object queue to enqueue objects …\nA transitive closure visitor to collect the slots from …\nThe plan constraints for the page protect plan.\nA plan describes the global core functionality for all …\nThis struct defines plan-specific constraints. Most of the …\nRead-only objects cannot be mutated once it is initialized.\nThe plan constraints for the semispace plan.\nThe plan constraints for the sticky immix plan.\nA vector queue for object references.\nAn implementation of <code>ObjectQueue</code> using a <code>Vec</code>.\nAllocate memory for an object.\nThe slow path allocation. This is only useful when the …\nGet active barrier trait object\nHolds some thread-local states for the barrier.\nThe barrier this plan uses. A binding may check this and …\nRead/Write barrier implementations.\nGet a immutable reference to the base plan. <code>BasePlan</code> is …\nGet a mutable reference to the base plan. <code>BasePlan</code> is …\nEnqueued nodes.\nEnqueued nodes.\nAsk the plan if they would trigger a GC. If MMTk is in …\nDoes the plan collect garbage? Obviously most plans do, …\nGet the plan constraints for the plan. This returns a …\nReturn whether the current GC may move any object.  The VM …\nEnqueue an object into the queue.\nGenerational plans (with a copying nursery) Generational …\nGet the allocator mapping between …\nGet the mutator thread for this mutator context. This is …\nGet the number of pages that are used.\nThe global part of a plan implementation.\nPlan: marksweep\nSize (in bytes) beyond which copied objects must be copied …\nSize (in bytes) beyond which new regular objects must be …\nSome plans may allow benign race for testing mark bit, and …\nTrue if the plan moves objects.\nMutator context for each application thread.\nThe mutator thread that is bound with this Mutator struct.\nTrue if this plan requires concurrent worker threads. This …\nSome policies do object forwarding after the first …\nTrue if this plan requires linear scanning. This is unused …\nDoes this plan use the log bit? See …\nSome (in fact, most) plans do nothing when preparing …\nPlan: nogc (allocation-only)\nPlan: pageprotect\nPlan-specific constraints.\nPerform post-allocation actions.  For many allocators none …\nPrepare the plan before a GC. This is invoked in an …\nDo the prepare work for this mutator.\nRelease the plan after transitive closure. A plan can …\nDo the release work for this mutator.\nSchedule work for the upcoming GC.\nPlan: semispace\nSticky plans (using sticky marks for generational …\nThis module contains code useful for tracing, i.e. …\nA barrier is a combination of fast-path behaviour + …\nBarrierSelector describes which barrier to use.\nA barrier semantics defines the barrier slow-path …\nEmpty barrier implementation. For GCs that do not need any …\nNo barrier is used.\nGeneric object barrier with a type argument defining it’…\nObject remembering barrier is used.\nReturns a boxed object from a boxed trait object if the …\nReturns a mutable reference to the object within the trait …\nReturns an <code>Rc</code>-ed object from an <code>Rc</code>-ed trait object if the …\nReturns a reference to the object within the trait object …\nA const function to check if two barrier selectors are the …\nFlush thread-local buffers or remembered sets. Normally …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if the trait object wraps an object of type …\nAttepmt to atomically log an object. Returns true if the …\nSubsuming barrier for array copy\nFull post-barrier for array copy\nFull pre-barrier for array copy\nSlow-path call for mempry slice copy operations. For …\nAttepmt to atomically log an object. Returns true if the …\nA pre-barrier indicating that some fields of the object …\nObject will probably be modified\nSubsuming barrier for object reference write\nFull post-barrier for object reference write\nFull pre-barrier for object reference write\nSlow-path call for object field write operations.\nObject reference write slow-path call. This can be called …\nThis data structure lets mutators trigger GC.\nClear the “GC requested” flag so that mutators can …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nRequest a GC.  Called by mutators when polling (during …\nSet by mutators to trigger GC.  It is atomic so that …\nBarrier overhead measurement:\nFull heap collection as nursery GC.\nConstraints for generational plans. Each generational plan …\nGenerational read/write barrier implementations.\nGenerational copying (GenCopy) Plan: generational copying\nReturns the argument unchanged.\nGenerational immix (GenImmix) Plan: generational immix\nCalls <code>U::from(self)</code>.\nCreate global side metadata specs for generational plans. …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nMMTk instance\nObject modbuf. Contains a list of objects that may contain …\nGenerational plan\nArray-copy modbuf. Contains a list of sub-arrays or array …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the generational copying plan.\nReturns the argument unchanged.\nReturn the number of pages available for allocation. …\nCalls <code>U::from(self)</code>.\nProcess edges for a nursery GC. This type is provided if a …\nThe modbuf contains a list of objects in mature space(s) …\nThe array-copy modbuf contains a list of array slices in …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nA list of <code>(start_address, bytes)</code> tuple.\nCommon implementation for generational plans. Each …\nThis trait includes methods that are specific to …\nThis trait is the extension trait for <code>GenerationalPlan</code> …\nCheck if we need a GC based on the nursery space usage. …\nThe common plan.\nForce the next collection to be full heap.\nReturns the argument unchanged.\nIs this GC full heap?\nGet pages reserved for the collection by a generational …\nReturn the number of pages available for allocation into …\nReturn the number of used pages in the mature space.\nGet pages used by a generational plan. A generational plan …\nCalls <code>U::from(self)</code>.\nIs the address in the nursery? As we only know addresses …\nIs the current GC a nursery GC? If a GC is not a nursery …\nIs the current GC a nursery GC?\nIs current GC only collecting objects allocated since last …\nIs the object in the nursery?\nReturn whether last GC is a full GC.\nIs next GC full heap?\nThe nursery space.\nPrepare Gen. This should be called by a single thread in …\nRelease Gen. This should be called by a single thread in …\nCheck if we should do a full heap GC. It returns true if …\nSet next_gc_full_heap to the given value.\nCheck a plan to see if the next GC should be a full heap …\nTrace an object in nursery collection. If the object is in …\nTrace objects for spaces in generational and common plans …\nIndependent of how many pages remain in the page budget (a …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the generational immix plan.\nGenerational immix. This implements the functionality of a …\nReturns the argument unchanged.\nGenerational plan, which includes a nursery space and …\nReturn the number of pages available for allocation. …\nAn immix space as the mature space.\nCalls <code>U::from(self)</code>.\nWhether the last GC was a defrag GC for the immix space.\nWhether the last GC was a full heap GC\nAllocation semantics that MMTk provides. Each allocation …\nBasePlan should contain all plan-related state and …\nCode objects have execution permission. Note that this is …\nCommonPlan is for representing state and features used by …\nArgs needed for creating any plan. This includes a set of …\nArgs needed for creating a specific plan. This includes …\nThe default semantic. This means there is no specific …\nA trait for anything that contains spaces. Examples …\nImmortal objects will not be reclaimed. MMTk still traces …\nLos + Code.\nLarge objects. It is usually desirable to allocate large …\nNon moving objects will not be moved by GC.\nA plan describes the global core functionality for all …\nA plan that uses <code>PlanProcessEdges</code> needs to provide an …\nRead-only objects cannot be mutated once it is initialized.\nGet a immutable reference to the base plan. <code>BasePlan</code> is …\nGet a mutable reference to the base plan. <code>BasePlan</code> is …\nAsk the plan if they would trigger a GC. If MMTk is in …\nGet the common plan. CommonPlan is included by most of …\nGet the common plan. CommonPlan is included by most of …\nGet the plan constraints for the plan. This returns a …\nCreate a copy config for this plan. A copying GC plan MUST …\nCreate a copy config for this plan. A copying GC plan MUST …\nCreate thread local GC worker.\nReturn whether the current GC may move any object.  The VM …\nReturns a boxed object from a boxed trait object if the …\nReturns a mutable reference to the object within the trait …\nReturns an <code>Rc</code>-ed object from an <code>Rc</code>-ed trait object if the …\nReturns a reference to the object within the trait object …\nInform the plan about the end of a GC. It is guaranteed …\nInform the plan about the end of a GC. It is guaranteed …\nVisit each space field immutably.\nVisit each space field mutably.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn a reference to <code>GenerationalPlan</code> to allow access …\nReturn a reference to <code>GenerationalPlan</code> to allow access …\nGet the allocator mapping between …\nGet the number of pages that are still available for use. …\nGet the number of pages that are still available for use. …\nGet the number of pages that are reserved for collection. …\nGet the number of pages that are reserved for collection. …\nGet the number of pages that are NOT used. This is clearly …\nGet the number of pages that are NOT used. This is clearly …\nGet the number of pages that are reserved, including pages …\nGet the number of pages that are reserved, including pages …\nGet a PlanCreateSpaceArgs that can be used to create a …\nGet the total number of pages for the heap.\nGet the total number of pages for the heap.\nGet the number of pages that are used.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if the trait object wraps an object of type …\nReturn whether last GC was an exhaustive attempt to …\nReturn whether last GC was an exhaustive attempt to …\nWhether objects in this plan may move. If any of the …\nNotify the plan that an emergency collection will happen. …\nNotify the plan that an emergency collection will happen. …\nGet the current run time options.\nGet the current run time options.\nPost-scan objects in the plan. Each object is scanned by …\nPrepare the plan before a GC. This is invoked in an …\nPrepare a worker for a GC. Each worker has its own prepare …\nPrepare a worker for a GC. Each worker has its own prepare …\nRelease the plan after transitive closure. A plan can …\nAn object is firstly reached by a sanity GC. So the object …\nAn object is firstly reached by a sanity GC. So the object …\nSchedule work for the upcoming GC.\nTrace objects in the plan. Generally one needs to figure …\nCall <code>space.verify_side_metadata_sanity</code> for all spaces in …\nCall <code>space.verify_side_metadata_sanity</code> for all spaces in …\nA VM space is a space allocated and populated by the VM.  …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the immix plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSchedule a full heap immix collection. This method is used …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\niterate through the heap and calculate the new location of …\ncompact live objects based on forwarding pointers …\nForwarding trace\nMarking trace\ncreate another round of root scanning work packets to …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the mark compact plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the mark sweep plan.\nAbandoned blocks. If a mutator dies, all its blocks go to …\nAbandoned blocks during a GC. Each allocator finishes …\nAllocation status for all chunks in MS space\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCount the number of pending <code>ReleaseMarkSweepSpace</code> and …\nWork packet scheduler\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nA mutator is a per-thread data structure that manages …\nEach GC plan should provide their implementation of a …\nThis is used for plans to indicate the number of …\nAllocate memory for an object.\nThe slow path allocation. This is only useful when the …\nGet the allocator for the selector.\nGet the allocator of a concrete type for the selector.\nGet the mutable allocator of a concrete type for the …\nMapping between allocation semantics and allocator selector\nGet the mutable allocator for the selector.\nGet active barrier trait object\nHolds some thread-local states for the barrier.\nCreate an allocator mapping for spaces in Common/BasePlan …\nCreate a space mapping for spaces in Common/BasePlan for a …\nFlush the mutator context.\nFlush the mutator context.\nFlush per-mutator remembered sets and create GC work for …\nFlush per-mutator remembered sets and create GC work for …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet all the valid allocator selector (no duplicate)\nReturn the base offset from a mutator pointer to the …\nGet the mutator thread for this mutator context. This is …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe mutator thread that is bound with this Mutator struct.\nA place-holder implementation for …\nInform each allocator about destroying. Call …\nPerform post-allocation actions.  For many allocators none …\nDo the prepare work for this mutator.\nPlan-specific code for mutator prepare. The VMWorkerThread …\nDo the release work for this mutator.\nPlan-specific code for mutator release. The VMWorkerThread …\nMapping between allocator selector and spaces. Each pair …\nA place-holder implementation for …\nA place-holder implementation for …\ncheck if the number of each allocator is okay. Panics if …\nThe plan constraints for the no gc plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nWhen nogc_multi_space is disabled, force all the …\nWe use three bump allocators when enabling …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the page protect plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a mutator instance. Every object is allocated to …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe default plan constraints. Each plan should define …\nThis struct defines plan-specific constraints. Most of the …\nThe barrier this plan uses. A binding may check this and …\nDoes the plan collect garbage? Obviously most plans do, …\nA const function to create the default plan constraints.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSize (in bytes) beyond which copied objects must be copied …\nSize (in bytes) beyond which new regular objects must be …\nSome plans may allow benign race for testing mark bit, and …\nTrue if the plan moves objects.\nTrue if this plan requires concurrent worker threads. This …\nSome policies do object forwarding after the first …\nTrue if this plan requires linear scanning. This is unused …\nDoes this plan use the log bit? See …\nSome (in fact, most) plans do nothing when preparing …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the semispace plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe plan constraints for the sticky immix plan.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReserve a capacity of this on first enqueue to avoid …\nThis trait represents an object queue to enqueue objects …\nA transitive closure visitor to collect the slots from …\nA vector queue for object references.\nAn implementation of <code>ObjectQueue</code> using a <code>Vec</code>.\nEnqueued nodes.\nEnqueued nodes.\nEnqueue an object into the queue.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConsume this <code>VectorObjectQueue</code> and return its underlying …\nReturn <code>true</code> if the queue is empty.\nCheck if the buffer size reaches <code>CAPACITY</code>.\nCreate an empty <code>VectorObjectQueue</code>.\nCreate an <code>ObjectsClosure</code>.\nPush an element to the queue. If the queue is empty, it …\nReturn the contents of the underlying vector.  It will …\nCopy context defines the thread local copy allocator for …\nPolicy specific GC work\nMark sweep space. MMTk provides two implementations of …\nThis class defines and manages spaces.  Each policy is an …\nA GC worker’s copy allocator for copying GCs. Each …\nThis type implements a simple copying space.\nCopy allocator for CopySpace\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThis trait defines policy-specific behavior for tracing …\nUsed to identify the trace if a policy has different kinds …\nReturn whether the policy moves objects.\nPolicy-specific post-scan-object hook.  It is called after …\nTrace object in the policy. If the policy copies objects, …\nMark/sweep memory for block-level only\nDo we allow Immix to do defragmentation?\nMark every allocated block as defragmentation source …\nPercentage of heap size reserved for defragmentation. …\nMark lines when scanning objects. Otherwise, do it at mark …\nThe max object size for immix: half of a block\nIn some cases/settings, Immix may never move objects. …\nIf Immix is used as a nursery space, do we prefer copy?\nMake every GC a defragment GC. (for debugging)\nData structure to reference an immix block.\nThe block allocation state.\nBlock defrag state table (side)\nLines in block\nLog lines in block\nLog pages in block\nPrivate constant\nBlock mark table (side)\nPrivate constant\nPrivate constant\nthe block is allocated and marked.\nPages in block\nthe block is marked as reusable.\nA non-block single-linked list to store blocks.\nthe block is not allocated.\nthe block is allocated but not marked.\nGet the chunk containing the block.\nClear VO bits metadata for unmarked regions. This is …\nDeinitalize a block before releasing.\nFlush the block queue\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the number of holes.\nGet block mark state.\nInitialize a clean block after acquired from page-resource.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTest if the block is marked for defragmentation.\nTest if the block is reuasable.\nIterate all the blocks in the queue. Call the visitor for …\nGet number of blocks in this list.\nGet the address range of the block’s line mark table.\nGet the range of lines within the block.\nCreate empty block list\nPop a block out of the list.\nAdd a block to the list.\nClear the list.\nMark the block for defragmentation.\nRecord the number of holes in the block.\nSet block mark state.\nSweep this block. Return true if the block is swept.\nReport back a completed mark histogram\nThe number of remaining clean pages in defrag space.\nDetermine whether the current GC should do defragmentation.\nGet the number of defrag headroom pages.\nIs defrag space exhausted?\nA block with number of holes greater than this threshold …\nCalculate the defrag threshold.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the numebr of all the recyclable lines in all the …\nCheck if the current GC is a defrag GC.\nIs current GC a defrag GC?\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nA list of completed mark histograms reported by workers\nAllocate a new local histogram.\nUpdate available_clean_pages_for_defrag counter when a …\nPrepare work. Should be called in ImmixSpace::prepare.\nReset the in-defrag state.\nCheck if the defrag space is exhausted.\nClear unmarked blocks, only.\nA work packet to clear VO bit metadata after Prepare.\nCount number of remaining work pacets, and flush page …\nClear all VO bits in all blocks.\nNormal immix copy context. It has one copying Immix …\nHybrid Immix copy context. It includes two different immix …\nSome arguments for Immix Space.\nClear unmarked lines, only.  (i.e. lines with line mark …\nA work packet to prepare each block for a major GC. …\nChunk sweeping work packet.\nAtomically mark an object.\nAllocation status for all chunks in immix space\ncheck if the current GC should do defragmentation.\nDefrag utilities\nGet the number of defrag headroom pages.\nThis is called when a GC finished. Return whether this GC …\nA destructor invoked when all <code>SweepChunk</code> packets are …\nCalled after a related work packet is finished.\nFlush the thread-local queues in BlockPageResource\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGenerate chunk sweep tasks\nAllocate a clean block.\nHole searching.\nPop a reusable block from the reusable block list.\nCheck if current GC is a defrag GC.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if an object is marked.\nCheck if an object is pinned.\nCurrent line mark state\nLine mark state in previous GC\nHow many lines have been consumed since last GC?\nMark all the lines that the given object spans.\nObject mark state\nWhether this ImmixSpace instance contains both young and …\nPost copy routine for Immix copy contexts\nRelease for the immix space.\nRelease a block.\nReset log bit at the start of a major GC. Normally we do …\nClear object mark table\nA list of all reusable blocks\nGet work packet scheduler\nWork packet scheduler\nGet side metadata specs\nSome settings for this space\nTrace object and do evacuation if required.\nTrace and mark objects without evacuation.\nMark an object as unlogged when we trace an object. …\nData structure to reference a line within an immix block.\nLine mark table (side)\nGet the block containing the line.\nReturns the argument unchanged.\nGet line index within its containing block.\nCalls <code>U::from(self)</code>.\nTest line mark state.\nMark the line. This will update the side line mark table.\nMark all lines the object is spanned to.\nThis type implements a simple immortal collection policy. …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nIs this used as VM space? If this is used as VM space, we …\nThis type implements a policy for large objects. Each …\nAllocate an object\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck if a given object is in nursery\nTest if the object’s mark bit is the same as the given …\nThis type implements a lock free version of the immortal …\nHeap range start\nReturns the argument unchanged.\nGet the name of the space\nCalls <code>U::from(self)</code>.\nHeap range end\nZero memory after slow-path allocation\nstart of this space\nTotal bytes for the space\nWe have to override the default implementation because …\nFor each MarkCompact object, we need one extra word for …\nWe need one extra header word for each object. Considering …\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet header forwarding pointer for an object\nGet the address for header forwarding pointer\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nLinear scan all the live objects in the given memory region\nStore header forwarding pointer for an object\nMalloc mark sweep. This uses <code>MallocSpace</code> and …\nNative mark sweep. This uses <code>MarkSweepSpace</code> and …\nSimple work packet that just sweeps a single chunk\nThis space uses malloc to get new memory, and performs …\nClean up for an empty chunk\nUsed when each chunk is done. Only called in debug build.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGiven an object in MallocSpace, return its malloc address, …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nFor malloc space, we just use the side metadata.\nWork packet scheduler\nSet multiple pages, starting from the given address, for …\nThis sweep function is called when the mark bit sits in …\nThis function is called when the mark bits sit on the side …\nSweep an object if it is dead, and unset page marks for …\nUnset multiple pages, starting from the given address, for …\nMetadata spec for the active chunk byte\nMetadata spec for the active page byte\nLock to synchronize the mapping of side metadata for a …\nMaximum metadata address for the …\nSet the page mark from 0 to 1. Return true if we set it …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCheck if there is an object allocated by malloc at the …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if a given object was allocated by malloc\nCheck if metadata is mapped for a range [addr, addr + …\nCheck if metadata is mapped for a given address. We check …\nIs this allocation an offset malloc? The argument address …\nLoad u128 bits of side metadata\nEagerly map the active chunk metadata surrounding …\nWe map the active chunk metadata (if not previously …\nSet the offset bit for the allocation. The argument …\nUnset the offset bit for the allocation. The argument …\nA 64KB region for MiMalloc. This is also known as MiMalloc …\nThe block allocation state.\nLog pages in block\nPrivate constant\nBlock mark table (side)\nPrivate constant\nPrivate constant\nthe block is allocated and marked.\nthe block is not allocated.\nthe block is allocated but not marked.\nRelease this block if it is unmarked. Return true if the …\nGet the chunk containing the block.\nDeinitalize a block before releasing.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet block mark state.\nInitialize a clean block after acquired from page-resource.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThis is a naive implementation that is inefficient but …\nSet block mark state.\nThis implementation uses object reference and cell address …\nSweep the block. This is done either lazily in the …\nList of blocks owned by the allocator\nAll the bins for the block lists\nThe largest valid bin.\nThe object size for the last bin. We should not try …\nNumber of bins in BlockLists. Reserve bin0 as an empty bin.\npointer size in bits\nLog2 of pointer size\npointer size in bytes\nLargest object size allowed with our mimalloc …\nLargest object size in words\nMoves all the blocks of <code>other</code> into <code>self</code>, leaving <code>other</code> …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nList has no blocks\nGet an iterator for the block list.\nLock the list. The MiMalloc allocator mostly uses …\nAlign a byte size to a size in machine words i.e. byte …\nCreate an empty set of block lists of different size …\nReturns how many pages the block lists uses.\nPop the first block in the list\nPush block to the front of the list\nRelease unmarked blocks, and sweep other blocks in the …\nRelease unmarked blocks, and do not sweep any blocks. Used …\nRemove a block from the list\nRemove all blocks\nUnlock list. See the comments on the lock method.\nAn available block. The block can be directly used if …\nAn unswept block. The block needs to be swept first before …\nThe result for <code>MarkSweepSpace.acquire_block()</code>. …\nA new block we just acquired from the page resource\nA mark sweep space.\nChunk sweeping work packet.  Only used by eager sweeping …\nAbandoned blocks. If a mutator dies, all its blocks go to …\nAbandoned blocks during a GC. Each allocator finishes …\nMark an object.  Return <code>true</code> if the object is newly …\nMark an object atomically.\nMark an object non-atomically.  If multiple GC worker …\nAllocation status for all chunks in MS space\nA destructor invoked when all <code>SweepChunk</code> packets are …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCount the number of pending <code>ReleaseMarkSweepSpace</code> and …\nRelease a block.\nWork packet scheduler\nPrint debug info for SFT. Should be false when committed.\nAn empty entry for SFT.\nSpace Function Table (SFT).\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet forwarding pointer if the object is forwarded.\nInitialize object metadata (in the header, or in the side …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs the object managed by MMTk? For most cases, if we find …\nIs the object live, determined by the policy?\nIs <code>addr</code> a valid object reference to an object allocated in …\nIs the object movable, determined by the policy? E.g. the …\nIs the object reachable, determined by the policy? Note: …\nIs the object sane? A policy should return false if there …\nThe space name\nTrace objects through SFT. This along with <code>SFTProcessEdges</code> …\nWe store raw pointer as a double word using atomics. We …\nSFTMap manages the SFT table, and mapping between …\nThe raw pointer for SFT. We expect a space to provide this …\nThe type we store SFT raw pointer as. It basically just …\nClear SFT for the address. The address must have a valid …\nEagerly initialize the SFT table. For most …\nReturns the argument unchanged.\nGet SFT for the address. The address can be arbitrary. For …\nGet the side metadata spec this SFT map uses.\nGet SFT for the address. The address must have a valid SFT …\nCheck if the address has an SFT entry in the map …\nCalls <code>U::from(self)</code>.\nNotify the SFT map for space creation. <code>DenseChunkMap</code> needs …\nA check at boot time to ensure <code>SFTRefStorage</code> is correct.\nSet SFT for the address range. The address must have a …\nEmpty space is at index 0\nSFTDenseChunkMap is a small table. It has one entry for …\nReturns the argument unchanged.\nA map from space name (assuming they are unique) to their …\nCalls <code>U::from(self)</code>.\nThe dense table, one entry per space. We use side metadata …\nSpace map is a small table, and it has one entry for each …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCreate a new space map.\nThe chunk map is a sparse table. It has one entry for each …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nUpdate SFT map for the given address range. It should be …\nArguments passed from a plan to create a space.\nArguments passed from a policy to create a space. This …\nA lock used during acquire() to make sure only one thread …\nReturn the number of physical pages available.\nFor a copying space that allows sft_trace_object(), this …\nReturns a boxed object from a boxed trait object if the …\nReturns a mutable reference to the object within the trait …\nReturns an <code>Rc</code>-ed object from an <code>Rc</code>-ed trait object if the …\nReturns a reference to the object within the trait object …\nEnsure this space is marked as mapped – used when the …\nEnumerate objects in the current space.\nEstimate the amount of side metadata memory needed for a …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThis is called after we get result from page resources.  …\nInitialize entires in SFT map for the space. This is …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTurning PlanCreateSpaceArgs into a PolicyCreateSpaceArgs\nReturns true if the trait object wraps an object of type …\nGet a mutable reference to the underlying page resource, …\nThis field equals to needs_log_bit in the plan constraints.\nPrint the VM map for a space. Space needs to be …\nWhat copy semantic we should use for this space if we copy …\nEnsure that the current space’s metadata context does …\nA check for the obvious out-of-memory case: if the …\nA special space for VM/Runtime managed memory. The …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCompute the forwarding addresses of objects …\nClear the VO bit metadata.  Mainly used by ImmixSpace.\nCompute the transtive closure following only strong …\nCompact objects (mark-compact-only).\nResume mutators and end GC.\nResurrect Java-style finalizable objects, and potentially …\nUpdate the list of Java-style finalization cadidates and …\nThis defines a GC work packet which are assigned to the …\nA GC worker.  This part is privately owned by a worker …\nHandle Java-style phantom references.\nTrace (non-transitively) pinning roots. Objects pointed by …\nPreparation work.  Plans, spaces, GC workers, mutators, …\nAn abstract trait for work packets that process object …\nUpdate Java-style weak references after computing …\nWork packets that should be done just before GC shall go …\nThe work packet type for scanning objects when using this …\nScan roots again to initiate another transitive closure to …\nHandle Java-style soft references, and potentially expand …\nCompute the transtive closure starting from transitively …\nThis bucket is always open.\nThe associate type for the VM.\nLet the VM handle VM-specific weak data structures, …\nLet the VM handle the forwarding of reference fields in …\nHandle Java-style weak references.\nThis enum defines all the work bucket types. The scheduler …\nThe copy context, used to implement copying GC.\nCreate an object-scanning work packet to be used for this …\nDefine the work for this packet. However, this is not …\nLocal work packet queue.\nThe reference to the MMTk instance.\nCreate a <code>ProcessEdgesWork</code>.\nThe ordinal of the worker, numbered from 0 to the number …\nThe reference to the scheduler.\nReference to the shared part of the GC worker.  It is used …\nStatistics for work packets\nThe VM-specific thread-local state of the GC thread.\nTrace an MMTk object. The implementation should forward …\nCounter for work packets\nThis module contain “goals” which are larger than work …\nThis module contains <code>WorkerMonitor</code> and related types.  It …\nRepresents the ID of a logical CPU on a system.\nBind the current thread to the specified core.\nReturn the total number of cores allocated to the program.\nThe maximum number of slots that should be put to one of …\nThe maximum number of slots that should be put to one of …\nThe associated ProcessEdgesWork for processing the …\nBuffer size for <code>ProcessEdgesWork</code> work packets. This …\nDo we update object reference? This has to be true for a …\nDo we update object reference? This has to be true for a …\nThis provides an implementation of …\nThis is an alternative to <code>ScanObjects</code> that calls the …\nThe global GC Preparation Work This work packet invokes …\nThe collector GC Preparation Work\nThe mutator GC Preparation Work\nAn abstract trait for work packets that process object …\nAn implementation of <code>RootsWorkFactory</code> that creates work …\nThis implements <code>ObjectTracer</code> by forwarding the <code>trace_object</code>…\nThis type implements <code>ObjectTracerContext</code> by creating a …\nThis work packet processes pinning roots.\nThe global GC release Work This work packet invokes …\nThe collector release Work\nThe mutator release Work\nFor USDT tracepoints for roots. Keep in sync with …\nIf true, we do object scanning in this work packet with …\nIf true, we do object scanning in this work packet with …\nA general implementation of <code>ProcessEdgesWork</code> using SFT. A …\nScan objects and enqueue the slots of the objects.  For …\nTrait for a work packet that scans objects\nThe work packet type for scanning objects when using this …\nA short-hand for <code>&lt;E::VM as VMBinding&gt;::VMSlot</code>.\nStop all mutators\nA <code>ProcessEdgesWork</code> type that panics when any of its method …\nThe associate type for the VM.\nDelegate to the VM binding for forwarding weak references.\nThis work packet calls <code>Collection::post_forwarding</code>.\nDelegate to the VM binding for weak reference processing.\nIf the work includes roots, we will store the roots …\nIf the work includes roots, we will store the roots …\nCreate an object-scanning work packet to be used for this …\nThe common code for ScanObjects and PlanScanObjects.\nFlush the nodes in ProcessEdgesBase, and create a …\nFlush the nodes in ProcessEdgesBase, and create a …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn the work bucket for this work packet and its …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a <code>ProcessEdgesWork</code>.\nPop all nodes from nodes, and clear nodes to an empty …\nCalled after each object is scanned.\nProcess a slot, including loading the object reference …\nProcess a slot, including loading the object reference …\nProcess all the slots in the work packet.\nProcess all the slots in the work packet.\nStart the a scan work packet. If SCAN_OBJECTS_IMMEDIATELY, …\nStart the a scan work packet. If SCAN_OBJECTS_IMMEDIATELY, …\nTrace an MMTk object. The implementation should forward …\nForward the <code>trace_object</code> call to the underlying …\nAdd the <code>ScheduleCollection</code> packet.  Called by the last …\nHow to assign the affinity of each GC thread. Specified by …\nCheck if all the work buckets are empty\nFind more work for workers to do.  Return true if more …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalled when GC has finished, i.e. when all work packets …\nCalled when the last worker parked.  <code>goal</code> allows this …\nCalled by workers to get a schedulable work packet. Park …\nGet a schedulable work packet.\nGet a schedulable work packet without retry.\nRequest a GC to be scheduled.  Called by mutator via …\nResolve the affinity of a thread.\nRespawn GC threads after forking.  This will reuse the …\nRespond to a worker reqeust.\nSchedule all the common work packets\nSchedule “sentinel” work packets for all activated …\nCreate GC threads for the first time.  It will also create …\nAsk all GC workers to exit for forking.\nSurrender the <code>GCWorker</code> struct of a GC worker when it exits.\nOpen buckets if their conditions are met.\nWork buckets\nWorkers\nFor synchronized communication between workers and with …\nMerge and print the work-packet level statistics from all …\nDescribing a single work packet\nWorker thread local counterpart of <code>SchedulerStat</code>\nStop all work counters for the work packet type of the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nUsed during statistics printing at …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMeasure the execution of a work packet by starting all …\nMerge work counters from different worker threads\nCollect work counters from work threads. Two dimensional …\nCount the number of work packets executed for different …\nMap work packet type IDs to work packet names\nExtract the work-packet name from the full type name. i.e. …\nThe <code>ProcessEdgesWork</code> implementation to use for tracing …\nThis defines a GC work packet which are assigned to the …\nThis trait provides a group of associated types that are …\nThe <code>ProcessEdgesWork</code> implementation to use for tracing …\nDefine the work for this packet. However, this is not …\nDo work and collect statistics. This internally calls …\nDo work and collect statistics. This internally calls …\nGet the compile-time static type name for the work packet.\nGet the compile-time static type name for the work packet.\nCompute the forwarding addresses of objects …\nClear the VO bit metadata.  Mainly used by ImmixSpace.\nCompute the transtive closure following only strong …\nCompact objects (mark-compact-only).\nResume mutators and end GC.\nResurrect Java-style finalizable objects, and potentially …\nUpdate the list of Java-style finalization cadidates and …\nHandle Java-style phantom references.\nTrace (non-transitively) pinning roots. Objects pointed by …\nPreparation work.  Plans, spaces, GC workers, mutators, …\nUpdate Java-style weak references after computing …\nWork packets that should be done just before GC shall go …\nScan roots again to initiate another transitive closure to …\nHandle Java-style soft references, and potentially expand …\nCompute the transtive closure starting from transitively …\nThis bucket is always open.\nLet the VM handle VM-specific weak data structures, …\nLet the VM handle the forwarding of reference fields in …\nHandle Java-style weak references.\nThis enum defines all the work bucket types. The scheduler …\nEnable the bucket\nAdd a work packet to this bucket\nAdd a work packet to this bucket\nLike <code>WorkBucket::add_no_notify</code>, but the work is boxed.\nAdd a work packet to this bucket, but do not notify any …\nAdd a work packet to this bucket Panic if this bucket …\nAdd multiple packets\nAdd multiple packets with a higher priority. Panic if this …\nDisable the bucket\nThe first stop-the-world bucket.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTest if the bucket is drained\nGet a work packet from this bucket\nAfter this bucket is activated and all pending work …\nAn abstraction of work counters\nCommon struct for different work counters\nMake <code>WorkCounter</code> trait objects cloneable\nMeasure the durations of work packets\nClone the object\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn a reference to <code>WorkCounterBase</code>\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMerge two <code>WorkCounterBase</code>, keep the semantics of the …\nMerge two <code>WorkCounterBase</code>, modify the current object in …\nUpdate the object based on a single value\nName of counter\nStart the counter\nStop the counter\nContains the error value\nA GC worker.  This part is privately owned by a worker …\nThe struct has one instance per worker, but is shared …\nThe initial state.  <code>GCWorker</code> structs have not been created …\nContains the success value\nThe result type of <code>GCWorker::pool</code>. Too many functions …\nAll worker threads are spawn and running.  <code>GCWorker</code> …\nWorker threads are stopping, or have already stopped, for …\nRepresents the ID of a GC worker thread.\nCurrent worker’s ordinal\nStateful part of <code>WorkerGroup</code>.\nA worker group to manage all the GC workers.\nA special error type that indicate a worker should exit. …\nAdd a work packet to the work queue. If the bucket is …\nAdd a work packet to the work queue and mark it with a …\nThe copy context, used to implement copying GC.\nCreate <code>GCWorker</code> instances.\nGet current worker ordinal. Return <code>None</code> if the current …\nA queue of GCWork that can only be processed by the owned …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the live bytes data from the worker, and clear the …\nGet a mutable reference of the copy context for this …\nReturn true if there’re any pending designated work\nSpawn GC worker threads for the first time.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nAccumulated bytes for live objects in this GC. When each …\nLocal work packet queue.\nThe reference to the MMTk instance.\nCreate a WorkerGroup\nThe ordinal of the worker, numbered from 0 to the number …\nPoll a ready-to-execute work packet in the following order:\nPrepare the buffer for workers to surrender their <code>GCWorker</code> …\nRespawn GC threads after stopping for forking.\nEntry point of the worker thread.\nGet the scheduler. There is only one scheduler per MMTk …\nThe reference to the scheduler.\nReference to the shared part of the GC worker.  It is used …\nSpawn all the worker threads\nWorker-local statistics data.\nThe stateful part.  <code>None</code> means state transition is …\nHandle for stealing packets from the current worker\nReturn the <code>GCWorker</code> struct to the worker group. This …\nThe VM-specific thread-local state of the GC thread.\nGet the number of workers in the group\nShared worker data\nThe local work queues for to-be-created workers.\n<code>GCWorker</code> instances not currently owned by active GC worker …\nDo a garbage collection.\nStop all GC threads so that the VM can call <code>fork()</code>.\nA goal, i.e. something that workers should work together …\nThis current and reqeusted goals.\nGet the current goal if exists.\nThe current goal.\nTest if the given <code>goal</code> is requested.  Used for debug …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalled when the current goal is completed.  This will …\nMove the highest priority goal from the pending requests …\nRequests received from mutators.  <code>requests[goal]</code> is true …\nSet the <code>goal</code> as requested.  Return <code>true</code> if the requested …\nThe result type of the <code>on_last_parked</code> call-back in …\nThe last parked worker should wait, too, until more work …\nWake up all parked GC workers.\nThe last parked worker should unpark and find work packet …\nA data structure for synchronizing workers with each other …\nThe synchronized part of <code>WorkerMonitor</code>.\nThis struct counts the number of workers parked and …\nDecrease the packed-workers counter. Called after a worker …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCurrent and requested goals.\nIncrease the packed-workers counter. Called before a …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMake a request.  Can be called by a mutator to request the …\nWake up workers when more work packets are made available …\nCalled when all workers have exited.\nPark a worker and wait on the CondVar …\nNumber of parked workers.\nCount parked workers.\nThe synchronized part.\nThe total number of workers.\nWorkers wait on this when idle.  Notified if workers have …\nAn abstract of memory address and object reference.\nAllocators Various allocators implementation.\nAn analysis framework for collecting data and profiling in …\nHelpers for making native APIs. This module contain …\nConstants used in MMTk\nCalculation, conversion and rounding for memory related …\nThe copy allocators for a GC worker.\nUtilities for implementing epilogues.\nNon-generic refs to generic types of <code>&lt;VM&gt;</code>. MMTk uses …\nFinalization implementation.\nA very simple, generic malloc-free allocator\nHeap implementation, including page resource, mmapper, etc.\nImplementation of GenericFreeList by an int vector.\nChecking if an address is an valid MMTk object.\nLinear scan through a heap range\nLogger initialization This module provides a built-in …\nVarious malloc implementations (conditionally compiled by …\nWrapper functions for memory syscalls such as mmap, …\nMetadata (OnSide or InHeader) implementation. This is a …\nHelper types for object enumeration\nForwarding word in object copying.\nOpaque pointers used in MMTk, e.g. VMThread.\nMMTk command line options.\nImplementation of GenericFreeList backed by raw memory, …\nReference processing implementation.\nUtilities funcitons for Rust This module works around …\nSanity checker for GC.\nLogging slots to check duplicated edges in GC. This is a …\nUtils for collecting statistics.\nA treadmill implementation.\nThe required minimal alignment for object reference. If …\nAddress represents an arbitrary address. This is designed …\noffset in byte\nsize in bytes\nThe highest possible address.\n<code>ObjectReference</code> represents address for an object. Compared …\nThe lowest possible address.\nAdd an offset to the address.\naligns down the address to the given alignment\naligns up the address to the given alignment\nBitwise ‘and’ with a mask.\nconverts the Address to a mutable Rust reference\nconverts the Address to a Rust reference\nconverts the Address to a pointer-sized integer\natomic operation: load\natomic operation: store\nreturns the chunk index for this address\natomic operation: compare and exchange usize\nReturns the argument unchanged.\nReturns the argument unchanged.\ncreates Address from a mutable pointer\ncreates Address from a pointer\nCast a raw address to an object reference.\nLike <code>from_raw_address</code>, but assume <code>addr</code> is not zero.  This …\ncreates Address from a Rust reference\ncreates an arbitrary Address\nGet the number of bytes between two addresses. The current …\nGet forwarding pointer if the object is forwarded.\nGet the offset from <code>other</code> to <code>self</code>. The result is negative …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nis this address aligned to the given alignment\nIs the object in any MMTk spaces?\nIs the object live, determined by the policy?\nreturn true if the referenced memory is mapped\nCan the object be moved?\nIs the object reachable, determined by the policy?\nIs the object sane?\nis this address zero?\nloads a value of type T from the address\ncreates an Address of (usize::MAX)\nApply an signed offset to the address.\nReturns the intersection of the two address ranges. The …\nPerform a saturating subtract on the Address\nshifts the address by N T-typed objects (returns addr + N …\nstores a value of type T to the address\nSubtract an offset from the address.\nGet the header base address from an object reference. This …\nconverts the Address to a mutable pointer\nGet the start of the allocation address for the object. …\nconverts the Address to a pointer\nCast the object reference to its raw address.\ncreates a null Address (0)\nA list of errors that MMTk can encounter during allocation.\nA trait which implements allocation routines. Every …\nThis type describes allocator information. It is used to …\nThis type describe an allocator in the <code>crate::Mutator</code>. For …\nA bump pointer allocator. It keeps a thread local …\nA common fast-path bump-pointer allocator shared across …\nRepresents a …\nThis allocator uses a …\nRepresents a …\nThe specified heap size is too small for the given program …\nRepresents a …\nRepresents a …\nAn allocator that only allocates at page granularity. This …\nRepresents a …\nThe allocator that internally uses malloc for all the …\nRepresents a …\nA thin wrapper(specific implementation) of bump allocator …\nThe OS is unable to mmap or acquire more memory. Critical …\nNo allocator found.\nThis allocator does not have a fastpath.\nThis allocator uses a fastpath, but we haven’t …\nAn allocation attempt. The implementation of this function …\nSingle slow path allocation attempt. This is called by …\nThe allocator trait and allocation-related functions.\nA list of all the allocators, embedded in Mutator\nBump-pointer itself.\nBump pointer allocator\nThe cursor inside the allocation buffer where the next …\nReturn if this allocator can do thread local allocation. …\nEmbedded metadata pages\nFill the specified region with the alignment value.\nFree list allocator based on Mimalloc\nReturn the context for the allocator.\nReturn the <code>Space</code> instance associated with this allocator …\nReturn the <code>VMThread</code> associated with this allocator …\nImmix allocator\nThe upperbound of the allocation buffer.\nAn alloactor backed by malloc\nMark compact allocator (actually a bump pointer allocator …\n<code>Space</code> instance associated with this allocator instance.\n<code>Space</code> instance associated with this allocator instance.\n<code>Space</code> instance associated with this allocator instance.\n<code>VMThread</code> associated with this allocator instance\n<code>VMThread</code> associated with this allocator instance\n<code>VMThread</code> associated with this allocator instance\nThe byte offset from the mutator’s pointer to the …\nA list of errors that MMTk can encounter during allocation.\nA trait which implements allocation routines. Every …\nThe context an allocator needs to access in order to …\nThe specified heap size is too small for the given program …\nThe OS is unable to mmap or acquire more memory. Critical …\nAn allocation attempt. The implementation of this function …\nSlowpath allocation attempt. This function is explicitly …\nSlowpath allocation attempt. This function is explicitly …\nSlowpath allocation attempt. This function executes the …\nSlowpath allocation attempt. This function executes the …\nSingle slow path allocation attempt. This is called by …\nSingle slowpath allocation attempt for stress test. When …\nSingle slowpath allocation attempt for stress test. When …\nA wrapper method for <code>alloc_slow_once</code> to insert USDT …\nA wrapper method for <code>alloc_slow_once</code> to insert USDT …\nReturn if this allocator can do thread local allocation. …\nReturns a boxed object from a boxed trait object if the …\nReturns a mutable reference to the object within the trait …\nReturns an <code>Rc</code>-ed object from an <code>Rc</code>-ed trait object if the …\nReturns a reference to the object within the trait object …\nFill the specified region with the alignment value.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn the context for the allocator.\nReturn the <code>Space</code> instance associated with this allocator …\nReturn at which granularity the allocator acquires memory …\nReturn at which granularity the allocator acquires memory …\nReturn the <code>VMThread</code> associated with this allocator …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns true if the trait object wraps an object of type …\nThe <code>crate::plan::Mutator</code> that includes this allocator is …\nThe <code>crate::plan::Mutator</code> that includes this allocator is …\nThis type describes allocator information. It is used to …\nThis type describe an allocator in the <code>crate::Mutator</code>. For …\nRepresents a …\nThis allocator uses a …\nRepresents a …\nRepresents a …\nRepresents a …\nRepresents a …\nRepresents a …\nNo allocator found.\nThis allocator does not have a fastpath.\nThis allocator uses a fastpath, but we haven’t …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nSafety\nSafety\nSafety\nSafety\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn an AllocatorInfo for the given allocator selector. …\nThe byte offset from the mutator’s pointer to the …\nA bump pointer allocator. It keeps a thread local …\nA common fast-path bump-pointer allocator shared across …\nSlow path for allocation if precise stress testing has …\nBump-pointer itself.\nThe cursor inside the allocation buffer where the next …\nDefaults to 0,0. In this case, the first allocation would …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe upperbound of the allocation buffer.\nReset the cursor and limit to the given values.\n<code>Space</code> instance associated with this allocator instance.\n<code>VMThread</code> associated with this allocator instance\nA MiMalloc free list allocator\nGet a block from the space.\nAdd a block to the given bin in the available block lists. …\nblocks with free space\nblocks with free space for precise stress GC For precise …\nfull blocks\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nTries to recycle local blocks if there is any. This is a …\n<code>VMThread</code> associated with this allocator instance\nblocks that are marked, not swept\nImmix allocator\nGet a recyclable block from ImmixSpace.\nSearch for recyclable lines.\nBump allocate small objects into recyclable lines (i.e. …\nAcquire a clean block from ImmixSpace for allocation.\nThis is called when precise stress is used. We try use the …\nThe fastpath bump pointer.\nIs this a copy allocator?\nReturns the argument unchanged.\n<em>unused</em>\nCalls <code>U::from(self)</code>.\nBump pointer for large objects\nHole-searching cursor\nLarge-object (larger than a line) bump allocation.\nIs the current request for large or small?\nReturn whether the TLAB has been exhausted and we need to …\nRestore the real limits for the bump allocation so we can …\nSet fake limits for the bump allocation for stress tests. …\n<code>Space</code> instance associated with this allocator instance.\n<code>VMThread</code> associated with this allocator instance\nAn allocator that only allocates at page granularity. This …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\n<code>Space</code> instance associated with this allocator instance.\n<code>VMThread</code> associated with this allocator instance\nThe allocator that internally uses malloc for all the …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\n<code>Space</code> instance associated with this allocator instance.\n<code>VMThread</code> associated with this allocator instance\nThe number of bytes that the allocator reserves for its …\nA thin wrapper(specific implementation) of bump allocator …\nSlow path for allocation if precise stress testing has …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThis trait exposes hooks for developers to implement their …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSimple analysis routine that counts the number of …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSimple analysis routine that counts the number of objects …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThis file implements an analysis routine that counts the …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nAn <code>Option&lt;ObjectReference&gt;</code> encoded as a <code>usize</code> (which is …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe number of bits in an address\nThe number of bits in a byte\nThe number of bits in a page\nThe number of bits in a word\nThe number of bytes in an address\nThe number of bytes in a byte\nThe number of bytes in a gigabyte\nThe number of bytes in a kilobyte\nThe number of bytes in a megabyte\nThe number of bytes in a page\nThe number of bytes in a word\nLazy sweeping - controlled from here because …\nlog2 of the number of bits in an address\nlog2 of the number of bits in a byte\nlog2 of the number of bits in a page\nlog2 of the number of bits in a word\nlog2 of the number of bytes in an address\nlog2 of the number of bytes in the address space\nlog2 of the number of bytes in a byte\nlog2 of the number of bytes in a gigabyte\nlog2 of the number of bytes in a kilobyte\nlog2 of the number of bytes in a megabyte\nlog2 of the number of bytes in a page\nlog2 of the number of bytes in a word\nlog2 of the minimal object size in bytes.\nThe minimal object size in bytes\nSome card scanning constants ported from Java MMTK. As we …\ntrack at byte grain, save shifting\neach card consumes four bytes of metadata\nnumber of units tracked per card\nConvert an address to the chunk index (aligned down).\nConvert size in bytes to the number of chunks (aligned up).\nConvert size in bytes to a readable short string, such as …\nConvert size in bytes to the number of pages (aligned up)\nAlign down an address to the nearest chunk.\nAlign up an address to the nearest chunk.\nConvert a chunk index to the start address of the chunk.\nIs the address aligned to word boundary?\nIs the address aligned to page boundary?\nAlign down an address to the nearest chunk at which …\nAlign up an address to the nearest chunk at which …\nAlign down an address to the nearest page.\nConvert the number of pages to bytes.\nAlign down an integer to the given alignment. <code>align</code> must …\nAlign up an integer to the given alignment. <code>align</code> must be …\nIs the integer aligned to the given alignment? <code>align</code> must …\nShift <code>num</code> by <code>bits</code> to the right.  Add 1 to the result if …\nA configuration for GCWorkerCopyContext. Similar to a …\nCopySemantics describes the copying operation. It depends …\nThe default copy behavior.\nThe thread local struct for each GC worker for copying. …\nCopy in mature generation.\nCopy in nursery generation.\nPromote an object from nursery to mature spaces.\nAllocate for the object for GC copying.\nThe config for the plan\nA reference to the plan constraints. GCWorkerCopyContext …\nCopy allocators for CopySpace\nMapping CopySemantics to the actual copying allocators …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCopy allocators for ImmixSpace\nCopy allocators for ImmixSpace\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nAre we copying to a mature space?\nCreate a GCWorkerCopyContext based on the configuration …\nCreate a stub GCWorkerCopyContext for non copying plans.\nPost allocation after allocating an object.\nPrepare the copying allocators.\nRelease the copying allocators.\nMapping copying allocators with space\nA debugging method for detecting the case when the …\nA special processor for Finalizable objects.\nCandidate objects that has finalizers with them\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIndex into candidates to record where we are up to in the …\nObjects that can be finalized. They are actually dead, but …\nReturns a boxed object from a boxed trait object if the …\nReturns a mutable reference to the object within the trait …\nReturns an <code>Rc</code>-ed object from an <code>Rc</code>-ed trait object if the …\nReturns a reference to the object within the trait object …\nFree a previously allocated contiguous lump of units\nReturns true if the trait object wraps an object of type …\nThis trait describes a GC trigger policy. A triggering …\nProvides statistics about the space. This is exposed to …\nCan the heap size grow?\nReturn the current heap size (in pages)\nReturn the upper bound of heap size\nIs a GC required now? The GC trigger may implement its own …\nIs current heap full?\nThe module defines virutal memory layout parameters.\nThe struct is used for page usage. Both page resource and …\nInform of clearing some reserved pages. This is used when …\nInform of successfully committing a certain number of …\nThe committed pages. This should be incremented when we …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nInform of releasing a certain number of pages. The number …\nInform of reserving a certain number of pages. Usually …\nInform of both reserving and committing a certain number …\nThe reserved pages. This should be incremented when we are …\nSet both reserved and committed pages to zero. This is …\nA fast PageResource for fixed-size block allocation only.\nA block queue which contains a global pool and a set of …\nA block list that supports fast lock-free push/pop …\nBlock granularity in pages\nAdd a BlockArray to the global pool\nAllocate a block\nGrow contiguous space\nA buffer for storing all the free blocks\nTotal number of blocks in the whole BlockQueue\nThe number of elements in the queue.\nThe underlying data storage.\nFlush a given thread-local queue to the global pool\nFlush all thread-local queues to the global pool\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet an entry\nA list of BlockArray that is flushed to the global pool\nFirst global BlockArray for fast allocation\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTest if the array is empty\nIterate all elements in the array\nIterate all the blocks in the BlockQueue\nGet array size\nGet total number of blocks in the whole BlockQueue\nCreate an array\nCreate a BlockQueue\nAtomically pop an element from the array.\nPop a block from the global pool\nPush a block to the thread-local queue\nNon-atomically push an element.\nReplace the array with a new array.\nSet an entry.\nSlow-path allocation synchronization\nThread-local block queues\nChunk alloc table\nThe chunk is allocated.\nData structure to reference a MMTk 4 MB chunk.\nA byte-map to record all the allocated chunks. A plan can …\nChunk allocation state\nThe chunk is not allocated.\nChunk constant with zero address\nA range of all chunks in the heap.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nHelper function to create per-chunk processing work …\nGet chunk state\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nGet an iterator for regions within this chunk.\nSet chunk state\nA special page resource that records some external pages …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nProtect the memory\nUnprotect the memory\nProtect memory on release, and unprotect on re-allocate.\nRelease pages previously allocated by <code>alloc_pages</code>.\nA simple GC trigger that uses a fixed heap size.\nGCTrigger is responsible for triggering GCs based on the …\nThis trait describes a GC trigger policy. A triggering …\nAn implementation of MemBalancer (Optimal heap limits for …\nProvides statistics about the space. This is exposed to …\nAllocated memory in pages\nPrevious allocated memory in pages.\nAllocation duration in secs\nPrevious allocation duration in secs\nCan the heap size grow?\nCollected memory in pages (memory traversed during …\nPrevious collected memory in pages\nCollection duration in secs\nPrevious colleciton duration in secs\nThe current heap size\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe live pages at the GC end\nThe time when this GC ends\nThe live pages before we release memory.\nThe time when this GC starts\nReturn true if we should compute a new heap limit. Only do …\nReturn the current heap size (in pages)\nReturn the upper bound of heap size\nReturn upper bound of the nursery size (in number of bytes)\nReturn upper bound of the nursery size (in number of pages)\nReturn lower bound of the nursery size (in number of bytes)\nReturn lower bound of the nursery size (in number of pages)\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs a GC required now? The GC trigger may implement its own …\nIs current heap full?\nCheck if the heap is full\nThe max heap size\nThe min heap size\nCreate new SpaceStats.\nInform the triggering policy that a GC ends.\nInform the triggering policy that a GC ends.\nInform the triggering policy that a GC is about to start …\nInform the triggering policy that a GC is about to start …\nInform the triggering policy that a GC starts.\nInform the triggering policy that a GC starts.\nInform the triggering policy that we have pending …\nInform the triggering policy that we have pending …\nThe number of pending allocation pages. The allocation …\nThe current plan. This is uninitialized when we create it, …\nThe triggering policy.\nThis method is called periodically by the allocation …\nGet the number of reserved pages for the space.\nSet the plan. This is called in <code>create_plan()</code> after we …\nCheck if we should do a stress GC now. If GC is …\nStatistics\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe avialable heap range between AVAILABLE_START and …\nThe heap range between HEAP_START and HEAP_END Heap range …\nThe module defines virutal memory layout parameters.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturn {@code true} if the given address has been mmapped\nMaximum number of slabs, which determines the maximum …\nParameters for the slab table.  The hash function requires …\n@param slab Address of the slab @param addr Address within …\nTake a free slab of chunks from the freeSlabs array, and …\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn {@code true} if the given address has been mmapped\n@param addr an address @return the base address of the …\n@param addr an address @return the base address of the …\nlog_2 of the maximum number of spaces a Plan can support.\nMaximum number of spaces a Plan can support.\nThe result of creating free list.\nSafety\nCreate a free-list for a discontiguous space. Must only be …\nCreate a free-list for a contiguous space. Must only be …\nFinalize the globlal maps in the implementations of <code>VMMap</code>. …\nSafety\nReturns the argument unchanged.\nReturn the total number of chunks available (unassigned) …\nReturn the total number of clients contending for chunks. …\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSafety\nSafety\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSafety\nThe mmap state of a mmap chunk.\nThe chunk is mapped by MMTk and is in use.\nGeneric mmap and protection functionality\nThe chunk is mapped and is also protected by MMTk.\nThe chunk is reserved for future use. MMTk reserved the …\nThe chunk is unmapped and not managed by MMTk.\nEquivalent to calling <code>transition_to_quarantined</code> on each …\nGiven an address array describing the regions of virtual …\nEnsure that a range of pages is mmapped (or equivalent).  …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nIs the page pointed to by this address mapped? Returns …\nMark a number of pages as mapped, without making any …\nMark a number of pages as inaccessible.\nQuarantine/reserve address range. We mmap from the OS with …\nCheck the current MapState of the chunk, and transition …\nCheck the current MapState of the chunk, and transition …\nCheck the current MapState of the chunk, and transition …\nCoarsest unit of address space allocation.\nMask for chunk size.\nThe maximum virtual memory address space that can be used …\nlog_2 of the coarsest unit of address space allocation.\nlog_2 of the granularity at which we map and unmap virtual …\nGranularity at which we map and unmap virtual address …\nCoarsest unit of address space allocation, in pages\nRuntime-initialized virtual memory constants\nThis mask extracts a few bits from address, and use it as …\nSize of the address space available to the MMTk heap.\nHighest virtual address available for MMTk to manage.\nLowest virtual address available for MMTk to manage.\nShould mmtk enable contiguous spaces and virtual memory …\nReturns the argument unchanged.\nHighest virtual address used by the virtual machine. …\nLowest virtual address used by the virtual machine. Should …\nCalls <code>U::from(self)</code>.\nlog_2 of the addressable heap virtual space.\nlog_2 of the maximum number of chunks we need to track.  …\nlog_2 of the number of pages in a 64-bit space\nAn upper bound on the extent of any space in the current …\nMaximum number of chunks we need to track.  Only used in …\nAn upper bound on the extent of any space in the current …\nNormal 32-bit configuration\nNormal 64-bit configuration\nThe number of pages in a 64-bit space\nCustom VM layout constants. VM bindings may use this …\nBitwise mask to isolate a space index in a virtual address.\nNumber of bits to shift a space index into/out of a …\nSize of each space in the 64-bit memory layout We can’t …\nGet the current virtual memory layout in use. If the …\nBase address of the current chunk of addresses\nGet highwater mark of current monotone space.\nPointer to the next block to be allocated.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIterate over all contiguous memory regions in this space. …\nSafety\nThe limit of the currently allocated address space.\nCurrent frontier of zeroing, in a separate zeroing thread\nCurrent limit of zeroing.  If zeroingCursor &lt; …\nCommit pages to the page budget.  This is called after …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn the number of available physical pages by this …\nAllocate pages from this resource. Simply bump the cursor, …\nExtend the virtual memory associated with a particular …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nRelease one or more contiguous chunks associated with a …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCoarsest unit of address space allocation.\nMask for chunk size.\nlog_2 of the coarsest unit of address space allocation.\nlog_2 of the granularity at which we map and unmap virtual …\nGranularity at which we map and unmap virtual address …\nCoarsest unit of address space allocation, in pages\nRuntime-initialized virtual memory constants\nShould mmtk enable contiguous spaces and virtual memory …\nHighest virtual address used by the virtual machine. …\nLowest virtual address used by the virtual machine. Should …\nlog_2 of the addressable heap virtual space.\nAn upper bound on the extent of any space in the current …\nGet the current virtual memory layout in use. If the …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe region size (in bytes) of the <code>VO_BIT</code> side metadata. …\nThe size in bytes for the region.\nDefault object size as ObjectModel::get_current_size()\nlog2 of the size in bytes for the region.\nDescribe object size for linear scan. Different policies …\nIterate over an address range, and find each object by VO …\nRegion represents a memory region with a properly aligned …\nAn iterator for contiguous regions.\nAlign the address to the region.\nReturn the region that contains the object.\nReturn the end address of the region. Note that the end …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a region from an address that is aligned to the …\nCreate a region from an arbitrary address.\nCheck if the given address is in the region.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if an address is aligned to the region.\nCreate an iterator for the address range. The caller must …\nCreate an iterator from the start region (inclusive) to …\nReturn the next region after this one.\nReturn the next nth region after this one.\nThe object size in bytes for the given object.\nReturn the start address of the region. For performance, …\nAttempt to init a env_logger for MMTk. Does nothing if the …\nManually allocate memory and initialize the bytes in the …\nManually allocate memory and initialize the bytes in the …\nManually allocate memory. Similar to libc’s malloc. This …\nManually free the memory that is returned from other …\nManually free the memory that is returned from other …\nMalloc provided by libraries\nManually allocate memory. Similar to libc’s malloc.\nUsing malloc as mark sweep free-list allocator.\nReallocate the given area of memory. Similar to libc’s …\nReallocate the given area of memory. Similar to libc’s …\nWhen we count page usage of library malloc, we assume they …\nIf no malloc lib is specified, use the libc implementation\nAllocate with alignment. This also guarantees the memory …\nAllocate with alignment and offset. Beside returning the …\nallocate <code>size</code> bytes, which is aligned to <code>align</code> at <code>offset</code> …\nget malloc usable size of an address is_offset_malloc: …\nFree an address that is allocated with an offset (returned …\nGet the malloc usable size for an address that is returned …\nSupport for huge pages\nThe strategy for MMTk’s own internal memory\nFor all other use cases.\nAnnotation for an mmap entry.\nThe protection flags for Mmap\nStrategy for performing mmap\nNo support for huge page\nDo not allow any access\nAllow read + write\nAllow read + write + code execution\nThe strategy for MMTk side metadata\nThe mmap is for a side metadata.\nThe mmap is for a space.\nThe mmap is for a test case.  Usually constructed using …\nEnable transparent huge pages for the pages that are …\nDemand-zero mmap: This function mmaps the memory and …\nDemand-zero mmap (no replace): This function mmaps the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the memory maps for the process. The returned string …\nReturns the total physical memory for the system in bytes.\nProperly handle errors from a mmap Result, including …\nDo we support huge pages?\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTurn the protection enum into the native flags\nConstruct an <code>MmapAnnotation::Test</code> with the current file …\nmmap with no swap space reserve: This function does not …\nProtect the given memory (in page granularity) to forbid …\nUnmap the given memory (in page granularity). This wraps …\nUnprotect the given memory (in page granularity) to allow …\nCreate a new strategy\nChecks if the memory has already been mapped. If not, we …\nThe protection flags for mmap\nCheck the result from an mmap function in this module. …\nSet a range of memory to the given value. Similar to …\nSet a range of memory to 0.\nThe source file.\nThe line number.\nThe name of the side metadata.\nThe name of the space.\nA human-readable descriptive name.\nThe name of the space.\nThe size of this atomic type in bits.\nDescribes bits and log2 bits for the numbers. If …\nDescribes bitwise operations. If num_traits has this, we …\nIn-header metadata uses bits from an object header.\nThe size (in log2) of this atomic type in bits.\nThis struct stores the specification of a metadata bit-set.\nThe number type for accessing metadata. It requires a few …\nOn-side metadata uses a side table.\nPerform bitwise and for two values.\nPerform bitwise or for two values.\nPerform bitwise xor for two values.\nSafety\nSafety\nSafety\nSafety\nSafety\nSafety\nThis module provides a default implementation of the …\nPerform bitwise invert (not) for the value.\nNon atomic load\nAtomic load\nThis module provides an implementation of side table …\nNon atomic store\nAtomic store\nValid object bit (VO bit)\nIn-header metadata uses bits from an object header.\nThis struct stores the specification of a metadata bit-set.\nOn-side metadata uses a side table.\nA function to atomically compare-and-exchange the …\nGiven a slice of metadata specifications, returns a vector …\nExtract SideMetadataSpec from a MetadataSpec. Panics if …\nA function to atomically perform an add operation on the …\nA function to atomically perform a bit-and operation on …\nA function to atomically perform a bit-or operation on the …\nA function to atomically perform a subtract operation on …\nA function to atomically perform an update operation on …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nIs this metadata stored in the object header?\nIs this metadata stored in the side table?\nA function to non-atomically load the specified metadata’…\nA function to atomically load the specified metadata’s …\nA function to non-atomically store a value to the …\nA function to atomically store a value to the specified …\nThis struct stores the specification of a header metadata …\nWe only allow mask for u8/u16/u32/u64/usize. If a mask is …\nAssert if this is a valid spec.\n<code>bit_offset</code> is the index of the starting bit from which the …\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\nInner method for fetch_add/sub on bits. For fetch_and/or, …\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\nReturns the argument unchanged.\nExtract bits from a raw byte, and put it to the lowest …\nGet the bit shift (the bit distance from the lowest bit to …\nCalls <code>U::from(self)</code>.\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\n<code>num_of_bits</code> specifies the number of consecutive bits to be …\nSet bits to a raw byte. <code>set_val</code> has the valid value in its …\nThis function provides a default implementation for the …\nThis function provides a default implementation for the …\nTruncate a value based on the spec.\nThis provides an abstraction of the mark bit. It abstracts …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCheck if the object is marked\nThis has to be called when a space resets its memory …\nThis has to be called in the global preparation of a space\nThis has to be called in the global release of a space\nThis has to be called during object initialization.\nThis value represents the marked state. If the mark bit is …\nAttempt to mark an object. If the object is marked by this …\nThe size of this atomic type in bits.\nDescribes bits and log2 bits for the numbers. If …\nDescribes bitwise operations. If num_traits has this, we …\nThe size (in log2) of this atomic type in bits.\nThe number type for accessing metadata. It requires a few …\nPerform bitwise and for two values.\nPerform bitwise or for two values.\nPerform bitwise xor for two values.\nSafety\nSafety\nSafety\nSafety\nSafety\nSafety\nPerform bitwise invert (not) for the value.\nNon atomic load\nAtomic load\nNon atomic store\nAtomic store\nGlobal side metadata start address\nThe base address for the global side metadata space …\nThe base offset for the global side metadata available to …\nThe base address for the local side metadata space …\nA byte array in side-metadata\nA union of Address or relative offset (usize) used to …\nThis struct stores the specification of a side metadata …\nBase address of VO bit, public to VM bindings which may …\nIs this side metadata global? Local metadata is used by …\nNumber of bytes of the region. E.g. 3 = 8 bytes, 12 = 4096 …\nNumber of bits needed per region. E.g. 0 = 1 bit, 1 = 2 …\nThe name for this side metadata.\nThe offset for this side metadata.\nData types for visiting metadata ranges at different …\nGlobal side metadata start address\nThe base address for the global side metadata space …\nThe base offset for the global side metadata available to …\nThe base address for the local side metadata space …\nThe max bytes (in log2) that may be used for global side …\nBase address of VO bit, public to VM bindings which may …\nA byte array in side-metadata\nThis struct stores all the side metadata specs for a …\nA union of Address or relative offset (usize) used to …\nThis struct stores the specification of a side metadata …\nGet an offset for a fixed address. This is usually used to …\nUsed only for debugging. This panics if the required …\nUsed only for debugging.\nBulk copy the <code>other</code> side metadata for a memory region to …\nBulk set a specific metadata for a memory region. Note …\nThis method does bulk update for the given data range. It …\nBulk-zero a specific metadata for a memory region. Note …\nReturn the pages reserved for side metadata based on the …\nStores the new value into the side metadata for the gien …\nAdds the value to the current value for this side metadata …\nBitwise ‘and’ the value with the current value for …\nThis is used to implement fetch_add/sub for bits. For …\nBitwise ‘or’ the value with the current value for this …\nSubtracts the value from the current value for this side …\nFetches the value for this side metadata for the given …\nSearch for a data address that has a non zero value in the …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a byte from the metadata byte array at the given index.\nGet the absolute offset for the spec.\nGet the relative offset for the spec.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs offset for this spec Address?\nIs this side metadata global? Local metadata is used by …\nCheck with the mmapper to see if side metadata is mapped …\nIf offset for this spec relative? (chunked side metadata …\nGet an offset after a spec. This is used to layout another …\nGet the length of the array.\nNon-atomic load of metadata.\nLoads a value from the side metadata for the given address.\nLoad the raw byte in the side metadata byte that is mapped …\nLoad the raw word that includes the side metadata byte …\nNumber of bytes of the region. E.g. 3 = 8 bytes, 12 = 4096 …\nNumber of bits needed per region. E.g. 0 = 1 bit, 1 = 2 …\nThe internal function to mmap metadata\nThe name for this side metadata.\nGet a piece of metadata address range as a byte array.\nThe offset for this side metadata.\nGet an offset for a relative offset (usize). This is …\nSearch for data addresses that have non zero values in the …\nThis method is used for bulk setting side metadata for a …\nAtomically store one to the side metadata for the data …\nNon-atomically store zero to the side metadata for the …\nAtomiccally store zero to the side metadata for the given …\nThis is a wrapper method for implementing side metadata …\nNon-atomic store of metadata.\nStore the given value to the side metadata for the given …\nTries to map the required metadata address range, without …\nTries to map the required metadata space and returns <code>true</code> …\nThe upper bound address for metadata address computed for …\nReturn the upperbound offset for the side metadata. The …\nIs this spec using contiguous side metadata? If not, it …\nThis method is used for bulk zeroing side metadata for a …\nThe result type for find meta bits functions.\nPerforms address translation in contiguous metadata spaces …\nPerforms the translation of data address (<code>data_addr</code>) to …\nAlign an pair of a metadata address and a metadata bit …\nPerforms reverse address translation from contiguous …\nCalculate the amount of metadata needed for the give …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturn the base-2 logarithm of the ratio of data bits and …\nCalculate the amount of data governed by the give amount …\nTries to mmap the metadata space (<code>spec</code>) for the specified …\nA range of bytes or bits within a byte.  It is the unit of …\nThe type for bit offset in a byte.\nA range of bits within a byte.\nA range of whole bytes.\nBreak a bit range into sub-ranges of whole bytes and …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nThe address of the byte.\nThe ending bit index (exclusive),  starting with zero from …\nThe starting bit index (inclusive), starting with zero …\nThe ending address (exclusive) of the bytes.\nThe starting address (inclusive) of the bytes.\nThis is a two-level hashmap to store the metadata content …\nAn internal str used as a name for global side metadata …\nAn internal enum to enhance code style for add/sub\nThis struct includes a hashmap to store the metadata specs …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns all global or policy-specific specs based-on the …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreates a new SideMetadataSanity instance.\nCommits a side metadata bulk copy operation (set the bits …\nCommits a side metadata bulk set operation (set the …\nCommits a side metadata bulk zero operation. Panics if the …\nChecks whether a slice of global specifications fit within …\nChecks whether the input global specifications fit within …\nEnsures a side metadata load operation returns the correct …\nVerifies that all local side metadata specs: 1 - are not …\n(For 64-bits targets) Checks whether the input local …\nThis verifies two things:\nAn internal method to ensure that a metadata context does …\n(For contiguous metadata) Checks whether two input …\nCommits a side metadata store operation. Panics if: 1 - …\nCommits an update operation and ensures it returns the …\nThe base address for VO bit side metadata on 64 bits …\nA VO bit is required per min-object-size aligned address, …\nHow many data memory bytes does 1 word in the VO bit side …\nBulk copy VO bits from side mark bits. Some VMs require …\nBulk zero the VO bit.\nFind the base reference to the object from a potential …\nGet the object reference from an aligned address where VO …\nBulk check if a VO bit word. Return true if there is any …\nThis module updates of VO bits during GC.  It is used for …\nCheck if the address could be an internal pointer in the …\nCheck if the address could be an internal pointer based on …\nNon-atomically check if the VO bit is set for this address.\nCheck if the VO bit is set for an object.\nCheck if an address can be turned directly into an object …\nCheck if an address can be turned directly into an object …\nAtomically set the VO bit for an object.\nAtomically unset the VO bit for an object.\nAtomically unset the VO bit for an object, regardless …\nNon-atomically unset the VO bit for an object. The caller …\nClear all VO bits after stacks are scanned, and …\nCopy the mark bits metadata over to the VO bits metadata …\nThe strategy to update the valid object (VO) bits.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nSelect a strategy for the VM.  It is a <code>const</code> function so …\nReturn <code>true</code> if the VO bit metadata is available during …\nAllow querying if a block may have objects. <code>MarkSweepSpace</code> …\nAn implementation of <code>ObjectEnumerator</code> that wraps a …\nA trait for enumerating objects in spaces, used by …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturn <code>true</code> if the block may contain valid objects …\nVisit an address range that may contain objects.\nVisit a single object.\nAttempt to become the worker thread who will forward the …\nZero the forwarding bits of an object. This function is …\nCopy an object and set the forwarding state.\n(This function is only used internal to the <code>util</code> module)\nReturn the forwarding bits for a given <code>ObjectReference</code>.\nRead the forwarding pointer of an object. This function is …\nSpin-wait for the object’s forwarding to become complete …\nWrite the forwarding pointer of an object. This function …\nOpaquePointer represents pointers that MMTk needs to know …\nRepresents an uninitialized value for <code>OpaquePointer</code>.\nRepresents an uninitialized value for <code>VMThread</code>.\nA VMMutatorThread is a VMThread that associates with a …\nA VMThread is an opaque pointer that can uniquely identify …\nA VMWorkerThread is a VMThread that is associates with a …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCast an <code>Address</code> type to an <code>OpaquePointer</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs this opaque pointer null?\nCast the opaque pointer to an <code>Address</code> type.\nAn adaptive approach using both non-temporal write and a …\nAffinityKind describes how to set the affinity of GC …\nA Bounded nursery has different upper and lower bounds. …\nZeroing with a separate zeroing thread.\nThe default max nursery size. This does not affect the …\nThe default max nursery size for 32 bits.\nThe default min nursery size. This does not affect the …\nThe default max nursery size proportional to the current …\nThe default min nursery size proportional to the current …\nThe default stress factor. This is set to the max usize, …\nDelegate the GC triggering to the binding. This is not …\nGC is triggered by internal herusticis, and the heap size …\nA Fixed nursery has the same upper and lower bounds. The …\nGC is triggered when a fix-sized heap is full. The value …\nSelect a GC trigger for MMTk.\nA generational collector that uses a copying nursery, and …\nA generational collector that uses a copying nursery, and …\nA mark-region collector that allows an opportunistic …\nAn MMTk option of a given type. This type allows us to …\nA mark-compact collector that marks objects and performs …\nA mark-sweep collector, which marks live objects and …\nAllocation only without a collector. This is usually used …\nZeroing with cache-bypassing non-temporal write.\nAn option that provides a min/max interface to MMTk and a …\nThe zeroing approach to use for new object allocations. …\nMMTk command line options.\nDelegate thread affinity to the OS scheduler\nA debugging collector that allocates memory at page …\nMMTk option for perf events\nSelect a GC plan for MMTk.\nA bounded nursery that is porportional to the current heap …\nAssign thread affinities over a list of cores in a round …\nA semi-space collector, which divides the heap into two …\nAn Immix collector that uses a sticky mark bit to allow …\nZeroing with normal temporal write.\nHow frequent (every X bytes) should we run analysis (a STW …\nCount live bytes for objects in each space during a GC.\nBy default, <code>Options</code> instance is created with built-in …\nShould we eagerly finish sweeping at the start of a …\nA vector of perf events in tuples of (event name, PID, CPU)\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCan we set this option through command line options/API?\nCan we set this option through env vars?\nShould a major GC be performed when a system GC is …\nSet the GC trigger. This defines the heap size and how …\nShould we ignore GCs requested by the user (e.g. …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCheck if the options are set for stress GC. If either …\nget max heap size\nCreate a new MMTKOption\nCreate an <code>Options</code> instance with built-in default settings.\nShould finalization be disabled?\nShould reference type processing be disabled? If reference …\nThe nursery size for generational plans. It can be one of …\nThe zeroing approach to use for new object allocations. …\nReturns an AffinityKind or String containing error. …\nParse a size representation, which could be a number to …\nShould we exclude perf events occurring in kernel space. …\nMeasuring perf events for GC and mutators\nThe GC plan to use.\nPrecise stress test. Trigger stress GCs exactly at X bytes …\nRead options from environment variables, and apply those …\nResolve affinity of GC thread. Has a side-effect of …\nSet the option to the given value. Returns true if the …\nBulk process options. Returns true if all the options are …\nSet an option from command line\nSet an option from env var\nSet an option and run its validator for its value.\nHow frequent (every X bytes) should we do a stress GC?\nSet how to bind affinity to the GC Workers. Default thread …\nNumber of GC worker threads.\nEnable transparent hugepage support for MMTk spaces via …\nEnable a return barrier (not supported)\nEnable an optimization that only scans the part of the …\nReturn true if the affinity is either OsDefault or the …\nReturn true if the values are valid.\nReturn true if the gc trigger is valid\nThe validator to ensure the value is valid.\nThe actual value for the option\nThe size of vmspace.\nThe start of vmspace.\nPerf events to measure Semicolons are used to separate …\nThe upper bound of the nursery size in bytes. Default to …\nThe upper bound of the nursery size as a proportion of the …\nThe lower bound of the nursery size in bytes. Default to …\nThe lower bound of the nursery size as a proportion of the …\nlog2 of the number of bytes used by a free list entry (two …\nlog2 of the number of bytes used by a free list unit\nlog2 of the number of bits used by a free list entry (two …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nWe create a reference processor for each semantics. …\nHolds all reference processors for each weak reference …\nAdd a candidate.\nIs it allowed to add candidate to this reference …\nInform the binding to enqueue the weak references whose …\nThis will invoke enqueue for each reference processor, …\nReferences whose referents are cleared during this GC. We …\nForward the reference tables in the reference processor. …\nA separate reference forwarding step. Normally when we …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturn the new <code>ObjectReference</code> of a reference object if it …\nReturn the new <code>ObjectReference</code> of a referent if it is …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThis function is called when retaining soft reference.  It\nIndex into the references table for the start of nursery …\nProcess a reference.\nThe table of reference objects for the current semantics. …\nRetain referent in the reference table. This method deals …\nScan the reference table, and update each …\nScan phantom references.\nScan soft references.\nScan weak references.\nThe semantics for the reference processor\nMost of the reference processor is protected by a mutex.\nThis function is called when forwarding the references and …\nInitializeOnce creates an uninitialized value that needs …\nThis implements <code>std::array::from_fn</code> introduced in Rust …\nCreate a formatted string that makes the best effort …\nReturns the argument unchanged.\nGet a mutable reference to the value. This is currently …\nGet the value. This should only be used after …\nInitialize the value. This should be called before ever …\nCalls <code>U::from(self)</code>.\nConst function for min value of two usize numbers.\nThis is used to guarantee <code>init_fn</code> is only called once.\nThis module provides an iterator that groups adjacent …\nThis module is for allocating large arrays or vectors with …\nAn iterator through groups of items with the same key.\nThis trait provides the <code>revisitable_group_by</code> method for …\nReturns the argument unchanged.\nReturns the argument unchanged.\nThe function to get the key.\nThe first item. Note that <code>iter</code> starts from the second …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe underlying iterator.\nThe underlying iterator.\nThe key of this group.\nThe length of this group.\nTemporarily save the item and key of the next group when …\nThe number of items remain to be iterated.\nGroup adjacent items by key.  <code>get_key</code> is a closure that …\nAllocate a <code>Vec&lt;T&gt;</code> of all-zero values.\nCache a list of root slots to the sanity checker.\nReset roots cache at the end of the sanity gc.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nVisited objects\nCached root nodes for sanity root scanning\nCached root slots for sanity root scanning\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nLogs a slot. Panics if the slot was already logged.\nReset the slot logger by clearing the hash-set of slots. …\nWhether we should check duplicate slots. This depends on …\nAn abstraction over how a specific Diffable value is …\nAn abstraction over some changing values that we want to …\nThe type of each reading\nRead the current value\nCompute the difference between two readings\nReturns the argument unchanged.\nGet the total count over past phases\nWhether the counter starts implicitly after creation\nCalls <code>U::from(self)</code>.\nWhether the counter merges other and stw phases.\nGet the name of the counter\nSignal a change in GC phase.\nPrint the counter value for a particular phase\nPrint the difference in a specific format\nPrint the count of the last phases\nPrint the maximum count of the past phases\nPrint the minimum count of the past phases\nPrint the total count over past phases\nStart the counter\nStart the Diffable\nnop for the wall-clock time\nStop the counter\nStop the Diffable\nnop for the wall-clock time\nThis file implements a simple event counter (counting …\nReturns the argument unchanged.\nIncrement the event counter\nIncrement the event counter by provided value\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nIncrement the event counter by provided value\nCalls <code>U::from(self)</code>.\nPrint current (mid-phase) units\nPrint (mid-phase) volume\nPrint units\nPrint volume\nStart this counter\nStop this counter\nGC stats shared among counters\nGC statistics\nReturns the argument unchanged.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nA value to fill in alignment gaps. This value can be used …\nThis value is used to assert if the cursor is reasonable …\nVM-specific methods for the current plan.\nVM-specific methods for garbage collection.\nDefault max alignment 8 bytes\nDefault min alignment 4 bytes\nA finalizable object for MMTk. MMTk needs to know the …\nThe type of finalizable objects. This type is used when …\nThread context for the spawned GC thread.  It is used by …\nA global 1-bit metadata used by generational plans to …\nA local 2-bit metadata for the forwarding status bits, …\nA local word-size metadata for the forwarding pointer, …\nA local 2-bit metadata used by the large object space to …\nA local 1-bit metadata for the mark bit, used by most …\nA local 1-bit metadata specification for the pinning bit, …\nAllowed maximum alignment in bytes.\nAllowed minimal alignment in bytes.\nFor our allocation result (object_start), the binding may …\nVM-specific methods for object model.\nCallback trait of scanning functions that directly trace …\nAn <code>ObjectTracerContext</code> gives a GC worker temporary access …\nVM-specific methods for reference processing, including …\nRoot-scanning methods use this trait to create work …\nVM-specific methods for scanning roots/objects.\nCallback trait of scanning functions that report slots.\nThe concrete <code>ObjectTracer</code> type.\nDoes the binding use a non-zero allocation offset? If this …\nThe binding’s implementation of <code>crate::vm::ActivePlan</code>.\nThe <code>VMBinding</code> trait associates with each trait, and …\nThe binding’s implementation of <code>crate::vm::Collection</code>.\n1-bit global metadata to log an object.\n2-bit local metadata for spaces that store a forwarding …\n1-word local metadata for spaces that may copy objects. …\n2-bits local metadata for the large object space. The two …\n1-bit local metadata for spaces that need to mark an …\n1-bit local metadata for spaces that support pinning.\nThe type of heap memory slice in this VM.\nThe binding’s implementation of <code>crate::vm::ObjectModel</code>.\nThe binding’s implementation of <code>crate::vm::ReferenceGlue</code>.\nThe binding’s implementation of <code>crate::vm::Scanning</code>.\nThe type of slots in this VM.\nThe GC thread to spawn is a worker thread. There can be …\nBlock the current thread for GC. This is called when an …\nWeak and soft references always clear the referent before …\nCopy an object and return the address of the new object. …\nCopy an object. This is required for delayed-copy …\nCreate work packets to handle non-transitively pinning …\nCreate work packets to handle non-pinned roots.  The roots …\nCreate work packets to handle transitively pinning (TP) …\nDump debugging information for an object.\nFor weak reference types, if the referent is cleared …\nReturn the alignment offset when an object is copied.\nReturn the alignment when an object is copied.\nReturn the size used by an object.\nLoad the object reference.\nReturn the reference that an object will be referred to …\nGet the referent from a weak reference object.\nReturn the size when an object is copied.\nGet the type descriptor for an object.\nReturn whether there is a mutator created and associated …\nKeep the heap references in the finalizable object alive. …\nReturn a <code>Mutator</code> reference for the thread.\nReturn an iterator that includes all the mutators at the …\nMMTk calls this method at the first time during a …\nReturn the total count of mutators.\nPrepare for another round of root scanning in the same GC. …\nReturn the header base address from an object reference. …\nReturn the lowest address of the storage associated with …\nResume all the mutator threads, the opposite of the above. …\nDelegated scanning of a object, visiting each reference …\nScan one mutator for stack roots.\nScan VM-specific roots. The creation of all root scan …\nStore the object reference.\nSet the referent in a weak reference object.\nThis module provides the trait <code>Slot</code> and related traits and …\nAsk the VM to spawn a GC thread for MMTk. A GC thread may …\nStop all the mutator threads. MMTk calls this method when …\nReturn whether the VM supports return barriers. This is …\nCall this function to trace through an object graph edge …\nCall this function for each slot.\nCreate a temporary <code>ObjectTracer</code> and provide access in the …\nVM-specific methods for the current plan.\nReturn whether there is a mutator created and associated …\nReturn a <code>Mutator</code> reference for the thread.\nReturn an iterator that includes all the mutators at the …\nReturn the total count of mutators.\nThe fallback for object tracing. MMTk generally expects to …\nThe fallback for object tracing. MMTk generally expects to …\nVM-specific methods for garbage collection.\nThread context for the spawned GC thread.  It is used by …\nThe GC thread to spawn is a worker thread. There can be …\nBlock the current thread for GC. This is called when an …\nAsk the binding to create a <code>GCTriggerPolicy</code> if the option …\nAsk the binding to create a <code>GCTriggerPolicy</code> if the option …\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nCallback function to ask the VM whether GC is enabled or …\nCallback function to ask the VM whether GC is enabled or …\nInform the VM of an out-of-memory error. The binding …\nInform the VM of an out-of-memory error. The binding …\nA hook for the VM to do work after forwarding objects.\nA hook for the VM to do work after forwarding objects.\nResume all the mutator threads, the opposite of the above. …\nInform the VM to schedule finalization threads.\nInform the VM to schedule finalization threads.\nAsk the VM to spawn a GC thread for MMTk. A GC thread may …\nStop all the mutator threads. MMTk calls this method when …\nReturn the amount of memory (in bytes) which the VM …\nReturn the amount of memory (in bytes) which the VM …\nA global 1-bit metadata used by generational plans to …\nA local 2-bit metadata for the forwarding status bits, …\nA local word-size metadata for the forwarding pointer, …\nA local 2-bit metadata used by the large object space to …\nA local 1-bit metadata for the mark bit, used by most …\nA local 1-bit metadata specification for the pinning bit, …\nSet this to true if the VM binding requires the valid …\nSet this to true if the VM binding requires the valid …\nFor our allocation result (object_start), the binding may …\nVM-specific methods for object model.\nIf this is true, the binding guarantees that the object …\nIf this is true, the binding guarantees that the object …\nThis is the worst case expansion that can occur due to …\nThis is the worst case expansion that can occur due to …\nA function to atomically compare-and-exchange the …\nA function to atomically compare-and-exchange the …\nCopy an object and return the address of the new object. …\nCopy an object. This is required for delayed-copy …\nDump debugging information for an object.\nA function to atomically perform an add operation on the …\nA function to atomically perform an add operation on the …\nA function to atomically perform a bit-and operation on …\nA function to atomically perform a bit-and operation on …\nA function to atomically perform a bit-or operation on the …\nA function to atomically perform a bit-or operation on the …\nA function to atomically perform a subtract operation on …\nA function to atomically perform a subtract operation on …\nA function to atomically perform an update operation on …\nA function to atomically perform an update operation on …\nReturn the alignment offset when an object is copied.\nReturn the alignment when an object is copied.\nReturn the size used by an object.\nReturn the reference that an object will be referred to …\nReturn the size when an object is copied.\nGet the type descriptor for an object.\nReturn if an object is valid from the runtime point of …\nReturn if an object is valid from the runtime point of …\nA function to non-atomically load the specified per-object …\nA function to non-atomically load the specified per-object …\nA function to atomically load the specified per-object …\nA function to atomically load the specified per-object …\nReturn the header base address from an object reference. …\nReturn the lowest address of the storage associated with …\nA function to non-atomically store a value to the …\nA function to non-atomically store a value to the …\nA function to atomically store a value to the specified …\nA function to atomically store a value to the specified …\nWhether this spec is global or local. For side metadata, …\nWhether this spec is global or local. For side metadata, …\nWhether this spec is global or local. For side metadata, …\nWhether this spec is global or local. For side metadata, …\nWhether this spec is global or local. For side metadata, …\nWhether this spec is global or local. For side metadata, …\nThe number of bits (in log2) that are needed for the spec.\nThe number of bits (in log2) that are needed for the spec.\nThe number of bits (in log2) that are needed for the spec.\nThe number of bits (in log2) that are needed for the spec.\nThe number of bits (in log2) that are needed for the spec.\nThe number of bits (in log2) that are needed for the spec.\n1-bit global metadata to log an object.\n2-bit local metadata for spaces that store a forwarding …\n1-word local metadata for spaces that may copy objects. …\n2-bits local metadata for the large object space. The two …\n1-bit local metadata for spaces that need to mark an …\n1-bit local metadata for spaces that support pinning.\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturn the inner <code>[crate::util::metadata::MetadataSpec]</code> for …\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nDeclare that the VM uses in-header metadata for this …\nDeclare that the VM uses in-header metadata for this …\nDeclare that the VM uses in-header metadata for this …\nDeclare that the VM uses in-header metadata for this …\nDeclare that the VM uses in-header metadata for this …\nDeclare that the VM uses in-header metadata for this …\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nTest if the mark bit for the object is set (1)\nCheck if an object is pinned.\nCheck if the log bit represents the unlogged state (the …\nSet the mark bit for the object to 1\nMark the log bit as unlogged (1 means unlogged)\nMark the entire byte as unlogged if the log bit is in the …\nReturn the number of bits for the metadata type.\nReturn the number of bits for the metadata type.\nReturn the number of bits for the metadata type.\nReturn the number of bits for the metadata type.\nReturn the number of bits for the metadata type.\nReturn the number of bits for the metadata type.\nPin an object by setting the pinning bit to 1. Return true …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nDeclare that the VM uses side metadata for this metadata …\nUnpin an object by clearing the pinning bit to 0. Return …\nA finalizable object for MMTk. MMTk needs to know the …\nThe type of finalizable objects. This type is used when …\nVM-specific methods for reference processing, including …\nWeak and soft references always clear the referent before …\nFor weak reference types, if the referent is cleared …\nLoad the object reference.\nGet the referent from a weak reference object.\nKeep the heap references in the finalizable object alive. …")